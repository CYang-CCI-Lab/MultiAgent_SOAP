{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import re\n",
    "from typing import Optional, Union, List, get_origin, get_args, Any, Dict, Literal\n",
    "import inspect\n",
    "# from __future__ import annotations\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import math\n",
    "import demjson3\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        handlers=[\n",
    "        # logging.FileHandler('0310_MA_MedicalQA_step2_async.log', mode='w'),  # Write to file\n",
    "        logging.StreamHandler()                     # Print to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_load(s: str) -> Any:\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string using the standard json.loads.\n",
    "    If that fails (e.g. due to an unterminated string), it will try using\n",
    "    a more forgiving parser (demjson3). If both attempts fail,\n",
    "    the original string is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(\"Standard json.loads failed: %s\", e)\n",
    "        try:\n",
    "            logger.info(\"Attempting to parse with demjson3 as fallback.\")\n",
    "            result = demjson3.decode(s)\n",
    "            logger.info(\"demjson3 successfully parsed the JSON.\")\n",
    "            return result\n",
    "        except Exception as e2:\n",
    "            logger.error(\"Fallback parsing with demjson3 also failed: %s. Returning original input.\", e2)\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_numbers(num1: float, num2: float) -> str:\n",
    "    \"\"\"\n",
    "    Compares a float (num1) with another number (num2) and returns a string.\n",
    "    \"\"\"\n",
    "    if num1 < num2:\n",
    "        return f\"{num1} is less than {num2}\"\n",
    "    elif num1 > num2:\n",
    "        return f\"{num1} is greater than {num2}\"\n",
    "    else:\n",
    "        return f\"{num1} is equal to {num2}\"\n",
    "\n",
    "def provide_final_prediction(reasoning: str, prediction: Literal[\"T1\", \"T2\", \"T3\", \"T4\"]) -> str:\n",
    "    \"\"\"\n",
    "    Returns a string with the reasoning and the final prediction.\n",
    "    \"\"\"\n",
    "    answer = f\"\"\"\n",
    "    Reasoning: {reasoning}\n",
    "    Final prediction: {prediction}\n",
    "    \"\"\"\n",
    "    return answer\n",
    "\n",
    "available_tools = {\"compare_numbers\": compare_numbers, \"provide_final_prediction\": provide_final_prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = generate_tools_spec(compare_numbers, provide_final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'compare_numbers',\n",
       "   'description': 'Compares a float (num1) with another number (num2) and returns a string.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'num1': {'type': 'number'}, 'num2': {'type': 'number'}},\n",
       "    'required': ['num1', 'num2']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'provide_final_prediction',\n",
       "   'description': 'Returns a string with the reasoning and the final prediction.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'reasoning': {'type': 'string'},\n",
       "     'prediction': {'type': 'string'}},\n",
       "    'required': ['reasoning', 'prediction']}}}]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = \"SPECIMENS: 1. F/S LINGULAR NODULE. 2. F/S LEFT LOWER LOBE WEDGE. 3. MARGIN OF LEFT LOWER LOBE WEDGE. 4. LEVEL 5 LYMPH NODE, LEFT. 5. LEVEL 7 LYMPH NODE, LEFT. 6. LEVEL 9 LYMPH NODE, LEFT. 7. BASILAR SEGMENT LEFT LOWER LOBE. SEE ADDENDUM. Reason For Addendum #1: Molecular Studies. Reason For Addendum #2: Molecular Studies. DIAGNOSIS: 1. LUNG, LINGULA: WEDGE RESECTION. - ADENOCARCINOMA, SOLID PREDOMINANT (1 CM), SEE NOTE. - THE STAPLE LINE MARGIN IS FREE OF TUMOR. Note: The tumor consists of solid (60%), acinar (30%) and lepidic. (10%) components. Immunohistochemical stains show that the tumor. cells are positive for TTF-1 and Napsin-A while negative for pó3,. supporting the diagnosis. 2,3,7. LUNG, LEFT LOWER LOBE, BASILAR SEGMENT: WEDGE BIOPSIES AND. COMPLETION SEGMENTECTOMY. - ADENOCARCINOMA, MICROPAPILLARY PREDOMINANT (3.5 CM),. SEE NOTE. - THE BRONCHIAL AND VASCULAR MARGINS ARE FREE OF TUMOR. - FOUR LYMPH NODES, NEGATIVE FOR CARCINOMA (0/4). Note: The tumor consists of micropapillary (60%), papillary (20%),. lepidic (10%) and acinar (10%) components and measures 3.5 cm in. aggregate dimension in Parts 2, 3 and 7. It is morphologically. distinct from the concurrent lingular adenocarcinoma, favoring a. separate primary. Results of mutational studies will be reported in. addenda. 4. LYMPH NODE, LEFT LEVEL 5: BIOPSY. - FOUR LYMPH NODES, NEGATIVE FOR CARCINOMA (0/4). 5. LYMPH NODE, LEFT LEVEL 7: BIOPSY. - ONE LYMPH NODE, NEGATIVE FOR CARCINOMA (0/1). 6. LYMPH NODE, LEFT LEVEL 9: BIOPSY. - ONE LYMPH NODE, NEGATIVE FOR CARCINOMA (0/1). Specimens: 1: F/S LINGULAR NODULE. 2: F/S LEFT LOWER LOBE WEDGE. 3: MARGIN OF LEFT LOWER LOBE WEDGE. 4: LEVEL 5 LYMPH NODE, LEFT. 5: LEVEL 7 LYMPH NODE, LEFT. 6: LEVEL 9 LYMPH NODE, LEFT. 7: BASILAR SEGMENT LEFT LOWER LOBE. LUNG: Resection. SPECIMEN. Specimen: Lobe(s) of lung (specify). lingula and left lower. Procedure: Segmentectomy. Specimen Laterality: Left. Tumor Site: Lower lobe. Tumor Focality: Synchronous carcinomas (specify sites). lingula and left lower lobe. TUMOR. Histologic Type: Adenocarcinoma, mixed subtype. Histologic Grade: G3: Poorly differentiated. EXTENT. Tumor Size: Greatest dimension (cm). 3.5cm. Visceral Pleura Invasion: Not identified. MARGINS. Bronchial Margin. Bronchial Margin Involvement by Invasive Carcinoma: Uninvolved by. invasive carcinoma. Vascular Margin: Uninvolved by invasive carcinoma. Parenchymal Margin: Uninvolved by invasive carcinoma. ACCESSORY FINDINGS. Lymph-Vascular Invasion: Not identified. STAGE (pTNM). TNM Descriptors: m (multiple primary tumors). Primary Tumor (pT): pT2a: Tumor greater than 3 cm, but 5 cm or less in greatest. dimension surrounded by lung or visceral pleura without. bronchoscopic evidence of invasion more proximal than the lobar. bronchus (i.e., not in the main bronchus); or Tumor 5 cm or less. in greatest dimension with any of the following features of extent: involves main bronchus, 2 cm or more distal to the carina; invades. the visceral pleura; associated with atelectasis or obstructive. pneumonitis that extends to the hilar region but does not inolve the. entire lung. Regional Lymph Nodes (pN). pNO: No regional lymph node metastasis. Distant Metastases (pM): Not applicable. ADDITIONAL NON-TUMOR. Additional Pathologic Finding(s): Emphysema. CLINICAL HISTORY AND PRE - OPERATIVE DIAGNOSIS: M ex-smoker (120 pack-years) with a 1.6 cm RUL nodule, 3.7 cm LLL. ground-glass mass and a 1 cm lingular nodule. MACROSCOPIC DESCRIPTION: The specimen is received in seven parts, each labeled with the. patient's name. 1. Part one is received fresh, labeled 'lingular nodule'. It. consists of a lingular segment of the lung measuring 15 x 7 x 3.5. cm. The staple line measures 17 cm which is shaved and the bronchial. around inked blue. The pleura is gray pink and glistening and. mottled moderately with fine black streaks. Also noted is a precut. area on the pleura which reveals a sub pleural gray white firm. nodule, measuring 1 x 0.9 x 0.8 cm located 2 cm from the staple line. margin. The remainder of the bronchial is pink red blotchy and. crepitant. No other nodule is grossly identified. Frozen section is. performed on the nodule and resubmitted for permanent section. Representative section of the specimen and entire nodule are. submitted. 2. Part two is labeled 'left lower lobe wedge'. It consists of one. piece of yellow-pink soft tissue measuring 2 x 1 x 0.5 cm. Entirely. submitted in one cassette. 3. Part three is received fresh, labeled 'margin of left lower lobe. wedge'. It consists of a stapled strip of light tan tissue. measuring 3.5 x 0.4 x 0.3 cm. The staple line is shaved and the soft. tissue is submitted. 4. Part four is labeled 'level #5 lymph node'. It consists of. multiple soft red-black lymph nodes measuring 1.5 x 1.1 x 0.6 cm in. aggregate. Entirely submitted in one cassette. 5. Part five is labeled 'level #7 lymph node'. It consists of a 1.5. x 1 x 0.8 cm red-black lymph node. Entirely submitted in one. cassette. 6. Part six is labeled 'level #9 lymph node'. It consists of a 1.2. x 1 x 0.6 cm red-black lymph node. Entirely submitted in one. cassette. 7. Part seven is received fresh, labeled 'basilar segment left lower. lobe silk stitches on tumor location'. It consists of a segment of. lung measuring 20 x 14 x 4.5 cm. The bronchial margin measures 1.5. cm and the vascular margin measures 1 cm. The pleura is gray pink. glistening and mottled moderately with fine black streaks. There are. two staple lines measuring 8 cm and 5 cm in length. There is a. precut area on the pleura which is marked with a stitch. At this. area there is a grey tan firm mass, measuring 1.5 x 1 cm and located. 1.5 cm from the bronchial resection margin, and 0.4 cm from the. closest staple line which is shaved and the bronchial is inked. black. The mass is located on the mediastinal surface of the lung. The remaining of the bronchial is pink red blotchy and crepitant. No. other nodule is grossly identified. Representative sections of the. specimen and the entire mass area with adjacent tissue are. submitted. SUMMARY OF SECTIONS: 1A frozen section of the nodule. 1B-1D remaining of the nodule. 1E random section of the lung parenchyma. 1F staple line margin. 2A in toto. 3A soft tissue submitted, shaved. 4A in toto. 5A in toto. 6A in toto. 7A bronchial margin, shaved. 7B vascular margin, shaved. 7C-7H mass from stitch area with overlying pleura. 7I-7L mass from stitch area after shaving the staple line. 7M anthracotic lymph node from the hilum. SPECIAL PROCEDURES: INTRA - OPERATIVE CONSULTATION: 1. Lung, lingula: wedge resection (Frozen Section). - Adenocarcinoma with lepidic, acinar and solid patterns. Result reported by. 2. Lung, left lower lobe: wedge biopsy (Frozen Section). - Adenocarcinoma with acinar and micropapillary patterns. Result reported by. on. Intra-Operative Consultation #1 performed by. Intra-Operative Consultation #2 performed by. Final Diagnosis performed by. ADDENDUM 1: Integrated Oncology. MOLECULAR ONCOLOGY. KRAS MUTATION ANALYSIS. Specimen #: RESULTS: Positive for a p.G12A (c.34G>C) mutation in codon 12 of. the KRAS gene. INTERPRETATION: Mutations in the KRAS gene are reported to. correlate with poor prognosis and resistance to tyrosine kinase. inhibitor therapies in patients with non-small lung cancer. COMMENT: KRAS mutations occur in 15-30% of non-small-cell lung cancer (NSCLC). patients and are strongly associated with adenocarcinoma and smoking. history. This assay analyzes codons 12 and 13 in exon 2 of the KRAS gene;. based on the current literature, approximately 98% of mutations are. expected to occur in these codons. The analytical sensitivity of. the assay is approximately 10%; thus mutations present in a low. percentage of cells may not be detected. This test is validated for use in identifying KRAS codon 12 and. codon 13 mutations in fresh, frozen, or formalin-fixed paraffin. embedded tissue. In particular the test performance has been. established in samples of colorectal cancer and non-small cell lung. carcinoma which harbor these mutations, although several other. tissues are also known to harbor KRAS mutations (e.g. tumors of. pancreas, bile duct, ovary, appendix, etc.). METHOD/LIMITATION: Tissue sections are reviewed by a pathologist and relevant tumor is. selected for analysis. DNA is isolated from the sample, quantified. and amplified by polymerase chain reaction (PCR) using primers to. exon 2 of the KRAS gene. PCR products are subjected to single. nucleotide primer extension to detect mutations at codons 12 and 13;. primer extension products are analyzed using capillary gel. electrophoresis and fluorescence detection. False positive or. negative results may occur for reasons that include genetic variants. or somatic heterogeneity of the tissue sample. REFERENCES: NSCLC. Mascaux C, Iannino N, et al. British Journal of Cancer, 2005;. 92:11-139. Pao W, Wang TY, et al. PLoS Medicine, 205; 2(1):57-61. Eberhard DA, Johnson BE, et al. J Clin Oncol, 2005; 23:5900-5909. Han SW, Kim TY, et al. Clin Cancer Res. 2006; 12(8):253888888-2544. CRC. DiFiore C, Blanchard F, et al. Br J Cancer, 20007; 96:1166-1169. Lievre A, Bachet J-B, et al. Cancer Res, 2006; 66:3992-3995,. This test was developed and its performance characteristics. determined by. The laboratory is. regulated under the Clinical Laboratory Improvement Amendments of. 1988 (CLIA) as qualified to perform high complexity clinical. testing. This particular test is not considered a stand alone test. and should be only used in the context of other diagnostic tests or. clinical work-up related to treatment decisions. Addendum #1 performed by. ADDENDUM 2: EGFR Mutation Analysis. Specimen #: Clinical Data: Adenocarcinoma. RESULTS: No mutation detected. INTERPRETATION: No mutations were identified; in the sample. provided for analysis. Fewer than %5 of non-small-cell lung. carcinoma patients without identifiable mutations are reported to be. responsive to EGFR tyrosine kinase inhibitor therapies. COMMENT: Forty percent (40%) or more cellularity is optimal for. this mutation analysis. The sample submitted showed 50% tumor. cellularity upon pathologist review. A frequently occurring sequence change 2361G>A (Q787Q) was. identified. This polymorphism is known not to have clinical. significance. Mutations in th vrosine kinase domain of the epidermal growth. factor recept. gene are reported to be associated with. differenti. ness or resistance to EGFR tyrosine kinase. inhibitr. The objective response rate among. patien. ing. itation ranges from 55 to 82%. 8-21 of the EGFR tyrosine kinase domain;. noni 11: most mutations in non-small-cell lung. (NSCLC). are expected to occur in these exons. Mutations. present a less that 10-. 0% of extracted DNA may not be detected by. this Muta on. au is in a sample may change during tumor. progress on or the burse. therapy; therefore, this result cannot. be used. Ince. absence of a mutation in another sample. ! fr. n this tumor. This. non-small cell lung carcinoma. The. clinica. jit. tility of this test in other tumor types. is unknown. METHOD: Tissue sections are reviewed by a pathologist and relevant tumor is. selected for analysis. DNA is isolated from the samples, quantified. and amplified by polymerase chain reaction (PCR) using primers to. exons 18-21 of the EGFR gene. PCR products are analyzed by. bi-directional direct DNA sequencing using capillary gel. electrophoresis and fluorescence detection. False positive or. negative results may occur for reasons that include genetic variants. or somatic heterogeneity of the tissue sample. REFERENCES: 1. Azzoli CG, et al. J Clin Oncol. 2009; 27-6251-6266. 2. Jackman DM et al. Clin Carcinoma Res 2009; 15:5267-5273. 3. Mok TS, et al. N Engl J Med. 2009;361:947-957. 4. Sharma SV, et al. Nat Rev Carcinoma. 2007;169-181. DISCLAIMER: This test was developed and its performance characteristics. determined by. The laboratory is. regulated under the Clinical Laboratory Improvement Amendments of. 1988 (CLIA) as qualified to perform high complexity clinical. testing. This particular test is not considered a stand alone test. and should be only used in the context of other diagnostic tests or. clinical work-up related to treatment decisions. Addendum #2 performed by. The electronic signature attests that the named Attending. Pathologist has evaluated the specimen referred to in the signed. section of the report and formulated the diagnosis therein. This report may include one or more immunohistochemical stain. results that use analyte specific reagents. The tests were developed and their performance characteristics. determined by. They have not been cleared or approved by the US Food and Drug. Administration. The FDA has determined that such clearance or approval is not. necessary.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are provided with a pathology report of a cancer patient.\n",
    "Determine the T stage by comparing the tumor size with standard thresholds.\n",
    "If you need to compare any numerical values with the threshold values, use the 'compare_numbers' function.\n",
    "When you have decided the stage, provide the final answer by calling 'provide_final_prediction' function with your reasoning and the final prediction as arguments.\n",
    "\n",
    "Pathology report:\n",
    "{report}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "formatted_prompt = prompt.format(report=report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:04:13 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-11 00:04:13 - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'\n"
     ]
    }
   ],
   "source": [
    "client=OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are an AI assistant specialized in cancer staging.\",\n",
    "    \"role\": \"user\", \"content\": formatted_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 00:05:38 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"\\nYou are provided with a pathology report of a cancer patient.\\n\\nPathology report:\\nSPECIMENS: 1. F/S LINGULAR NODULE. 2. F/S LEFT LOWER LOBE WEDGE. 3. MARGIN OF LEFT LOWER LOBE WEDGE. 4. LEVEL 5 LYMPH NODE, LEFT. 5. LEVEL 7 LYMPH NODE, LEFT. 6. LEVEL 9 LYMPH NODE, LEFT. 7. BASILAR SEGMENT LEFT LOWER LOBE. SEE ADDENDUM. Reason For Addendum #1: Molecular Studies. Reason For Addendum #2: Molecular Studies. DIAGNOSIS: 1. LUNG, LINGULA: WEDGE RESECTION. - ADENOCARCINOMA, SOLID PREDOMINANT (1 CM), SEE NOTE. - THE STAPLE LINE MARGIN IS FREE OF TUMOR. Note: The tumor consists of solid (60%), acinar (30%) and lepidic. (10%) components. Immunohistochemical stains show that the tumor. cells are positive for TTF-1 and Napsin-A while negative for pó3,. supporting the diagnosis. 2,3,7. LUNG, LEFT LOWER LOBE, BASILAR SEGMENT: WEDGE BIOPSIES AND. COMPLETION SEGMENTECTOMY. - ADENOCARCINOMA, MICROPAPILLARY PREDOMINANT (3.5 CM),. SEE NOTE. - THE BRONCHIAL AND VASCULAR MARGINS ARE FREE OF TUMOR. - FOUR LYMPH NODES, NEGATIVE FOR CARCINOMA (0/4). Note: The tumor consists of micropapillary (60%), papillary (20%),. lepidic (10%) and acinar (10%) components and measures 3.5 cm in. aggregate dimension in Parts 2, 3 and 7. It is morphologically. distinct from the concurrent lingular adenocarcinoma, favoring a. separate primary. Results of mutational studies will be reported in. addenda. 4. LYMPH NODE, LEFT LEVEL 5: BIOPSY. - FOUR LYMPH NODES, NEGATIVE FOR CARCINOMA (0/4). 5. LYMPH NODE, LEFT LEVEL 7: BIOPSY. - ONE LYMPH NODE, NEGATIVE FOR CARCINOMA (0/1). 6. LYMPH NODE, LEFT LEVEL 9: BIOPSY. - ONE LYMPH NODE, NEGATIVE FOR CARCINOMA (0/1). Specimens: 1: F/S LINGULAR NODULE. 2: F/S LEFT LOWER LOBE WEDGE. 3: MARGIN OF LEFT LOWER LOBE WEDGE. 4: LEVEL 5 LYMPH NODE, LEFT. 5: LEVEL 7 LYMPH NODE, LEFT. 6: LEVEL 9 LYMPH NODE, LEFT. 7: BASILAR SEGMENT LEFT LOWER LOBE. LUNG: Resection. SPECIMEN. Specimen: Lobe(s) of lung (specify). lingula and left lower. Procedure: Segmentectomy. Specimen Laterality: Left. Tumor Site: Lower lobe. Tumor Focality: Synchronous carcinomas (specify sites). lingula and left lower lobe. TUMOR. Histologic Type: Adenocarcinoma, mixed subtype. Histologic Grade: G3: Poorly differentiated. EXTENT. Tumor Size: Greatest dimension (cm). 3.5cm. Visceral Pleura Invasion: Not identified. MARGINS. Bronchial Margin. Bronchial Margin Involvement by Invasive Carcinoma: Uninvolved by. invasive carcinoma. Vascular Margin: Uninvolved by invasive carcinoma. Parenchymal Margin: Uninvolved by invasive carcinoma. ACCESSORY FINDINGS. Lymph-Vascular Invasion: Not identified. STAGE (pTNM). TNM Descriptors: m (multiple primary tumors). Primary Tumor (pT): pT2a: Tumor greater than 3 cm, but 5 cm or less in greatest. dimension surrounded by lung or visceral pleura without. bronchoscopic evidence of invasion more proximal than the lobar. bronchus (i.e., not in the main bronchus); or Tumor 5 cm or less. in greatest dimension with any of the following features of extent: involves main bronchus, 2 cm or more distal to the carina; invades. the visceral pleura; associated with atelectasis or obstructive. pneumonitis that extends to the hilar region but does not inolve the. entire lung. Regional Lymph Nodes (pN). pNO: No regional lymph node metastasis. Distant Metastases (pM): Not applicable. ADDITIONAL NON-TUMOR. Additional Pathologic Finding(s): Emphysema. CLINICAL HISTORY AND PRE - OPERATIVE DIAGNOSIS: M ex-smoker (120 pack-years) with a 1.6 cm RUL nodule, 3.7 cm LLL. ground-glass mass and a 1 cm lingular nodule. MACROSCOPIC DESCRIPTION: The specimen is received in seven parts, each labeled with the. patient's name. 1. Part one is received fresh, labeled 'lingular nodule'. It. consists of a lingular segment of the lung measuring 15 x 7 x 3.5. cm. The staple line measures 17 cm which is shaved and the bronchial. around inked blue. The pleura is gray pink and glistening and. mottled moderately with fine black streaks. Also noted is a precut. area on the pleura which reveals a sub pleural gray white firm. nodule, measuring 1 x 0.9 x 0.8 cm located 2 cm from the staple line. margin. The remainder of the bronchial is pink red blotchy and. crepitant. No other nodule is grossly identified. Frozen section is. performed on the nodule and resubmitted for permanent section. Representative section of the specimen and entire nodule are. submitted. 2. Part two is labeled 'left lower lobe wedge'. It consists of one. piece of yellow-pink soft tissue measuring 2 x 1 x 0.5 cm. Entirely. submitted in one cassette. 3. Part three is received fresh, labeled 'margin of left lower lobe. wedge'. It consists of a stapled strip of light tan tissue. measuring 3.5 x 0.4 x 0.3 cm. The staple line is shaved and the soft. tissue is submitted. 4. Part four is labeled 'level #5 lymph node'. It consists of. multiple soft red-black lymph nodes measuring 1.5 x 1.1 x 0.6 cm in. aggregate. Entirely submitted in one cassette. 5. Part five is labeled 'level #7 lymph node'. It consists of a 1.5. x 1 x 0.8 cm red-black lymph node. Entirely submitted in one. cassette. 6. Part six is labeled 'level #9 lymph node'. It consists of a 1.2. x 1 x 0.6 cm red-black lymph node. Entirely submitted in one. cassette. 7. Part seven is received fresh, labeled 'basilar segment left lower. lobe silk stitches on tumor location'. It consists of a segment of. lung measuring 20 x 14 x 4.5 cm. The bronchial margin measures 1.5. cm and the vascular margin measures 1 cm. The pleura is gray pink. glistening and mottled moderately with fine black streaks. There are. two staple lines measuring 8 cm and 5 cm in length. There is a. precut area on the pleura which is marked with a stitch. At this. area there is a grey tan firm mass, measuring 1.5 x 1 cm and located. 1.5 cm from the bronchial resection margin, and 0.4 cm from the. closest staple line which is shaved and the bronchial is inked. black. The mass is located on the mediastinal surface of the lung. The remaining of the bronchial is pink red blotchy and crepitant. No. other nodule is grossly identified. Representative sections of the. specimen and the entire mass area with adjacent tissue are. submitted. SUMMARY OF SECTIONS: 1A frozen section of the nodule. 1B-1D remaining of the nodule. 1E random section of the lung parenchyma. 1F staple line margin. 2A in toto. 3A soft tissue submitted, shaved. 4A in toto. 5A in toto. 6A in toto. 7A bronchial margin, shaved. 7B vascular margin, shaved. 7C-7H mass from stitch area with overlying pleura. 7I-7L mass from stitch area after shaving the staple line. 7M anthracotic lymph node from the hilum. SPECIAL PROCEDURES: INTRA - OPERATIVE CONSULTATION: 1. Lung, lingula: wedge resection (Frozen Section). - Adenocarcinoma with lepidic, acinar and solid patterns. Result reported by. 2. Lung, left lower lobe: wedge biopsy (Frozen Section). - Adenocarcinoma with acinar and micropapillary patterns. Result reported by. on. Intra-Operative Consultation #1 performed by. Intra-Operative Consultation #2 performed by. Final Diagnosis performed by. ADDENDUM 1: Integrated Oncology. MOLECULAR ONCOLOGY. KRAS MUTATION ANALYSIS. Specimen #: RESULTS: Positive for a p.G12A (c.34G>C) mutation in codon 12 of. the KRAS gene. INTERPRETATION: Mutations in the KRAS gene are reported to. correlate with poor prognosis and resistance to tyrosine kinase. inhibitor therapies in patients with non-small lung cancer. COMMENT: KRAS mutations occur in 15-30% of non-small-cell lung cancer (NSCLC). patients and are strongly associated with adenocarcinoma and smoking. history. This assay analyzes codons 12 and 13 in exon 2 of the KRAS gene;. based on the current literature, approximately 98% of mutations are. expected to occur in these codons. The analytical sensitivity of. the assay is approximately 10%; thus mutations present in a low. percentage of cells may not be detected. This test is validated for use in identifying KRAS codon 12 and. codon 13 mutations in fresh, frozen, or formalin-fixed paraffin. embedded tissue. In particular the test performance has been. established in samples of colorectal cancer and non-small cell lung. carcinoma which harbor these mutations, although several other. tissues are also known to harbor KRAS mutations (e.g. tumors of. pancreas, bile duct, ovary, appendix, etc.). METHOD/LIMITATION: Tissue sections are reviewed by a pathologist and relevant tumor is. selected for analysis. DNA is isolated from the sample, quantified. and amplified by polymerase chain reaction (PCR) using primers to. exon 2 of the KRAS gene. PCR products are subjected to single. nucleotide primer extension to detect mutations at codons 12 and 13;. primer extension products are analyzed using capillary gel. electrophoresis and fluorescence detection. False positive or. negative results may occur for reasons that include genetic variants. or somatic heterogeneity of the tissue sample. REFERENCES: NSCLC. Mascaux C, Iannino N, et al. British Journal of Cancer, 2005;. 92:11-139. Pao W, Wang TY, et al. PLoS Medicine, 205; 2(1):57-61. Eberhard DA, Johnson BE, et al. J Clin Oncol, 2005; 23:5900-5909. Han SW, Kim TY, et al. Clin Cancer Res. 2006; 12(8):253888888-2544. CRC. DiFiore C, Blanchard F, et al. Br J Cancer, 20007; 96:1166-1169. Lievre A, Bachet J-B, et al. Cancer Res, 2006; 66:3992-3995,. This test was developed and its performance characteristics. determined by. The laboratory is. regulated under the Clinical Laboratory Improvement Amendments of. 1988 (CLIA) as qualified to perform high complexity clinical. testing. This particular test is not considered a stand alone test. and should be only used in the context of other diagnostic tests or. clinical work-up related to treatment decisions. Addendum #1 performed by. ADDENDUM 2: EGFR Mutation Analysis. Specimen #: Clinical Data: Adenocarcinoma. RESULTS: No mutation detected. INTERPRETATION: No mutations were identified; in the sample. provided for analysis. Fewer than %5 of non-small-cell lung. carcinoma patients without identifiable mutations are reported to be. responsive to EGFR tyrosine kinase inhibitor therapies. COMMENT: Forty percent (40%) or more cellularity is optimal for. this mutation analysis. The sample submitted showed 50% tumor. cellularity upon pathologist review. A frequently occurring sequence change 2361G>A (Q787Q) was. identified. This polymorphism is known not to have clinical. significance. Mutations in th vrosine kinase domain of the epidermal growth. factor recept. gene are reported to be associated with. differenti. ness or resistance to EGFR tyrosine kinase. inhibitr. The objective response rate among. patien. ing. itation ranges from 55 to 82%. 8-21 of the EGFR tyrosine kinase domain;. noni 11: most mutations in non-small-cell lung. (NSCLC). are expected to occur in these exons. Mutations. present a less that 10-. 0% of extracted DNA may not be detected by. this Muta on. au is in a sample may change during tumor. progress on or the burse. therapy; therefore, this result cannot. be used. Ince. absence of a mutation in another sample. ! fr. n this tumor. This. non-small cell lung carcinoma. The. clinica. jit. tility of this test in other tumor types. is unknown. METHOD: Tissue sections are reviewed by a pathologist and relevant tumor is. selected for analysis. DNA is isolated from the samples, quantified. and amplified by polymerase chain reaction (PCR) using primers to. exons 18-21 of the EGFR gene. PCR products are analyzed by. bi-directional direct DNA sequencing using capillary gel. electrophoresis and fluorescence detection. False positive or. negative results may occur for reasons that include genetic variants. or somatic heterogeneity of the tissue sample. REFERENCES: 1. Azzoli CG, et al. J Clin Oncol. 2009; 27-6251-6266. 2. Jackman DM et al. Clin Carcinoma Res 2009; 15:5267-5273. 3. Mok TS, et al. N Engl J Med. 2009;361:947-957. 4. Sharma SV, et al. Nat Rev Carcinoma. 2007;169-181. DISCLAIMER: This test was developed and its performance characteristics. determined by. The laboratory is. regulated under the Clinical Laboratory Improvement Amendments of. 1988 (CLIA) as qualified to perform high complexity clinical. testing. This particular test is not considered a stand alone test. and should be only used in the context of other diagnostic tests or. clinical work-up related to treatment decisions. Addendum #2 performed by. The electronic signature attests that the named Attending. Pathologist has evaluated the specimen referred to in the signed. section of the report and formulated the diagnosis therein. This report may include one or more immunohistochemical stain. results that use analyte specific reagents. The tests were developed and their performance characteristics. determined by. They have not been cleared or approved by the US Food and Drug. Administration. The FDA has determined that such clearance or approval is not. necessary.\\n\\nInstructions:\\nDetermine the T stage by comparing the tumor size with standard thresholds.\\nIf you need to compare any numerical values with the threshold values, use the 'compare_numbers' function.\\nWhen you have decided the stage, provide the final answer by calling 'provide_final_prediction' function with your reasoning and the final prediction as arguments.\\n\"}, {'role': 'assistant', 'tool_calls': [{'id': 'chatcmpl-tool-f7607771b1814c22be0b190e2cdc219f', 'function': {'arguments': '{\"num1\": \"3.5\", \"num2\": \"3\"}', 'name': 'compare_numbers'}, 'type': 'function'}]}, {'role': 'tool', 'content': '3.5 is greater than 3', 'tool_call_id': 'chatcmpl-tool-f7607771b1814c22be0b190e2cdc219f', 'name': 'compare_numbers'}, {'role': 'assistant', 'tool_calls': [{'id': 'chatcmpl-tool-6d4f51ba60784a8cb095088e730f04fe', 'function': {'arguments': '{\"num1\": \"3.5\", \"num2\": \"5\"}', 'name': 'compare_numbers'}, 'type': 'function'}]}, {'role': 'tool', 'content': '3.5 is less than 5', 'tool_call_id': 'chatcmpl-tool-6d4f51ba60784a8cb095088e730f04fe', 'name': 'compare_numbers'}], 'model': 'meta-llama/Llama-3.3-70B-Instruct', 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'compare_numbers', 'description': 'Compares a float (num1) with another number (num2) and returns a string.', 'parameters': {'type': 'object', 'properties': {'num1': {'type': 'number'}, 'num2': {'type': 'number'}}, 'required': ['num1', 'num2']}}}, {'type': 'function', 'function': {'name': 'provide_final_prediction', 'description': 'Returns a string with the reasoning and the final prediction.', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string'}, 'prediction': {'type': 'string'}}, 'required': ['reasoning', 'prediction']}}}]}}\n",
      "2025-03-11 00:05:38 - DEBUG - Sending HTTP Request: POST http://localhost:8000/v1/chat/completions\n",
      "2025-03-11 00:05:38 - DEBUG - close.started\n",
      "2025-03-11 00:05:38 - DEBUG - close.complete\n",
      "2025-03-11 00:05:38 - DEBUG - connect_tcp.started host='localhost' port=8000 local_address=None timeout=5.0 socket_options=None\n",
      "2025-03-11 00:05:38 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff9a48b1970>\n",
      "2025-03-11 00:05:38 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 00:05:38 - DEBUG - send_request_headers.complete\n",
      "2025-03-11 00:05:38 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-11 00:05:38 - DEBUG - send_request_body.complete\n",
      "2025-03-11 00:05:38 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 00:05:46 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Mar 2025 00:05:37 GMT'), (b'server', b'uvicorn'), (b'content-length', b'768'), (b'content-type', b'application/json')])\n",
      "2025-03-11 00:05:46 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-11 00:05:46 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-11 00:05:46 - DEBUG - receive_response_body.complete\n",
      "2025-03-11 00:05:46 - DEBUG - response_closed.started\n",
      "2025-03-11 00:05:46 - DEBUG - response_closed.complete\n",
      "2025-03-11 00:05:46 - DEBUG - HTTP Response: POST http://localhost:8000/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 11 Mar 2025 00:05:37 GMT', 'server': 'uvicorn', 'content-length': '768', 'content-type': 'application/json'})\n",
      "2025-03-11 00:05:46 - DEBUG - request_id: None\n"
     ]
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model = \"meta-llama/Llama-3.3-70B-Instruct\", \n",
    "    messages = messages,\n",
    "    tools = tools,\n",
    "    tool_choice=\"auto\", \n",
    "    # tool_choice=\"none\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls detected.\n",
      "\n",
      "    Reasoning: The tumor size is 3.5 cm, which is greater than 3 cm but less than 5 cm. According to the TNM staging system, this corresponds to a T2a stage.\n",
      "    Final prediction: T2a\n",
      "    \n",
      "Final prediction detected.\n"
     ]
    }
   ],
   "source": [
    "if resp.choices[0].message.tool_calls:\n",
    "    print(\"Tool calls detected.\")\n",
    "    messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": resp.choices[0].message.tool_calls\n",
    "    })\n",
    "    for call in resp.choices[0].message.tool_calls:\n",
    "        \n",
    "        args = safe_json_load(call.function.arguments)\n",
    "        if call.function.name == \"provide_final_prediction\":\n",
    "            return args\n",
    "        result = available_tools[call.function.name](**args)\n",
    "        print(result)\n",
    "        messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": result,\n",
    "        \"tool_call_id\": call.id,\n",
    "        \"name\": call.function.name,\n",
    "        })\n",
    "\n",
    "else:\n",
    "    final_result = resp.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": final_result})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='In order to determine the T stage of the lung cancer based on the provided pathology report and to follow the format required for the response, we need to compare the size of the tumor with standard thresholds defined by the TNM staging system. The size of the tumor is mentioned as 3.5 cm in the report. According to the TNM staging system for lung cancer, a tumor size greater than 3 cm but less than or equal to 5 cm corresponds to T2a.\\n\\nHere is how you could write the Python code to implement these steps and provide the final answer:\\n\\n```python\\ndef provide_final_prediction(reasoning, prediction):\\n    return f\"The final answer is {prediction} because {reasoning}.\"\\n\\n# Compare the tumor size with the threshold for T2a\\nnum1 = 3.5  # Tumor size in cm\\nnum2 = 3    # Threshold size for T2a in cm\\n\\n# Determine the T stage based on the comparison\\nif num1 > num2 and num1 <= 5:\\n    T_stage = \"T2a\"\\n    reasoning = \"the tumor size is greater than 3 cm but less than or equal to 5 cm, which corresponds to T2a according to the TNM staging system for lung cancer.\"\\nelse:\\n    T_stage = \"Unknown\"\\n    reasoning = \"the tumor size does not match the criteria for T2a.\"\\n\\nfinal_answer = provide_final_prediction(reasoning, T_stage)\\nprint(final_answer)\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], reasoning_content=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'The tumor size is 3.5 cm, which is greater than 3 cm but less than 5 cm. According to the TNM staging system, this corresponds to a T2a stage.',\n",
       " 'prediction': 'T2a'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-8f3cefefc2434cb9ab9bed620d8071f9', function=Function(arguments='{\"reasoning\": \"The tumor size is 3.5 cm, which is greater than 3 cm but less than 5 cm. According to the TNM staging system, this corresponds to a T2a stage.\", \"prediction\": \"T2a\"}', name='provide_final_prediction'), type='function')], reasoning_content=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 15:14:33 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-07 15:14:33 - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'\n"
     ]
    }
   ],
   "source": [
    "def safe_json_load(s: str) -> Any:\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string using the standard json.loads.\n",
    "    If that fails (e.g. due to an unterminated string), it will try using\n",
    "    a more forgiving parser (demjson3). If both attempts fail,\n",
    "    the original string is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(\"Standard json.loads failed: %s\", e)\n",
    "        try:\n",
    "            logger.info(\"Attempting to parse with demjson3 as fallback.\")\n",
    "            result = demjson3.decode(s)\n",
    "            logger.info(\"demjson3 successfully parsed the JSON.\")\n",
    "            return result\n",
    "        except Exception as e2:\n",
    "            logger.error(\"Fallback parsing with demjson3 also failed: %s. Returning original input.\", e2)\n",
    "            return s\n",
    "\n",
    "\n",
    "class LLMAgent:\n",
    "    def __init__(self, system_prompt: str, \n",
    "                 client=AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")):\n",
    "        self.client = client\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    async def llm_call(self, user_prompt: str,\n",
    "                       guided_: dict = None,\n",
    "                       tools: List[dict] = None) -> Any:\n",
    "        logger.debug(f\"LLMAgent.llm_call() - user_prompt[:60]: {user_prompt[:60]}...\")\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        params = {\n",
    "            \"model\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "            \"messages\": self.messages,\n",
    "            \"temperature\": 0.5,\n",
    "        }\n",
    "        if guided_:\n",
    "            logger.debug(f\"Guided JSON/choice detected: {guided_}\")\n",
    "            params[\"extra_body\"] = guided_\n",
    "        if tools:\n",
    "            params[\"tools\"] = tools\n",
    "\n",
    "        response = await self.client.chat.completions.create(**params)\n",
    "        return response.choices[0].message\n",
    "    \n",
    "    def append_message(self, content, role='assistant'):\n",
    "        logger.debug(f\"Appending message with role='{role}' to conversation.\")\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "        return\n",
    "\n",
    "\n",
    "class InitializerAgent(LLMAgent):\n",
    "    def __init__(self, n_specialists: int):\n",
    "        self.n_specialists = n_specialists\n",
    "        system_prompt = (\n",
    "            \"You are an initializer agent in a multi-agent AI system designed to handle medical questions.\\n\"\n",
    "            f\"Your job is to select {self.n_specialists} medical specialists whose expertise best matches the user's query.\\n\"\n",
    "            \"For each specialist, specify their role and a list of relevant expertise areas related to the query.\\n\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def identify_specialists(self, query: str):\n",
    "        logger.info(\"InitializerAgent: Identifying specialists.\")\n",
    "        class Specialist(BaseModel):\n",
    "            specialist: str = Field(..., description=\"Role of the specialist\")\n",
    "            expertise: List[str] = Field(..., description=\"Areas of expertise for the specialist.\")\n",
    "        panel_dict = {f\"Specialist_{i+1}\": (Specialist, ...) for i in range(self.n_specialists)}\n",
    "        SpecialistPanel = create_model(\"SpecialistPanel\", **panel_dict)\n",
    "\n",
    "        user_prompt = (\n",
    "            \"Here is the user's query:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            \"Based on the above query, identify the most suitable specialists.\"\n",
    "        )\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": SpecialistPanel.schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"InitializerAgent response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "class SpecialistAgent(LLMAgent):\n",
    "    def __init__(self, specialist: str, expertise: List[str]):\n",
    "        self.specialist = specialist\n",
    "        self.expertise = expertise\n",
    "        system_prompt = (\n",
    "            f\"You are a {specialist}.\\n\"\n",
    "            f\"Your expertise includes:\\n{expertise}\\n\"\n",
    "            f\"Analyze the user's query from the perspective of a {specialist}.\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def analyze_query(self, query: str, choices: List[str]):\n",
    "        logger.info(f\"[{self.specialist}] Analyzing query...\")\n",
    "        self.query = query\n",
    "        self.choices = tuple(choices)\n",
    "        choices_str = ', '.join(choices)\n",
    "\n",
    "        user_prompt = (\n",
    "            \"Here is the query of interest:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            f\"The possible answers are: {choices_str}.\\n\"\n",
    "            f\"From your perspective as a {self.specialist}, first provide step-by-step reasoning (rationale), \"\n",
    "            \"and then clearly state your final answer.\\n\\n\"\n",
    "        )\n",
    "\n",
    "        class Response(BaseModel):\n",
    "            reasoning: str = Field(..., description=\"Step-by-step reasoning leading to the final choice\")\n",
    "            choice: Literal[self.choices] = Field(..., description=\"Final choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": Response.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"[{self.specialist}] analyze_query response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "    \n",
    "    async def debate(self, agents: Dict[str, Any]):\n",
    "        logger.info(f\"[{self.specialist}] Debating with other specialists.\")\n",
    "        other_specialists = {}\n",
    "        for name, value in agents.items():\n",
    "            if name != self.specialist:\n",
    "                other_specialists[name] = value\n",
    "\n",
    "        formatted_other_specialists = json.dumps(other_specialists, indent=4)\n",
    "        user_prompt = (\n",
    "            \"Regarding the previous query, other specialists have also provided their reasoning and choices.\\n\"\n",
    "            \"Critically evaluate the reasoning and choice of those specialists.\\n\\n\"\n",
    "            f\"Specialists and their choices:\\n{formatted_other_specialists}\\n\\n\"\n",
    "            \"Considering the newly provided perspectives, refine your own reasoning and choice.\\n\"\n",
    "            \"You can change your choice or stick with the original one.\\n\\n\"\n",
    "        )\n",
    "\n",
    "        class Response(BaseModel):\n",
    "            reasoning: str = Field(..., description=\"Step-by-step reasoning leading to final choice\")\n",
    "            choice: Literal[self.choices] = Field(..., description=\"Final choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": Response.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"[{self.specialist}] debate response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "class AggregatorAgent(LLMAgent):\n",
    "    def __init__(self):\n",
    "        system_prompt = (\n",
    "            \"You are the aggregator agent in a multi-agent AI system for medical queries.\\n\"\n",
    "            \"You have access to each specialist's entire chat history.\\n\"\n",
    "            \"Your job is to read those full conversations, analyze their reasoning and any conflicts, \"\n",
    "            \"and then provide a single, definitive answer to the user.\\n\"\n",
    "            \"Provide a clear explanation for your final conclusion.\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def aggregate(self, query: str, choices: List[str], specialists_chat_history: Dict[str, Any]):\n",
    "        logger.info(\"AggregatorAgent: Aggregating final answer from all specialists' chat history.\")\n",
    "        specialists_str = json.dumps(specialists_chat_history, indent=4)\n",
    "\n",
    "        user_prompt = (\n",
    "            f\"Here is the query of interest:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            \"Below is the *entire conversation history* for each specialist:\\n\\n\"\n",
    "            f\"{specialists_str}\\n\\n\"\n",
    "            \"Please review all these conversations in detail and produce one single, definitive final answer. \"\n",
    "            \"If there is no unanimous or majority choice, choose the answer best supported by the specialists' reasoning. \"\n",
    "            \"Clearly justify your reasoning, then provide your final recommended answer.\"\n",
    "        )\n",
    "\n",
    "        class AggregatedResponse(BaseModel):\n",
    "            aggregated_reasoning: str = Field(..., description=\"Detailed reasoning behind final choice\")\n",
    "            aggregated_choice: Literal[tuple(choices)] = Field(..., description=\"Single recommended choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": AggregatedResponse.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"AggregatorAgent response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "def check_consensus(status_dict: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Returns the consensus choice if >= 80% of specialists agree, else returns None.\n",
    "    \"\"\"\n",
    "    logger.info(\"Checking for consensus among specialists.\")\n",
    "    specialists_count = len(status_dict)\n",
    "    consensus_threshold = math.ceil(0.8 * specialists_count)\n",
    "\n",
    "    choice_counts = {}\n",
    "    for _, specialist_data in status_dict.items():\n",
    "        final_choice = specialist_data['response_after_debate']['choice']\n",
    "        choice_counts[final_choice] = choice_counts.get(final_choice, 0) + 1\n",
    "\n",
    "    for choice, count in choice_counts.items():\n",
    "        if count >= consensus_threshold:\n",
    "            logger.info(f\"Consensus found on choice '{choice}' with {count}/{specialists_count} specialists.\")\n",
    "            return choice\n",
    "    logger.info(\"No consensus found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 3) PROCESS A SINGLE ROW/QUERY\n",
    "# --------------------------------\n",
    "async def process_single_query(\n",
    "    question_text: str,\n",
    "    ground_truth: str,\n",
    "    choices: List[str],\n",
    "    n_specialists: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Given a single query (question + ground_truth + multiple choices), \n",
    "    run the multi-agent system (Initializer -> Specialists -> Debates -> Aggregator if needed).\n",
    "    Return the final dictionary containing all the specialists' output and aggregator results.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Initialize specialists\n",
    "    initializer = InitializerAgent(n_specialists=n_specialists)\n",
    "    json_resp = await initializer.identify_specialists(query=question_text)\n",
    "    if not isinstance(json_resp, dict):\n",
    "        logger.error(\"Invalid JSON output from initializer; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # Build specialists status dict\n",
    "    specialists_status = {}\n",
    "    for _, agent_info in json_resp.items():\n",
    "        specialist_name = agent_info[\"specialist\"]\n",
    "        expertise = agent_info[\"expertise\"]\n",
    "        specialists_status[specialist_name] = {\"expertise\": expertise}\n",
    "    \n",
    "    # 2. Run analyze_query for each specialist in parallel\n",
    "    async def analyze_specialist(specialist_name: str, status: Dict[str, Any], query: str, choices: List[str]):\n",
    "        specialist_agent = SpecialistAgent(specialist=specialist_name, expertise=status[\"expertise\"])\n",
    "        status[\"instance\"] = specialist_agent\n",
    "        message = await specialist_agent.analyze_query(query=query, choices=choices)\n",
    "        if not isinstance(message, dict):\n",
    "            logger.error(f\"[{specialist_name}] Invalid JSON output from specialist; skipping this specialist.\")\n",
    "            return None\n",
    "        status[\"original_response\"] = message\n",
    "        logger.info(f\"[{specialist_name}] Completed analyze_query.\")\n",
    "        return specialist_name\n",
    "\n",
    "    analyze_tasks = [\n",
    "        asyncio.create_task(analyze_specialist(name, status, question_text, choices))\n",
    "        for name, status in specialists_status.items()\n",
    "    ]\n",
    "    analyze_results = await asyncio.gather(*analyze_tasks)\n",
    "    if any(r is None for r in analyze_results):\n",
    "        logger.error(\"At least one specialist failed; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # Build a minimal dictionary for debate (remove 'instance')\n",
    "    input_specialists_dict = {\n",
    "        specialist_name: {\n",
    "            k: v for k, v in specialist_data.items() \n",
    "            if k != \"instance\"\n",
    "        }\n",
    "        for specialist_name, specialist_data in specialists_status.items()\n",
    "    }\n",
    "\n",
    "    # 3. Debate step, also in parallel\n",
    "    async def debate_specialist(specialist_name: str, status: Dict[str, Any], specialists_dict: Dict[str, Any]):\n",
    "        specialist_agent = status[\"instance\"]\n",
    "        message = await specialist_agent.debate(specialists_dict)\n",
    "        if not isinstance(message, dict):\n",
    "            logger.error(f\"[{specialist_name}] Invalid JSON output during debate; skipping this specialist.\")\n",
    "            return None\n",
    "        status[\"response_after_debate\"] = message\n",
    "        specialists_dict[specialist_name][\"response_after_debate\"] = message\n",
    "        logger.info(f\"[{specialist_name}] Completed debate.\")\n",
    "        return specialist_name\n",
    "\n",
    "    debate_tasks = [\n",
    "        asyncio.create_task(debate_specialist(name, status, input_specialists_dict))\n",
    "        for name, status in specialists_status.items()\n",
    "    ]\n",
    "    debate_results = await asyncio.gather(*debate_tasks)\n",
    "    if any(r is None for r in debate_results):\n",
    "        logger.error(\"At least one specialist failed during debate; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # 4. Check consensus\n",
    "    consensus_choice = check_consensus(input_specialists_dict)\n",
    "    aggregator_result = None\n",
    "\n",
    "    if consensus_choice is not None:\n",
    "        logger.info(f\"Consensus reached: {consensus_choice}\")\n",
    "        input_specialists_dict[\"Aggregator\"] = {\n",
    "            \"final_choice\": consensus_choice, \n",
    "            \"final_reasoning\": \"Consensus reached\"\n",
    "        }\n",
    "    else:\n",
    "        logger.info(\"No consensus reached; enabling aggregator path...\")\n",
    "        aggregator = AggregatorAgent()\n",
    "        aggregated_response = await aggregator.aggregate(\n",
    "            query=question_text,\n",
    "            choices=choices,\n",
    "            specialists_chat_history=input_specialists_dict\n",
    "        )\n",
    "        if not isinstance(aggregated_response, dict):\n",
    "            logger.error(\"Invalid JSON output from aggregator; skipping this query.\")\n",
    "            return {}  # Skip processing and continue to the next query\n",
    "        \n",
    "        final_choice = aggregated_response['aggregated_choice']\n",
    "        final_reasoning = aggregated_response['aggregated_reasoning']\n",
    "\n",
    "        logger.info(f\"Aggregator final choice: {final_choice}\")\n",
    "        logger.info(f\"Aggregator reasoning: {final_reasoning}\")\n",
    "\n",
    "        aggregator_result = {\n",
    "            \"final_choice\": final_choice,\n",
    "            \"final_reasoning\": final_reasoning\n",
    "        }\n",
    "        input_specialists_dict[\"Aggregator\"] = aggregator_result\n",
    "\n",
    "    # Add question and ground_truth for reference\n",
    "    input_specialists_dict[\"Question\"] = question_text\n",
    "    input_specialists_dict[\"Answer\"] = ground_truth\n",
    "\n",
    "    return input_specialists_dict\n",
    "\n",
    "\n",
    "async def process_multiple_queries(\n",
    "    qa_df: pd.DataFrame,\n",
    "    choices: List[str],\n",
    "    n_specialists: int,\n",
    "    max_concurrency: int = 5\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process multiple rows (queries) in `qa_df` asynchronously.\n",
    "    Each row is passed to `process_single_query`.\n",
    "    \n",
    "    :param qa_df: DataFrame with columns [\"question\", \"choice\", \"ground_truth\"] at least.\n",
    "    :param choices: A list of all possible answer choices, e.g. [\"A\", \"B\", \"C\", \"D\", \"E\"].\n",
    "    :param n_specialists: Number of specialists to initialize for each query.\n",
    "    :param max_concurrency: Limit on how many queries to process simultaneously.\n",
    "    :return: A list of result dictionaries, one per row in `qa_df`.\n",
    "    \"\"\"\n",
    "\n",
    "    # This semaphore keeps at most `max_concurrency` tasks running at once\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "    async def run_single_query(row_idx: int, row: pd.Series):\n",
    "        \"\"\"\n",
    "        This inner function is used to call `process_single_query` with concurrency control.\n",
    "        \"\"\"\n",
    "        async with semaphore:\n",
    "            logger.info(f\"Starting row {row_idx}\")\n",
    "            question_text = row[\"question\"] + \"\\n\" + str(row[\"choice\"])\n",
    "            ground_truth = str(row[\"ground_truth\"])\n",
    "            result = await process_single_query(\n",
    "                question_text=question_text,\n",
    "                ground_truth=ground_truth,\n",
    "                choices=choices,\n",
    "                n_specialists=n_specialists\n",
    "            )\n",
    "            logger.info(f\"Finished row {row_idx}\")\n",
    "            return result\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.create_task(run_single_query(i, row))\n",
    "        for i, row in qa_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    all_results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # `all_results` is a list of return values from each `run_single_query`\n",
    "    return all_results\n",
    "\n",
    "async def main():\n",
    "\n",
    "    logger.info(\"===== MAIN START =====\")\n",
    "\n",
    "    # Example CSV loading\n",
    "    df_path = \"/home/yl3427/cylab/llm_reasoning/reasoning/data/step2_ALL.csv\"\n",
    "    qa_df = pd.read_csv(df_path, encoding=\"latin-1\")  # columns: idx, question, choice, ground_truth, qn_num\n",
    "    # qa_df = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/SOAP_5_problems.csv')\n",
    "    logger.info(\"Loaded dataframe with %d rows.\", len(qa_df))\n",
    "\n",
    "\n",
    "    ################# 'process_single_query' Example usage #################\n",
    "    results = []\n",
    "    for idx, row in qa_df.iterrows():\n",
    "        # if idx <= 10:\n",
    "        #     continue\n",
    "        logger.info(f\"Processing row index {idx}\")\n",
    "        question_text = row[\"question\"] + \"\\n\" + str(row[\"choice\"])\n",
    "        ground_truth = str(row[\"ground_truth\"])\n",
    "\n",
    "        # patient_info = str(row[\"Subjective\"]) + \"\\n\" + str(row['Objective'])\n",
    "        # question_text = f\"\"\"\n",
    "        # Based on the following patient report, does the patient have sepsis?\n",
    "\n",
    "        # {patient_info}\n",
    "        # \"\"\"\n",
    "        # ground_truth = str(row[\"terms\"])\n",
    "        \n",
    "\n",
    "        # Run the multi-agent system for this single query\n",
    "        result_dict = await process_single_query(\n",
    "            question_text=question_text,\n",
    "            ground_truth=ground_truth,\n",
    "            choices=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "            # choices=[\"Yes\", \"No\"],\n",
    "            n_specialists=5\n",
    "        )\n",
    "        # result_dict[\"File ID\"] = row[\"File ID\"]\n",
    "        result_dict[\"qn_num\"] = row[\"qn_num\"]\n",
    "\n",
    "        # Store result for later evaluation\n",
    "        results.append(result_dict)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            output_json_path = f\"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step2_{idx}.json\"\n",
    "            with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"Saved aggregated results to {output_json_path}\")\n",
    "\n",
    "    # OPTIONAL: Save results to JSON\n",
    "    output_json_path = \"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step2_final.json\"\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    logger.info(f\"Saved aggregated results to {output_json_path}\")\n",
    "\n",
    "    logger.info(\"===== MAIN END =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for name, status in specialists_status.items():\n",
    "    print(f\"Specialist: {name}\")\n",
    "    message = status[\"instance\"].messages\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are a knowledgeable and meticulous medical expert specialized in diagnosing diseases based on partial information from SOAP notes. \n",
    "You will receive either:\n",
    "1. A single-disease assessment request (“specialist” scenario), or \n",
    "2. A multiple-disease assessment request (“generalist” scenario).\n",
    "\n",
    "In the “specialist” scenario, you focus on one disease and analyze evidence within the Subjective (S) and Objective (O) sections for or against that single disease. Your final answer must be in valid JSON with:\n",
    "    {\n",
    "        \"reasoning\": \"Concise explanation of your thought process\",\n",
    "        \"diagnosis\": true_or_false\n",
    "    }\n",
    "\n",
    "In the “generalist” scenario, you must assess each disease from a given list. For each disease, identify subjective and objective evidence that supports or refutes the disease. If evidence strongly supports it, conclude the diagnosis is true; if not, conclude false. If conflicting or incomplete, offer a reasoned explanation and a likely conclusion. Your final answer must be in valid JSON with each disease as a key:\n",
    "    {\n",
    "      \"DiseaseName1\": { \"reasoning\": \"Your reasoning...\", \"diagnosis\": true_or_false },\n",
    "      \"DiseaseName2\": { \"reasoning\": \"Your reasoning...\", \"diagnosis\": true_or_false },\n",
    "      ...\n",
    "    }\n",
    "\n",
    "When reasoning, consider clinical clues like symptoms, exam findings, risk factors, and labs. Clearly and succinctly justify why each disease is likely or unlikely. If any information is missing or ambiguous, note the uncertainty and choose the most probable conclusion.\n",
    "\n",
    "Follow these instructions precisely:\n",
    "• Always return output in the exact JSON format requested (no extra fields or text).\n",
    "• Provide concise, medically sound rationale for each decision.\n",
    "\"\"\"\n",
    "\n",
    "prompt_specialist = \"\"\"\n",
    "You are a medical expert specializing in {PROBLEM}.\n",
    "\n",
    "You are provided with only the Subjective (S) and Objective (O) sections of a patient's SOAP-formatted progress note for a potential case of {PROBLEM}.\n",
    "Identify relevant clues in the subjective and objective sections that align with or argue against {PROBLEM}. If evidence strongly suggests {PROBLEM}, conclude the diagnosis is true; if not, conclude it is false. If the evidence is uncertain or conflicting, explain your reasoning and lean toward the most likely conclusion.\n",
    "\n",
    "Patient Report:\n",
    "<Subjective>\n",
    "{SUBJ}\n",
    "</Subjective>\n",
    "\n",
    "<Objective>\n",
    "{OBJ}\n",
    "</Objective>\n",
    "\n",
    "Your answer must be output as valid JSON formatted exactly as follows:\n",
    "    {{\n",
    "        \"reasoning\": \"Your reasoning here...\",\n",
    "        \"diagnosis\": true_or_false\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "prompt_generalist = \"\"\"\n",
    "You are a medical expert in diagnostic reasoning.\n",
    "\n",
    "You are provided with only the Subjective (S) and Objective (O) sections of a patient's SOAP-formatted progress note that may be relevant to one or more of the following diseases:\n",
    "{PROBLEM_LIST}\n",
    "\n",
    "The patient may have one or more of these diseases, or none at all. Evaluate each disease independently.\n",
    "Identify relevant clues in the subjective and objective sections that align with or argue against each disease. If evidence strongly suggests the disease, conclude the diagnosis is true; if not, conclude it is false. If the evidence is uncertain or conflicting, explain your reasoning and lean toward the most likely conclusion.\n",
    "\n",
    "Patient Report:\n",
    "<Subjective>\n",
    "{SUBJ}\n",
    "</Subjective>\n",
    "\n",
    "<Objective>\n",
    "{OBJ}\n",
    "</Objective>\n",
    "\n",
    "Your answer must be output as valid JSON formatted exactly as follows:\n",
    "{{\n",
    "{json_keys}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "system_instruction_mediator = \"\"\"\n",
    "You are the mediator agent in a medical multi-agent diagnostic system. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    reasoning: str = Field(..., description=\"Step-by-step reasoning leading to the final diagnosis.\")\n",
    "    diagnosis: bool = Field(..., description=\"True if patient has the disease, False otherwise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_origin, get_args, Union, Any\n",
    "\n",
    "def generate_tools_spec(*functions):\n",
    "    \"\"\"\n",
    "    Generate a list of tool definitions (function schemas) for OpenAI's tool calling.\n",
    "    \n",
    "    Each function's name, docstring, and parameters (with types and required flags)\n",
    "    are extracted to form the JSON schema as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        *functions: One or more Python function objects to document.\n",
    "    Returns:\n",
    "        List[dict]: A list of tool definition dictionaries compatible with OpenAI API.\n",
    "    \"\"\"\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    for func in functions:\n",
    "        # Basic function info\n",
    "        func_name = func.__name__\n",
    "        func_description = func.__doc__.strip() if func.__doc__ else \"\"\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            param_name = param.name\n",
    "\n",
    "            # Determine JSON schema type from annotation (if available)\n",
    "            json_type = \"string\"  # default type\n",
    "            annotation = param.annotation\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                if origin is Union:\n",
    "                    args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(args) == 1:\n",
    "                        annotation = args[0]\n",
    "                        origin = get_origin(annotation)\n",
    "                # Map to JSON type if direct or via origin for generics\n",
    "                if annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                # Handle list item types for generics like list[int]\n",
    "                if json_type == \"array\":\n",
    "                    item_type = \"string\"  # default for items\n",
    "                    args = get_args(annotation)\n",
    "                    if args:\n",
    "                        # Use first type argument for list item if present\n",
    "                        item_type = type_map.get(args[0], \"string\")\n",
    "                    properties[param_name] = {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": item_type}\n",
    "                    }\n",
    "                elif json_type == \"object\":\n",
    "                    # For dicts or unknown complex types, use object without specifics\n",
    "                    properties[param_name] = {\"type\": \"object\"}\n",
    "                else:\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "            else:\n",
    "                # No annotation, assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        # Build the tool dictionary for this function\n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        tools.append(tool_dict)\n",
    "    return tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_synonyms(problem: str) -> Optional[List[str]]: \n",
    "    \"\"\"\n",
    "    Retrieve the list of synonyms for a given problem.\n",
    "    \"\"\"\n",
    "    problem = problem.lower()\n",
    "    mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "    chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "    pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "    pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "    sepsis = [\"sepsis\", \"septic shock\"]\n",
    "    urosepsis = [\"urosepsis\"]\n",
    "    meningitis = [\"meningitis\"]\n",
    "    aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "    atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "    pancreatitis = [\"pancreatitis\"]\n",
    "    gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "    hepatitis = [\"hepatitis\", \" hep\"]\n",
    "    cholangitis = [\"cholangitis\"]\n",
    "    asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "    prob_dict = {'myocardial infarction': mi, \n",
    "                 'congestive heart failure': chf, \n",
    "                 'pulmonary embolism': pulmonary_embolism, \n",
    "                 'pulmonary hypertension': pulmonary_hypertension, \n",
    "                 'sepsis': sepsis, \n",
    "                 'urosepsis': urosepsis, \n",
    "                 'meningitis': meningitis, \n",
    "                 'acute kidney injury': aki, \n",
    "                 'acute tubular necrosis': atn, \n",
    "                 'pancreatitis': pancreatitis, \n",
    "                 'gastrointestinal bleed': gi_bleed, \n",
    "                 'hepatitis': hepatitis, \n",
    "                 'cholangitis': cholangitis, \n",
    "                 'aspiration pneumonia': asp_pneumonia}\n",
    "    result = prob_dict.get(problem, None)\n",
    "    return result\n",
    "tools = generate_tools_spec(retrieve_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the synonym for acute kidney injury?\"}\n",
    "]\n",
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")\n",
    "response = client.chat.completions.create(\n",
    "    model=client.models.list().data[0].id,\n",
    "    messages=messages,\n",
    "    temperature= 0.1,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\" #none\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(name, args):\n",
    "    if name == \"retrieve_synonyms\":\n",
    "        return retrieve_synonyms(**args)\n",
    "    \n",
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    result = str(call_function(name, args))\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"name\": name,\n",
    "        \"output\": result\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "툴콜링 됐을 때와 아닐때 모델 아웃풋 차이\n",
    "```\n",
    "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-e9f31a3069694cc69887d4e03d16b412', function=Function(arguments='{\"problem\": \"acute kidney injury\"}', name='retrieve_synonyms'), type='function')], reasoning_content=None)\n",
    "\n",
    "\n",
    "ChatCompletionMessage(content='The synonym for acute kidney injury (AKI) is acute renal failure (ARF).', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], reasoning_content=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=client.models.list().data[0].id,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, client: OpenAI):\n",
    "        self.client = client\n",
    "\n",
    "    def get_response(\n",
    "        self, \n",
    "        messages: List[Dict], \n",
    "        temperature: Optional[float] = 0.1,\n",
    "        guided_: Optional[dict] = None, # {\"guided_json\": json_schema}, {\"guided_choice\": [\"positive\", \"negative\"]}\n",
    "        tools: Optional[List[Dict]] = None\n",
    "    ):\n",
    "        try:\n",
    "            request_params = {\n",
    "                \"model\": self.client.models.list().data[0].id,\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": temperature,\n",
    "            }\n",
    "            if guided_:\n",
    "                request_params[\"extra_body\"] = guided_\n",
    "            if tools:\n",
    "                request_params[\"tools\"] = tools\n",
    "\n",
    "            response = self.client.chat.completions.create(**request_params)\n",
    "\n",
    "            return response.choices[0].message\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    # def test_single_prob(self, dataset: pd.DataFrame, problem: str):\n",
    "    #     pbar = tqdm(total=dataset.shape[0], desc=f\"Testing {problem}\")\n",
    "    #     for idx, row in dataset.iterrows():\n",
    "    #         subj_text = row[\"Subjective\"]\n",
    "    #         obj_text = row[\"Objective\"]\n",
    "\n",
    "    #         prompt_specialist_formatted = prompt_specialist.format(\n",
    "    #             PROBLEM=problem,\n",
    "    #             SUBJ=subj_text,\n",
    "    #             OBJ=obj_text\n",
    "    #         )\n",
    "    #         messages = [\n",
    "    #             {\"role\": \"system\", \"content\": system_instruction},\n",
    "    #             {\"role\": \"user\", \"content\": prompt_specialist_formatted}\n",
    "    #         ]\n",
    "    #         response = self.get_response(\n",
    "    #             messages,\n",
    "    #             schema= DiseaseDiagnosis.model_json_schema()\n",
    "    #         )\n",
    "    #         if response:\n",
    "    #             dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_pred_single\"] = response[\"diagnosis\"]\n",
    "    #             dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_reasoning_single\"] = response[\"reasoning\"]\n",
    "\n",
    "    #         pbar.update(1)\n",
    "    #     pbar.close()\n",
    "    #     return dataset\n",
    "    \n",
    "    # def test_multi_prob(self, dataset: pd.DataFrame, problem_lst: list):\n",
    "\n",
    "    #     problem_dict = {problem: (DiseaseDiagnosis, ...) for problem in problem_lst}\n",
    "\n",
    "    #     DynamicResponseMultiDiagnosis = create_model(\n",
    "    #                 'DynamicResponseMultiDiagnosis',\n",
    "    #                 **problem_dict\n",
    "    #             )\n",
    "\n",
    "    #     pbar = tqdm(total=dataset.shape[0], desc=\"Testing Multi-Diagnosis\")\n",
    "    #     for idx, row in dataset.iterrows():\n",
    "    #         subj_text = row[\"Subjective\"]\n",
    "    #         obj_text = row[\"Objective\"]\n",
    "\n",
    "    #         json_keys_list = [\n",
    "    #             f'  \"{disease}\": {{\"reasoning\": \"Your reasoning here...\", \"diagnosis\": true_or_false}}'\n",
    "    #             for disease in problem_lst\n",
    "    #         ]\n",
    "    #         json_keys = \",\\n\".join(json_keys_list)\n",
    "\n",
    "    #         prompt_generalist_formatted = prompt_generalist.format(\n",
    "    #             PROBLEM_LIST=\", \".join(problem_lst),\n",
    "    #             SUBJ=subj_text,\n",
    "    #             OBJ=obj_text,\n",
    "    #             json_keys=json_keys,\n",
    "    #         )\n",
    "\n",
    "    #         messages = [\n",
    "    #             {\"role\": \"system\", \"content\": system_instruction},\n",
    "    #             {\"role\": \"user\", \"content\": prompt_generalist_formatted}\n",
    "    #         ]\n",
    "\n",
    "    #         response = self.get_response(\n",
    "    #             messages,\n",
    "    #             schema=DynamicResponseMultiDiagnosis.model_json_schema()\n",
    "    #         )\n",
    "    #         if response:\n",
    "    #             for problem in problem_lst:\n",
    "    #                 dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_pred_multi\"] = response[problem][\"diagnosis\"]\n",
    "    #                 dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_reasoning_multi\"] = response[problem][\"reasoning\"]\n",
    "    #         pbar.update(1)\n",
    "    #     pbar.close()\n",
    "    #     return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")\n",
    "df = pd.read_csv(\n",
    "    '/home/yl3427/cylab/SOAP_MA/data/mergedBioNLP2023.csv',\n",
    "    usecols=['File ID', 'Subjective', 'Objective', 'Summary', 'cleaned_expanded_Summary', 'terms']\n",
    ")\n",
    "df = df.fillna('').apply(lambda x: x.str.lower())\n",
    "df['combined_summary'] = df['Summary'] + df['cleaned_expanded_Summary'] + df['terms']\n",
    "\n",
    "mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "sepsis = [\"sepsis\", \"septic shock\"]\n",
    "urosepsis = [\"urosepsis\"]\n",
    "meningitis = [\"meningitis\"]\n",
    "aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "pancreatitis = [\"pancreatitis\"]\n",
    "gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "hepatitis = [\"hepatitis\", \" hep\"]\n",
    "cholangitis = [\"cholangitis\"]\n",
    "asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "prob_dict = {'myocardial infarction': mi, \n",
    "                'congestive heart failure': chf, \n",
    "                'pulmonary embolism': pulmonary_embolism, \n",
    "                'pulmonary hypertension': pulmonary_hypertension, \n",
    "                'sepsis': sepsis, \n",
    "                'urosepsis': urosepsis, \n",
    "                'meningitis': meningitis, \n",
    "                'acute kidney injury': aki, \n",
    "                'acute tubular necrosis': atn, \n",
    "                'pancreatitis': pancreatitis, \n",
    "                'gastrointestinal bleed': gi_bleed, \n",
    "                'hepatitis': hepatitis, \n",
    "                'cholangitis': cholangitis, \n",
    "                'aspiration pneumonia': asp_pneumonia}\n",
    "\n",
    "ids = set()\n",
    "for name, lst in prob_dict.items():\n",
    "    problem_terms = lst\n",
    "    problem_terms = [term.lower() for term in problem_terms]\n",
    "\n",
    "    # Use the first term as the primary term to check in the combined summary.\n",
    "    primary_term = problem_terms[0]\n",
    "\n",
    "    # Build a regex pattern that matches any of the problem terms.\n",
    "    # pattern = '|'.join(problem_terms)\n",
    "    pattern = '|'.join(re.escape(term) for term in problem_terms)\n",
    "\n",
    "    mask = (\n",
    "        df['combined_summary'].str.contains(pattern, na=False) &\n",
    "        ~df['Subjective'].str.contains(pattern, na=False) &\n",
    "        ~df['Objective'].str.contains(pattern, na=False)\n",
    "    )\n",
    "\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    ids.update(filtered_df['File ID'])\n",
    "\n",
    "agent = Agent(client=client)\n",
    "\n",
    "df = df[df['File ID'].isin(ids)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "result_df = agent.test_multi_prob(df, list(prob_dict.keys()))\n",
    "result_df.to_csv(\"multi_result_full.csv\", index=False)\n",
    "\n",
    "for name, lst in prob_dict.items():\n",
    "    result_df = agent.test_single_prob(result_df, name)\n",
    "    result_df.to_csv(f\"single_result_{name}.csv\", index=False)\n",
    "result_df.to_csv(\"single_result_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "ï»¿idx                                                         11\n",
      "question        A 25-year-old man volunteers to participate in...\n",
      "choice                     A: , B: , C: , D: , E: , F: , G: , H: \n",
      "ground_truth                                                    H\n",
      "qn_num                                                         11\n",
      "Name: 10, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qa_df = pd.read_csv(\"/home/yl3427/cylab/llm_reasoning/reasoning/data/step1_ALL.csv\", encoding=\"latin-1\")\n",
    "print(len(qa_df))\n",
    "for idx, row in qa_df.iterrows():\n",
    "    if idx == 10:\n",
    "        # print(row['question'] + \"\\n\" + str(row['choice']))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿idx</th>\n",
       "      <th>question</th>\n",
       "      <th>choice</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>qn_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Serum LDL-cholesterol concentrations are measu...</td>\n",
       "      <td>A: 105-155, B: 120-140, C: 125-135, D: 128-132...</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A 48-year-old man dies suddenly of a cardiac a...</td>\n",
       "      <td>A. Acute inflammation, B. Fibrinous exudate, C...</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>In a sample of 100 individuals, the mean leuko...</td>\n",
       "      <td>A: 5500-9500/mm3, B: &lt;6500/mm3 or &gt;8500/mm3, C...</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A 55-year-old woman comes to the clinic becaus...</td>\n",
       "      <td>A: Candida albicans, B: Chlamydia trachomatis,...</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A 39-year-old man comes to the physician becau...</td>\n",
       "      <td>A: Asthma, B: Bronchiectasis, C: Chronic pulmo...</td>\n",
       "      <td>E</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>A 15-year-old boy is brought to the office by ...</td>\n",
       "      <td>A: Cytomegalovirus, B: Epstein-Barr virus, C: ...</td>\n",
       "      <td>B</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>A 14-year-old boy is brought to the emergency ...</td>\n",
       "      <td>A: BMI, B: Family history, C: Medication use, ...</td>\n",
       "      <td>A</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>A 38-year-old woman comes to the clinic to dis...</td>\n",
       "      <td>A: \"As the patient, you really should make any...</td>\n",
       "      <td>B</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>A 36-year-old woman with hypertension comes to...</td>\n",
       "      <td>A: Fetal lung/epithelial differentiation, B: F...</td>\n",
       "      <td>C</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>A 25-year-old woman, gravida 1, para 1, comes ...</td>\n",
       "      <td>A: Activation of mutations of TSH receptors, B...</td>\n",
       "      <td>D</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ï»¿idx                                           question  \\\n",
       "0         1  Serum LDL-cholesterol concentrations are measu...   \n",
       "1         2  A 48-year-old man dies suddenly of a cardiac a...   \n",
       "2         3  In a sample of 100 individuals, the mean leuko...   \n",
       "3         4  A 55-year-old woman comes to the clinic becaus...   \n",
       "4         5  A 39-year-old man comes to the physician becau...   \n",
       "..      ...                                                ...   \n",
       "114     115  A 15-year-old boy is brought to the office by ...   \n",
       "115     116  A 14-year-old boy is brought to the emergency ...   \n",
       "116     117  A 38-year-old woman comes to the clinic to dis...   \n",
       "117     118  A 36-year-old woman with hypertension comes to...   \n",
       "118     119  A 25-year-old woman, gravida 1, para 1, comes ...   \n",
       "\n",
       "                                                choice ground_truth  qn_num  \n",
       "0    A: 105-155, B: 120-140, C: 125-135, D: 128-132...            B       1  \n",
       "1    A. Acute inflammation, B. Fibrinous exudate, C...            E       2  \n",
       "2    A: 5500-9500/mm3, B: <6500/mm3 or >8500/mm3, C...            D       3  \n",
       "3    A: Candida albicans, B: Chlamydia trachomatis,...            A       4  \n",
       "4    A: Asthma, B: Bronchiectasis, C: Chronic pulmo...            E       5  \n",
       "..                                                 ...          ...     ...  \n",
       "114  A: Cytomegalovirus, B: Epstein-Barr virus, C: ...            B     115  \n",
       "115  A: BMI, B: Family history, C: Medication use, ...            A     116  \n",
       "116  A: \"As the patient, you really should make any...            B     117  \n",
       "117  A: Fetal lung/epithelial differentiation, B: F...            C     118  \n",
       "118  A: Activation of mutations of TSH receptors, B...            D     119  \n",
       "\n",
       "[119 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
