{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 07:41:20 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-11 07:41:20 - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import re\n",
    "from typing import Optional, Union, List, get_origin, get_args, Any, Dict, Literal\n",
    "import inspect\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import math\n",
    "import demjson3\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        handlers=[\n",
    "        logging.FileHandler('TNM_test.log', mode='w'),  # Write to file\n",
    "        logging.StreamHandler()                     # Print to console\n",
    "    ]\n",
    ")\n",
    "from MA_async import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_load(s: str) -> Any:\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string using the standard json.loads.\n",
    "    If that fails (e.g. due to an unterminated string), it will try using\n",
    "    a more forgiving parser (demjson3). If both attempts fail,\n",
    "    the original string is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(\"Standard json.loads failed: %s\", e)\n",
    "        try:\n",
    "            logger.info(\"Attempting to parse with demjson3 as fallback.\")\n",
    "            result = demjson3.decode(s)\n",
    "            logger.info(\"demjson3 successfully parsed the JSON.\")\n",
    "            return result\n",
    "        except Exception as e2:\n",
    "            logger.error(\"Fallback parsing with demjson3 also failed: %s. Returning original input.\", e2)\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tools_spec(*functions):\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    for func in functions:\n",
    "        # Basic function info\n",
    "        func_name = func.__name__\n",
    "        func_description = func.__doc__.strip() if func.__doc__ else \"\"\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            param_name = param.name\n",
    "\n",
    "            # Determine JSON schema type from annotation (if available)\n",
    "            json_type = \"string\"  # default type\n",
    "            annotation = param.annotation\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                if origin is Union:\n",
    "                    args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(args) == 1:\n",
    "                        annotation = args[0]\n",
    "                        origin = get_origin(annotation)\n",
    "                # Map to JSON type if direct or via origin for generics\n",
    "                if annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                # Handle list item types for generics like list[int]\n",
    "                if json_type == \"array\":\n",
    "                    item_type = \"string\"  # default for items\n",
    "                    args = get_args(annotation)\n",
    "                    if args:\n",
    "                        # Use first type argument for list item if present\n",
    "                        item_type = type_map.get(args[0], \"string\")\n",
    "                    properties[param_name] = {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": item_type}\n",
    "                    }\n",
    "                elif json_type == \"object\":\n",
    "                    # For dicts or unknown complex types, use object without specifics\n",
    "                    properties[param_name] = {\"type\": \"object\"}\n",
    "                else:\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "            else:\n",
    "                # No annotation, assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        # Build the tool dictionary for this function\n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        tools.append(tool_dict)\n",
    "    return tools\n",
    "\n",
    "def provide_final_prediction(reasoning: str, prediction: Literal[\"T1\", \"T2\", \"T3\", \"T4\"]) -> str:\n",
    "    \"\"\"\n",
    "    Returns an answer string with reasoning and final prediction.\n",
    "    Args:\n",
    "        reasoning: A step-by-step explanation for how you arrived at the predicted T stage.\n",
    "        prediction: The final predicted T stage (T1, T2, T3, or T4).\n",
    "    \"\"\"\n",
    "    answer = f\"\"\"\n",
    "    Reasoning: {reasoning}\n",
    "    Final prediction: {prediction}\n",
    "    \"\"\"\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_ajcc_criteria(\n",
    "    cancer_type: str,\n",
    "    staging_category: Literal[\"T\", \"N\", \"M\"]\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the AJCC staging criteria for a given cancer type and staging category.\n",
    "    Args:\n",
    "        cancer_type (str): The type of cancer (e.g., \"lung\", \"breast\").\n",
    "        staging_category (Literal[\"T\", \"N\", \"M\"]): \"T\" for tumor, \"N\" for regional lymph nodes, or \"M\" for distant metastasis.\n",
    "    \"\"\"\n",
    "    sample_data = {\n",
    "        \"T\": {\n",
    "            \"T1\": {\"max_size_cm\": 2, \"description\": \"Tumor ≤2 cm\"},\n",
    "            \"T2\": {\"min_size_cm\": 2, \"max_size_cm\": 5, \"description\": \"Tumor >2 cm but ≤5 cm\"},\n",
    "            \"T3\": {\"min_size_cm\": 5, \"description\": \"Tumor >5 cm\"}\n",
    "        },\n",
    "        \"N\": {\n",
    "            \"N0\": {\"description\": \"No regional lymph node metastasis\"},\n",
    "            \"N1\": {\"description\": \"Metastasis to 1-3 lymph nodes\"},\n",
    "            \"N2\": {\"description\": \"Metastasis to 4 or more lymph nodes\"}\n",
    "        },\n",
    "        \"M\": {\n",
    "            \"M0\": {\"description\": \"No distant metastasis\"},\n",
    "            \"M1\": {\"description\": \"Distant metastasis present\"}\n",
    "        }\n",
    "    }\n",
    "    return sample_data.get(staging_category, {})\n",
    "\n",
    "def extract_information(\n",
    "    info_to_extract: list[str]\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extracts relevent information for cancer staging from a pathology report.\n",
    "    Args:\n",
    "        items_to_extract (list[str]): A list of information fields to be extracted (e.g. [\"tumor_size\", \"depth_of_invasion\", ... etc]).\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    return results\n",
    "\n",
    "def compare_numerical_values(\n",
    "    value: float,\n",
    "    min_value: float = None,\n",
    "    max_value: float = None,\n",
    "    inclusive_min: bool = True,\n",
    "    inclusive_max: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Compares a given numeric value against optional minimum and maximum thresholds.\n",
    "    Args:\n",
    "        value (float): The numeric value to compare.\n",
    "        min_value (float, optional): The lower threshold. \n",
    "                                     If None, no lower bound check is performed.\n",
    "        max_value (float, optional): The upper threshold. \n",
    "                                     If None, no upper bound check is performed.\n",
    "        inclusive_min (bool): Whether the comparison with min_value \n",
    "                              should be inclusive (value >= min_value) \n",
    "                              or exclusive (value > min_value).\n",
    "        inclusive_max (bool): Whether the comparison with max_value \n",
    "                              should be inclusive (value <= max_value) \n",
    "                              or exclusive (value < max_value).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the value satisfies all specified boundary conditions; \n",
    "              False otherwise.\n",
    "\n",
    "    Examples:\n",
    "        compare_numerical_values(3.2, min_value=2, max_value=5) \n",
    "            -> True (assuming inclusive checks)\n",
    "        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\n",
    "            -> False, since 2 is not strictly > 2\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        if inclusive_min:\n",
    "            if value < min_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value <= min_value:\n",
    "                return False\n",
    "\n",
    "    if max_value is not None:\n",
    "        if inclusive_max:\n",
    "            if value > max_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value >= max_value:\n",
    "                return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tools = {\n",
    "    \"retrieve_ajcc_criteria\": retrieve_ajcc_criteria,\n",
    "    \"extract_information\": extract_information,\n",
    "    \"compare_numerical_values\": compare_numerical_values,\n",
    "    \"provide_final_prediction\": provide_final_prediction\n",
    "}\n",
    "tools = generate_tools_spec(*available_tools.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'retrieve_ajcc_criteria',\n",
       "   'description': 'Retrieves the AJCC staging criteria for a given cancer type and staging category.\\n    Args:\\n        cancer_type (str): The type of cancer (e.g., \"lung\", \"breast\").\\n        staging_category (Literal[\"T\", \"N\", \"M\"]): \"T\" for tumor, \"N\" for regional lymph nodes, or \"M\" for distant metastasis.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'cancer_type': {'type': 'string'},\n",
       "     'staging_category': {'type': 'string'}},\n",
       "    'required': ['cancer_type', 'staging_category']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'extract_information',\n",
       "   'description': 'Extracts relevent information for cancer staging from a pathology report.\\n    Args:\\n        items_to_extract (list[str]): A list of information fields to be extracted (e.g. [\"tumor_size\", \"depth_of_invasion\", ... etc]).',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'info_to_extract': {'type': 'array',\n",
       "      'items': {'type': 'string'}}},\n",
       "    'required': ['info_to_extract']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'compare_numerical_values',\n",
       "   'description': 'Compares a given numeric value against optional minimum and maximum thresholds.\\n    Args:\\n        value (float): The numeric value to compare.\\n        min_value (float, optional): The lower threshold. \\n                                     If None, no lower bound check is performed.\\n        max_value (float, optional): The upper threshold. \\n                                     If None, no upper bound check is performed.\\n        inclusive_min (bool): Whether the comparison with min_value \\n                              should be inclusive (value >= min_value) \\n                              or exclusive (value > min_value).\\n        inclusive_max (bool): Whether the comparison with max_value \\n                              should be inclusive (value <= max_value) \\n                              or exclusive (value < max_value).\\n\\n    Returns:\\n        bool: True if the value satisfies all specified boundary conditions; \\n              False otherwise.\\n\\n    Examples:\\n        compare_numerical_values(3.2, min_value=2, max_value=5) \\n            -> True (assuming inclusive checks)\\n        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\\n            -> False, since 2 is not strictly > 2',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'value': {'type': 'number'},\n",
       "     'min_value': {'type': 'number'},\n",
       "     'max_value': {'type': 'number'},\n",
       "     'inclusive_min': {'type': 'boolean'},\n",
       "     'inclusive_max': {'type': 'boolean'}},\n",
       "    'required': ['value']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'provide_final_prediction',\n",
       "   'description': 'Returns an answer string with reasoning and final prediction.\\n    Args:\\n        reasoning: A step-by-step explanation for how you arrived at the predicted T stage.\\n        prediction: The final predicted T stage (T1, T2, T3, or T4).',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'reasoning': {'type': 'string'},\n",
       "     'prediction': {'type': 'string'}},\n",
       "    'required': ['reasoning', 'prediction']}}}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guided_json': {'properties': {'reasoning': {'description': 'A step-by-step explanation for how you arrived at the predicted T stage.',\n",
       "    'title': 'Reasoning',\n",
       "    'type': 'string'},\n",
       "   'stage': {'description': 'The final predicted T stage (T1, T2, T3, or T4).',\n",
       "    'enum': ['T1', 'T2', 'T3', 'T4'],\n",
       "    'title': 'Stage',\n",
       "    'type': 'string'}},\n",
       "  'required': ['reasoning', 'stage'],\n",
       "  'title': 'ResponseStage',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResponseStage(BaseModel):\n",
    "    reasoning: str = Field(\n",
    "        description=\"A step-by-step explanation for how you arrived at the predicted T stage.\"\n",
    "    )\n",
    "    stage: Literal[\"T1\", \"T2\", \"T3\", \"T4\"] = Field(\n",
    "        description=\"The final predicted T stage (T1, T2, T3, or T4).\"\n",
    "    )\n",
    "{\"guided_json\": ResponseStage.model_json_schema()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'retrieve_ajcc_criteria',\n",
       "   'description': 'Retrieves the AJCC staging criteria for a given cancer type and staging category.\\n    Args:\\n        cancer_type (str): The type of cancer (e.g., \"lung\", \"breast\").\\n        staging_category (Literal[\"T\", \"N\", \"M\"]): \"T\" for tumor, \"N\" for regional lymph nodes, or \"M\" for distant metastasis.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'cancer_type': {'type': 'string'},\n",
       "     'staging_category': {'type': 'string'}},\n",
       "    'required': ['cancer_type', 'staging_category']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'extract_information',\n",
       "   'description': 'Extracts relevent information for cancer staging from a pathology report.\\n    Args:\\n        items_to_extract (list[str]): A list of information fields to be extracted (e.g. [\"tumor_size\", \"depth_of_invasion\", ... etc]).',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'info_to_extract': {'type': 'array',\n",
       "      'items': {'type': 'string'}}},\n",
       "    'required': ['info_to_extract']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'compare_numerical_values',\n",
       "   'description': 'Compares a given numeric value against optional minimum and maximum thresholds.\\n    Args:\\n        value (float): The numeric value to compare.\\n        min_value (float, optional): The lower threshold. \\n                                     If None, no lower bound check is performed.\\n        max_value (float, optional): The upper threshold. \\n                                     If None, no upper bound check is performed.\\n        inclusive_min (bool): Whether the comparison with min_value \\n                              should be inclusive (value >= min_value) \\n                              or exclusive (value > min_value).\\n        inclusive_max (bool): Whether the comparison with max_value \\n                              should be inclusive (value <= max_value) \\n                              or exclusive (value < max_value).\\n\\n    Returns:\\n        bool: True if the value satisfies all specified boundary conditions; \\n              False otherwise.\\n\\n    Examples:\\n        compare_numerical_values(3.2, min_value=2, max_value=5) \\n            -> True (assuming inclusive checks)\\n        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\\n            -> False, since 2 is not strictly > 2',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'value': {'type': 'number'},\n",
       "     'min_value': {'type': 'number'},\n",
       "     'max_value': {'type': 'number'},\n",
       "     'inclusive_min': {'type': 'boolean'},\n",
       "     'inclusive_max': {'type': 'boolean'}},\n",
       "    'required': ['value']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'provide_final_prediction',\n",
       "   'description': 'Returns an answer string with reasoning and final prediction.\\n    Args:\\n        reasoning: A step-by-step explanation for how you arrived at the predicted T stage.\\n        prediction: The final predicted T stage (T1, T2, T3, or T4).',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'reasoning': {'type': 'string'},\n",
       "     'prediction': {'type': 'string'}},\n",
       "    'required': ['reasoning', 'prediction']}}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \\\n",
    "\"\"\"You are an AI agent specialized in accurately determining the pathologic T stage (T1, T2, T3, or T4) for breast cancer, according to the AJCC Cancer Staging Manual (7th edition). \n",
    "You have access to multiple tools to help extract and interpret relevant information from pathology reports. Your task is to identify the appropriate tools and plan a logical sequence of actions to achieve correct staging.\"\"\"\n",
    "\n",
    "user_prompt = \\\n",
    "\"\"\"Here is the pathology report for a breast cancer patient:\n",
    "\n",
    "<Pathology Report>\n",
    "{report}\n",
    "</Pathology Report>\n",
    "\n",
    "List clearly:\n",
    "1. Which tools you would use.\n",
    "2. The exact sequence in which you would use them.\n",
    "3. Briefly explain why you chose this sequence.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"\"\"You are an AI assistant specialized in determining the T stage of breast cancer following the AJCC Cancer Staging Manual (7th edition).\n",
    "\n",
    "# You have access to multiple tools to assist your reasoning if needed. \n",
    "\n",
    "# **Important Requirements**:\n",
    "# - Use the above tools whenever you need additional information, staging criteria, or numeric comparisons.\n",
    "# You must provide your final T stage by calling the provide_final_prediction function with two arguments:\n",
    "# 1) reasoning: an explanation of how you arrived at the stage,\n",
    "# 2) prediction: one of T1, T2, T3, or T4.\n",
    "# \"\"\"\n",
    "# user_prompt = \"\"\"You are provided with a pathology report of a breast cancer patient. Please review the report carefully and determine the pathologic T stage (T1, T2, T3, or T4) according to the AJCC Cancer Staging Manual (7th edition).\n",
    "\n",
    "# <Pathology Report>\n",
    "# {report}\n",
    "# </Pathology Report>\n",
    "\n",
    "# **Important Requirements**:\n",
    "# 1. If you need any additional information or calculations, call the appropriate tool.\n",
    "# 2. Conclude by calling the provide_final_prediction function with your reasoning and your final T stage.\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FINAL PATHOLOGIC DIAGNOSIS. A. Lymph node, sentinel #1, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). - Biopsy site changes identified. B. Lymph node, sentinel #2, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). C. Lymph node, sentinel #3, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). D. Lymph node, sentinel #4, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). E. Breast, right, partial mastectomy: - Invasive lobular carcinoma, see breast pathologic. parameters. - Margins of excision free of tumor, distance to the closest margin >2 mm. to superior and anterior. - Lobular intraepithelial neoplasia (LCIS), classic type. - Atypical ductal hyperplasia. - Previous biopsy site identified with extensive fat necrosis. - Flat epithelial atypia, focally associated with microcalcifications. - Sclerosing adenosis, focally associated with microcalcifications. - Microcalcifications in benign ductal and stroma. - Fibrocystic changes with cystic apocrine metaplasia. F. Breast, additional superior medial margin, excision: - Focal atypical ductal hyperplasia. - Lobular intraepithelial neoplasia (ALH/LCIS). - Focal flat epithelial atypia. to Sclerosing adenosis focally associated with microcalcifications. - Microcalcifications in benign ductules and stroma. - Fibrocystic changes with cystic apocrine metaplasia. - Duct ectasia. Breast Pathologic Parameters. Specimen E: Breast, right, partial mastectomy. 1. Invasive carcinoma: A. Size: Gross measurement: 1.6 x 1.5 X 1.4 cm. B. Composite histologic (modified SBR) grade II. - Architecture: 3. - Nuclear grade: 2. - Mitotic count: 1. C. Associated lobular intraepithelial neoplasia (LCIS): - Within main mass (forming <5% of tumor volume). - Extending away from main mass. 3. Excisional biopsy margins: Free of tumor. - Invasive carcinoma > 2 mm from anterior and superior margins. - Additional margins greater than 3 mm away. 4. Blood vessel and lymphatic invasion: Not definitively identified. 5. Axillary lymph nodes: Negative for tumor (0/4). 6. Special studies (see. - Strong expression of ER in 90% of invasive tumor nuclei. - Strong expression of PR in 50% of invasive tumor nuclei. - Her2/neu antigen (FISH) Not amplified. Ratio 1.5. 7. pTNM: pT1c, NO(sn), MX. Clinical History: The patient is an. year old female with a history of biopsy proven grade Il. ILC of the right breast who undergoes right breast needle localization. lumpectomy and right axillary sentinel node dissection. Most recent breast. imaging on. showed in the right breast at the 10 o' clock position an. irregularly shaped heterogenous enhancing mass with irregular margins and. metallic clip artifact at mid depth measuring 1.4 X 1.2 X 1.2 cm representing. the biopsy proven malignant lesion. Posterior to that main mass was a focal. non-mass like enhancement measuring 1.6 x 1.1 cm suspicious for extension of the. disease with a total extent of 2.8 cm. Comment. Part E: The tumor reveals a mixed ductal and lobular morphologic appearance,. however, immunohistochemical stains for E-cadherin were performed on. representative areas and supports the presence of a lobular carcinoma. Case presented at multidisciplinary breast conference on. Specimens Received: A: Right axillary sentinel node#1. B: Right axillary sentinel node #2. C: Right axillary sentinel node #3. D: Right axillary sentinel node #4. E: Right breast partial mastectomy. F: Additional superior medial margin. Gross Description: The specimen is received in six containers each labeled with the patient' S name. and medical record number. A. Container A is further designated as 1. Right axillary sentinel node #1.'. Received fresh and placed in formalin is a 1.5 x 1.2 x 1.0 cm firm, rubbery. lymph node that is dissected and entirely submitted in cassette A1. B. Container B is further designated as 2. Right axillary sentinel node #2. Received fresh and placed in formalin is a 0.7 X 0.6 X 0.4 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette B1. C. Container C is further designated as '3. Right axillary sentinel node #3.'. Received fresh and placed in formalin is a 0.9 X 0,7 X 0.4 cm tan, rubbery lymph. node candidate. It is entirely submitted in cassette C1. D. Container D is further designated as 14. Right axillary sentinel node #4. Received fresh and placed in formalin is a 0.6 x 0.5 x 0.2 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette D1. E. Container E is further designated as '5. Right breast partial mastectomy'. with the paper work additionally designating 1 stitch = lateral. Received fresh. and placed in formalin is a 99.5 gram, 8.5 cm (superior to inferior) X 10.0 cm. (medial to lateral) X 3.5 cm (anterior to posterior) breast lumpectomy specimen. on a radiographic grid with a corresponding x-ray film. There is a metallic. clip located in the center of a spiculated irregularly shaped mass which. corresponds to C3-C4, D3-D4 and D5. The metallic clip is located in D4. There. is a questionable extension of the mass into grids E3-E4. A wire extends through. the center of this mass entering at B5 and terminating at F1. The specimen is. received with two sutures, long designating lateral and short designating. superior. The margins are inked as follows: superior blue, inferior green,. anterior black, posterior red, lateral violet and medial yellow. The. specimen is serially sectioned from lateral to medial into 14 slices to reveal a. 1.6 X 1.5 X 1.4 cm firm, white poorly circumscribed mass extending from slice 6. to slice 9. There is a metallic clip found on the center of this mass in slice. 8. The mass approaches the anterior margin within 0.3 cm (slice 9) and the. posterior margin within 0.6 cm (slice 7). Additionally, the lesion is 3.5 cm. from the inferior margin and 0.7 cm from the superior margin. The mass is. greater than 2 cm from both the medial and lateral margins. The wire terminates. in slice 11. The remainder of the breast tissue consists of grossly. unremarkable yellow, lobulated adipose tissue. Representative sections are. submitted as follows: E1: mass with clip (slice 8) showing approach to posterior and superior margins. E2-E3: anterior margin from slice 8. E4-E5: mass in slice 7 showing closest approach to posterior margin. E6-E7: mass in slice 6 demonstrating biopsy site changes. E8: inferior margin from slice 6. E9-E10: mass in slice 10 showing nearest approach to anterior margin. E11: posterior margin slice 7. E12-E13: posterior inferior margin slice 8. E14: posterior margin slice 9. E15: anterior margin slice 9. E16: anterior margin slice 8. E17: anterior superior margin slice 6. E18-E20: sections immediately lateral to mass (slice 5). E21-E22: sections immediately medial to mass (slice 10). E23: grossly unremarkable breast parenchyma slice 3. E24: grossly unremarkable breast parenchyma slice 12. E25: lateral margin serially sectioned (slice 1). E26: medial margin serially sectioned (slice 14). F.Container F is further designated as '3. Additionalsuperior medial margin,. short stitch marks new true margin.' Received fresh is a 38.0 gram portion of. yellow, lobulated fibroadipose tissue that measures 8.5 X 6.0 X 1.5 cm. The. short stitch designates the new true margin. This aspect is inked blue. The. specimen does not have any further orientation. The specimen is serially. sectioned to reveal that is primarily composed of yellow, lobulated adipose. tissue with a region of enhanced firm, white fibrosis measuring 2.4 X 1.5 X 1.5. cm that appears to abut the new true margin. The specimen is entirely submitted. sequentially in cassettes F1-F23 with the fibrotic region in F9-F14. Pathologist Sign Out:\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result_breast/results_t_stage_run_2.csv\")[[\"patient_filename\", \"t\", \"text\"]]\n",
    "df.iloc[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 10:28:18 - INFO - Loaded dataframe with 1031 rows.\n",
      "2025-03-11 10:28:18 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2025-03-11 10:28:18 - DEBUG - load_verify_locations cafile='/usr/lib/ssl/certs/ca-certificates.crt'\n",
      "2025-03-11 10:28:18 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are an AI agent specialized in accurately determining the pathologic T stage (T1, T2, T3, or T4) for breast cancer, according to the AJCC Cancer Staging Manual (7th edition). \\nYou have access to multiple tools to help extract and interpret relevant information from pathology reports. Your task is to identify the appropriate tools and plan a logical sequence of actions to achieve correct staging.'}, {'role': 'user', 'content': \"Here is the pathology report for a breast cancer patient:\\n\\n<Pathology Report>\\nFINAL PATHOLOGIC DIAGNOSIS. A. Lymph node, sentinel #1, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). - Biopsy site changes identified. B. Lymph node, sentinel #2, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). C. Lymph node, sentinel #3, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). D. Lymph node, sentinel #4, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). E. Breast, right, partial mastectomy: - Invasive lobular carcinoma, see breast pathologic. parameters. - Margins of excision free of tumor, distance to the closest margin >2 mm. to superior and anterior. - Lobular intraepithelial neoplasia (LCIS), classic type. - Atypical ductal hyperplasia. - Previous biopsy site identified with extensive fat necrosis. - Flat epithelial atypia, focally associated with microcalcifications. - Sclerosing adenosis, focally associated with microcalcifications. - Microcalcifications in benign ductal and stroma. - Fibrocystic changes with cystic apocrine metaplasia. F. Breast, additional superior medial margin, excision: - Focal atypical ductal hyperplasia. - Lobular intraepithelial neoplasia (ALH/LCIS). - Focal flat epithelial atypia. to Sclerosing adenosis focally associated with microcalcifications. - Microcalcifications in benign ductules and stroma. - Fibrocystic changes with cystic apocrine metaplasia. - Duct ectasia. Breast Pathologic Parameters. Specimen E: Breast, right, partial mastectomy. 1. Invasive carcinoma: A. Size: Gross measurement: 1.6 x 1.5 X 1.4 cm. B. Composite histologic (modified SBR) grade II. - Architecture: 3. - Nuclear grade: 2. - Mitotic count: 1. C. Associated lobular intraepithelial neoplasia (LCIS): - Within main mass (forming <5% of tumor volume). - Extending away from main mass. 3. Excisional biopsy margins: Free of tumor. - Invasive carcinoma > 2 mm from anterior and superior margins. - Additional margins greater than 3 mm away. 4. Blood vessel and lymphatic invasion: Not definitively identified. 5. Axillary lymph nodes: Negative for tumor (0/4). 6. Special studies (see. - Strong expression of ER in 90% of invasive tumor nuclei. - Strong expression of PR in 50% of invasive tumor nuclei. - Her2/neu antigen (FISH) Not amplified. Ratio 1.5. 7. pTNM: pT1c, NO(sn), MX. Clinical History: The patient is an. year old female with a history of biopsy proven grade Il. ILC of the right breast who undergoes right breast needle localization. lumpectomy and right axillary sentinel node dissection. Most recent breast. imaging on. showed in the right breast at the 10 o' clock position an. irregularly shaped heterogenous enhancing mass with irregular margins and. metallic clip artifact at mid depth measuring 1.4 X 1.2 X 1.2 cm representing. the biopsy proven malignant lesion. Posterior to that main mass was a focal. non-mass like enhancement measuring 1.6 x 1.1 cm suspicious for extension of the. disease with a total extent of 2.8 cm. Comment. Part E: The tumor reveals a mixed ductal and lobular morphologic appearance,. however, immunohistochemical stains for E-cadherin were performed on. representative areas and supports the presence of a lobular carcinoma. Case presented at multidisciplinary breast conference on. Specimens Received: A: Right axillary sentinel node#1. B: Right axillary sentinel node #2. C: Right axillary sentinel node #3. D: Right axillary sentinel node #4. E: Right breast partial mastectomy. F: Additional superior medial margin. Gross Description: The specimen is received in six containers each labeled with the patient' S name. and medical record number. A. Container A is further designated as 1. Right axillary sentinel node #1.'. Received fresh and placed in formalin is a 1.5 x 1.2 x 1.0 cm firm, rubbery. lymph node that is dissected and entirely submitted in cassette A1. B. Container B is further designated as 2. Right axillary sentinel node #2. Received fresh and placed in formalin is a 0.7 X 0.6 X 0.4 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette B1. C. Container C is further designated as '3. Right axillary sentinel node #3.'. Received fresh and placed in formalin is a 0.9 X 0,7 X 0.4 cm tan, rubbery lymph. node candidate. It is entirely submitted in cassette C1. D. Container D is further designated as 14. Right axillary sentinel node #4. Received fresh and placed in formalin is a 0.6 x 0.5 x 0.2 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette D1. E. Container E is further designated as '5. Right breast partial mastectomy'. with the paper work additionally designating 1 stitch = lateral. Received fresh. and placed in formalin is a 99.5 gram, 8.5 cm (superior to inferior) X 10.0 cm. (medial to lateral) X 3.5 cm (anterior to posterior) breast lumpectomy specimen. on a radiographic grid with a corresponding x-ray film. There is a metallic. clip located in the center of a spiculated irregularly shaped mass which. corresponds to C3-C4, D3-D4 and D5. The metallic clip is located in D4. There. is a questionable extension of the mass into grids E3-E4. A wire extends through. the center of this mass entering at B5 and terminating at F1. The specimen is. received with two sutures, long designating lateral and short designating. superior. The margins are inked as follows: superior blue, inferior green,. anterior black, posterior red, lateral violet and medial yellow. The. specimen is serially sectioned from lateral to medial into 14 slices to reveal a. 1.6 X 1.5 X 1.4 cm firm, white poorly circumscribed mass extending from slice 6. to slice 9. There is a metallic clip found on the center of this mass in slice. 8. The mass approaches the anterior margin within 0.3 cm (slice 9) and the. posterior margin within 0.6 cm (slice 7). Additionally, the lesion is 3.5 cm. from the inferior margin and 0.7 cm from the superior margin. The mass is. greater than 2 cm from both the medial and lateral margins. The wire terminates. in slice 11. The remainder of the breast tissue consists of grossly. unremarkable yellow, lobulated adipose tissue. Representative sections are. submitted as follows: E1: mass with clip (slice 8) showing approach to posterior and superior margins. E2-E3: anterior margin from slice 8. E4-E5: mass in slice 7 showing closest approach to posterior margin. E6-E7: mass in slice 6 demonstrating biopsy site changes. E8: inferior margin from slice 6. E9-E10: mass in slice 10 showing nearest approach to anterior margin. E11: posterior margin slice 7. E12-E13: posterior inferior margin slice 8. E14: posterior margin slice 9. E15: anterior margin slice 9. E16: anterior margin slice 8. E17: anterior superior margin slice 6. E18-E20: sections immediately lateral to mass (slice 5). E21-E22: sections immediately medial to mass (slice 10). E23: grossly unremarkable breast parenchyma slice 3. E24: grossly unremarkable breast parenchyma slice 12. E25: lateral margin serially sectioned (slice 1). E26: medial margin serially sectioned (slice 14). F.Container F is further designated as '3. Additionalsuperior medial margin,. short stitch marks new true margin.' Received fresh is a 38.0 gram portion of. yellow, lobulated fibroadipose tissue that measures 8.5 X 6.0 X 1.5 cm. The. short stitch designates the new true margin. This aspect is inked blue. The. specimen does not have any further orientation. The specimen is serially. sectioned to reveal that is primarily composed of yellow, lobulated adipose. tissue with a region of enhanced firm, white fibrosis measuring 2.4 X 1.5 X 1.5. cm that appears to abut the new true margin. The specimen is entirely submitted. sequentially in cassettes F1-F23 with the fibrotic region in F9-F14. Pathologist Sign Out:\\n</Pathology Report>\\n\\nList clearly:\\n1. Which tools you would use.\\n2. The exact sequence in which you would use them.\\n3. Briefly explain why you chose this sequence.\"}], 'model': 'meta-llama/Llama-3.3-70B-Instruct', 'temperature': 0.4, 'tools': [{'type': 'function', 'function': {'name': 'retrieve_ajcc_criteria', 'description': 'Retrieves the AJCC staging criteria for a given cancer type and staging category.\\n    Args:\\n        cancer_type (str): The type of cancer (e.g., \"lung\", \"breast\").\\n        staging_category (Literal[\"T\", \"N\", \"M\"]): \"T\" for tumor, \"N\" for regional lymph nodes, or \"M\" for distant metastasis.', 'parameters': {'type': 'object', 'properties': {'cancer_type': {'type': 'string'}, 'staging_category': {'type': 'string'}}, 'required': ['cancer_type', 'staging_category']}}}, {'type': 'function', 'function': {'name': 'extract_information', 'description': 'Extracts relevent information for cancer staging from a pathology report.\\n    Args:\\n        items_to_extract (list[str]): A list of information fields to be extracted (e.g. [\"tumor_size\", \"depth_of_invasion\", ... etc]).', 'parameters': {'type': 'object', 'properties': {'info_to_extract': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['info_to_extract']}}}, {'type': 'function', 'function': {'name': 'compare_numerical_values', 'description': 'Compares a given numeric value against optional minimum and maximum thresholds.\\n    Args:\\n        value (float): The numeric value to compare.\\n        min_value (float, optional): The lower threshold. \\n                                     If None, no lower bound check is performed.\\n        max_value (float, optional): The upper threshold. \\n                                     If None, no upper bound check is performed.\\n        inclusive_min (bool): Whether the comparison with min_value \\n                              should be inclusive (value >= min_value) \\n                              or exclusive (value > min_value).\\n        inclusive_max (bool): Whether the comparison with max_value \\n                              should be inclusive (value <= max_value) \\n                              or exclusive (value < max_value).\\n\\n    Returns:\\n        bool: True if the value satisfies all specified boundary conditions; \\n              False otherwise.\\n\\n    Examples:\\n        compare_numerical_values(3.2, min_value=2, max_value=5) \\n            -> True (assuming inclusive checks)\\n        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\\n            -> False, since 2 is not strictly > 2', 'parameters': {'type': 'object', 'properties': {'value': {'type': 'number'}, 'min_value': {'type': 'number'}, 'max_value': {'type': 'number'}, 'inclusive_min': {'type': 'boolean'}, 'inclusive_max': {'type': 'boolean'}}, 'required': ['value']}}}, {'type': 'function', 'function': {'name': 'provide_final_prediction', 'description': 'Returns an answer string with reasoning and final prediction.\\n    Args:\\n        reasoning: A step-by-step explanation for how you arrived at the predicted T stage.\\n        prediction: The final predicted T stage (T1, T2, T3, or T4).', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string'}, 'prediction': {'type': 'string'}}, 'required': ['reasoning', 'prediction']}}}]}}\n",
      "2025-03-11 10:28:18 - DEBUG - Sending HTTP Request: POST http://localhost:8000/v1/chat/completions\n",
      "2025-03-11 10:28:18 - DEBUG - connect_tcp.started host='localhost' port=8000 local_address=None timeout=5.0 socket_options=None\n",
      "2025-03-11 10:28:18 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0f79e23790>\n",
      "2025-03-11 10:28:18 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 10:28:18 - DEBUG - send_request_headers.complete\n",
      "2025-03-11 10:28:18 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2025-03-11 10:28:18 - DEBUG - send_request_body.complete\n",
      "2025-03-11 10:28:18 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 10:29:23 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Mar 2025 10:28:18 GMT'), (b'server', b'uvicorn'), (b'content-length', b'2785'), (b'content-type', b'application/json')])\n",
      "2025-03-11 10:29:23 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-11 10:29:23 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-11 10:29:23 - DEBUG - receive_response_body.complete\n",
      "2025-03-11 10:29:23 - DEBUG - response_closed.started\n",
      "2025-03-11 10:29:23 - DEBUG - response_closed.complete\n",
      "2025-03-11 10:29:23 - DEBUG - HTTP Response: POST http://localhost:8000/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 11 Mar 2025 10:28:18 GMT', 'server': 'uvicorn', 'content-length': '2785', 'content-type': 'application/json'})\n",
      "2025-03-11 10:29:23 - DEBUG - request_id: None\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Loaded dataframe with %d rows.\", len(df))\n",
    "\n",
    "row = df.iloc[2]\n",
    "report = row[\"text\"]\n",
    "t_stage = row[\"t\"]\n",
    "formatted_user_prompt = user_prompt.format(report=report)\n",
    "\n",
    "client=OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": formatted_user_prompt}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    messages=messages,\n",
    "    temperature=0.4,\n",
    "    tools=tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 10:47:55 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are an AI agent specialized in accurately determining the pathologic T stage (T1, T2, T3, or T4) for breast cancer, according to the AJCC Cancer Staging Manual (7th edition). \\nYou have access to multiple tools to help extract and interpret relevant information from pathology reports. Your task is to identify the appropriate tools and plan a logical sequence of actions to achieve correct staging.'}, {'role': 'user', 'content': \"Here is the pathology report for a breast cancer patient:\\n\\n<Pathology Report>\\nFINAL PATHOLOGIC DIAGNOSIS. A. Lymph node, sentinel #1, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). - Biopsy site changes identified. B. Lymph node, sentinel #2, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). C. Lymph node, sentinel #3, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). D. Lymph node, sentinel #4, right axillary, excision: - One lymph node, negative for metastatic carcinoma (0/1). E. Breast, right, partial mastectomy: - Invasive lobular carcinoma, see breast pathologic. parameters. - Margins of excision free of tumor, distance to the closest margin >2 mm. to superior and anterior. - Lobular intraepithelial neoplasia (LCIS), classic type. - Atypical ductal hyperplasia. - Previous biopsy site identified with extensive fat necrosis. - Flat epithelial atypia, focally associated with microcalcifications. - Sclerosing adenosis, focally associated with microcalcifications. - Microcalcifications in benign ductal and stroma. - Fibrocystic changes with cystic apocrine metaplasia. F. Breast, additional superior medial margin, excision: - Focal atypical ductal hyperplasia. - Lobular intraepithelial neoplasia (ALH/LCIS). - Focal flat epithelial atypia. to Sclerosing adenosis focally associated with microcalcifications. - Microcalcifications in benign ductules and stroma. - Fibrocystic changes with cystic apocrine metaplasia. - Duct ectasia. Breast Pathologic Parameters. Specimen E: Breast, right, partial mastectomy. 1. Invasive carcinoma: A. Size: Gross measurement: 1.6 x 1.5 X 1.4 cm. B. Composite histologic (modified SBR) grade II. - Architecture: 3. - Nuclear grade: 2. - Mitotic count: 1. C. Associated lobular intraepithelial neoplasia (LCIS): - Within main mass (forming <5% of tumor volume). - Extending away from main mass. 3. Excisional biopsy margins: Free of tumor. - Invasive carcinoma > 2 mm from anterior and superior margins. - Additional margins greater than 3 mm away. 4. Blood vessel and lymphatic invasion: Not definitively identified. 5. Axillary lymph nodes: Negative for tumor (0/4). 6. Special studies (see. - Strong expression of ER in 90% of invasive tumor nuclei. - Strong expression of PR in 50% of invasive tumor nuclei. - Her2/neu antigen (FISH) Not amplified. Ratio 1.5. 7. pTNM: pT1c, NO(sn), MX. Clinical History: The patient is an. year old female with a history of biopsy proven grade Il. ILC of the right breast who undergoes right breast needle localization. lumpectomy and right axillary sentinel node dissection. Most recent breast. imaging on. showed in the right breast at the 10 o' clock position an. irregularly shaped heterogenous enhancing mass with irregular margins and. metallic clip artifact at mid depth measuring 1.4 X 1.2 X 1.2 cm representing. the biopsy proven malignant lesion. Posterior to that main mass was a focal. non-mass like enhancement measuring 1.6 x 1.1 cm suspicious for extension of the. disease with a total extent of 2.8 cm. Comment. Part E: The tumor reveals a mixed ductal and lobular morphologic appearance,. however, immunohistochemical stains for E-cadherin were performed on. representative areas and supports the presence of a lobular carcinoma. Case presented at multidisciplinary breast conference on. Specimens Received: A: Right axillary sentinel node#1. B: Right axillary sentinel node #2. C: Right axillary sentinel node #3. D: Right axillary sentinel node #4. E: Right breast partial mastectomy. F: Additional superior medial margin. Gross Description: The specimen is received in six containers each labeled with the patient' S name. and medical record number. A. Container A is further designated as 1. Right axillary sentinel node #1.'. Received fresh and placed in formalin is a 1.5 x 1.2 x 1.0 cm firm, rubbery. lymph node that is dissected and entirely submitted in cassette A1. B. Container B is further designated as 2. Right axillary sentinel node #2. Received fresh and placed in formalin is a 0.7 X 0.6 X 0.4 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette B1. C. Container C is further designated as '3. Right axillary sentinel node #3.'. Received fresh and placed in formalin is a 0.9 X 0,7 X 0.4 cm tan, rubbery lymph. node candidate. It is entirely submitted in cassette C1. D. Container D is further designated as 14. Right axillary sentinel node #4. Received fresh and placed in formalin is a 0.6 x 0.5 x 0.2 cm tan, rubbery lymph. node candidate that is entirely submitted in cassette D1. E. Container E is further designated as '5. Right breast partial mastectomy'. with the paper work additionally designating 1 stitch = lateral. Received fresh. and placed in formalin is a 99.5 gram, 8.5 cm (superior to inferior) X 10.0 cm. (medial to lateral) X 3.5 cm (anterior to posterior) breast lumpectomy specimen. on a radiographic grid with a corresponding x-ray film. There is a metallic. clip located in the center of a spiculated irregularly shaped mass which. corresponds to C3-C4, D3-D4 and D5. The metallic clip is located in D4. There. is a questionable extension of the mass into grids E3-E4. A wire extends through. the center of this mass entering at B5 and terminating at F1. The specimen is. received with two sutures, long designating lateral and short designating. superior. The margins are inked as follows: superior blue, inferior green,. anterior black, posterior red, lateral violet and medial yellow. The. specimen is serially sectioned from lateral to medial into 14 slices to reveal a. 1.6 X 1.5 X 1.4 cm firm, white poorly circumscribed mass extending from slice 6. to slice 9. There is a metallic clip found on the center of this mass in slice. 8. The mass approaches the anterior margin within 0.3 cm (slice 9) and the. posterior margin within 0.6 cm (slice 7). Additionally, the lesion is 3.5 cm. from the inferior margin and 0.7 cm from the superior margin. The mass is. greater than 2 cm from both the medial and lateral margins. The wire terminates. in slice 11. The remainder of the breast tissue consists of grossly. unremarkable yellow, lobulated adipose tissue. Representative sections are. submitted as follows: E1: mass with clip (slice 8) showing approach to posterior and superior margins. E2-E3: anterior margin from slice 8. E4-E5: mass in slice 7 showing closest approach to posterior margin. E6-E7: mass in slice 6 demonstrating biopsy site changes. E8: inferior margin from slice 6. E9-E10: mass in slice 10 showing nearest approach to anterior margin. E11: posterior margin slice 7. E12-E13: posterior inferior margin slice 8. E14: posterior margin slice 9. E15: anterior margin slice 9. E16: anterior margin slice 8. E17: anterior superior margin slice 6. E18-E20: sections immediately lateral to mass (slice 5). E21-E22: sections immediately medial to mass (slice 10). E23: grossly unremarkable breast parenchyma slice 3. E24: grossly unremarkable breast parenchyma slice 12. E25: lateral margin serially sectioned (slice 1). E26: medial margin serially sectioned (slice 14). F.Container F is further designated as '3. Additionalsuperior medial margin,. short stitch marks new true margin.' Received fresh is a 38.0 gram portion of. yellow, lobulated fibroadipose tissue that measures 8.5 X 6.0 X 1.5 cm. The. short stitch designates the new true margin. This aspect is inked blue. The. specimen does not have any further orientation. The specimen is serially. sectioned to reveal that is primarily composed of yellow, lobulated adipose. tissue with a region of enhanced firm, white fibrosis measuring 2.4 X 1.5 X 1.5. cm that appears to abut the new true margin. The specimen is entirely submitted. sequentially in cassettes F1-F23 with the fibrotic region in F9-F14. Pathologist Sign Out:\\n</Pathology Report>\\n\\nList clearly:\\n1. Which tools you would use.\\n2. The exact sequence in which you would use them.\\n3. Briefly explain why you chose this sequence.\"}, {'role': 'system', 'content': 'To accurately determine the pathologic T stage for breast cancer based on the provided pathology report, I would use the following tools in the specified sequence:\\n\\n### 1. Tools to Use:\\n- **Extract Information Tool:** To extract relevant information such as tumor size, depth of invasion, lymph node status, and other parameters necessary for staging.\\n- **AJCC Criteria Retrieval Tool:** To understand the specific criteria for T staging in breast cancer, which involves tumor size, extent of invasion, and other factors.\\n- **Numerical Comparison Tool:** To compare the extracted numerical values (e.g., tumor size) against the AJCC criteria thresholds for T staging.\\n- **Final Prediction Tool:** To synthesize the information and provide a final prediction of the T stage along with the reasoning.\\n\\n### 2. Sequence of Use:\\n1. **Extract Information Tool:** First, extract all relevant information from the pathology report, including tumor size (1.6 x 1.5 x 1.4 cm), lymph node status (negative), and any other details that could influence T staging.\\n2. **AJCC Criteria Retrieval Tool:** Next, retrieve the AJCC staging criteria for breast cancer to understand how tumor size, lymph node status, and other factors are used to determine the T stage.\\n3. **Numerical Comparison Tool:** Then, compare the extracted tumor size and other relevant numerical values against the AJCC criteria to determine the appropriate T stage. For example, comparing the tumor size (1.6 cm) against the size thresholds for T1 (≤2 cm), T2 (>2 cm but ≤5 cm), T3 (>5 cm), and T4 (any size with direct extension to the chest wall or skin).\\n4. **Final Prediction Tool:** Finally, use the results of the comparisons and the extracted information to predict the T stage and provide a detailed explanation of how this prediction was made.\\n\\n### 3. Rationale for Sequence:\\nThis sequence is logical because it progresses from data collection (extracting relevant information) to understanding the context and rules (retrieving AJCC criteria), applying those rules to the data (comparing numerical values), and finally synthesizing the results into a meaningful conclusion (predicting the T stage). Each step builds on the previous one, ensuring that the final prediction is well-informed and accurately reflects the pathology report and the AJCC staging criteria.'}, {'role': 'system', 'content': 'To accurately determine the pathologic T stage for breast cancer based on the provided pathology report, I would use the following tools in the specified sequence:\\n\\n### 1. Tools to Use:\\n- **Extract Information Tool:** To extract relevant information such as tumor size, depth of invasion, lymph node status, and other parameters necessary for staging.\\n- **AJCC Criteria Retrieval Tool:** To understand the specific criteria for T staging in breast cancer, which involves tumor size, extent of invasion, and other factors.\\n- **Numerical Comparison Tool:** To compare the extracted numerical values (e.g., tumor size) against the AJCC criteria thresholds for T staging.\\n- **Final Prediction Tool:** To synthesize the information and provide a final prediction of the T stage along with the reasoning.\\n\\n### 2. Sequence of Use:\\n1. **Extract Information Tool:** First, extract all relevant information from the pathology report, including tumor size (1.6 x 1.5 x 1.4 cm), lymph node status (negative), and any other details that could influence T staging.\\n2. **AJCC Criteria Retrieval Tool:** Next, retrieve the AJCC staging criteria for breast cancer to understand how tumor size, lymph node status, and other factors are used to determine the T stage.\\n3. **Numerical Comparison Tool:** Then, compare the extracted tumor size and other relevant numerical values against the AJCC criteria to determine the appropriate T stage. For example, comparing the tumor size (1.6 cm) against the size thresholds for T1 (≤2 cm), T2 (>2 cm but ≤5 cm), T3 (>5 cm), and T4 (any size with direct extension to the chest wall or skin).\\n4. **Final Prediction Tool:** Finally, use the results of the comparisons and the extracted information to predict the T stage and provide a detailed explanation of how this prediction was made.\\n\\n### 3. Rationale for Sequence:\\nThis sequence is logical because it progresses from data collection (extracting relevant information) to understanding the context and rules (retrieving AJCC criteria), applying those rules to the data (comparing numerical values), and finally synthesizing the results into a meaningful conclusion (predicting the T stage). Each step builds on the previous one, ensuring that the final prediction is well-informed and accurately reflects the pathology report and the AJCC staging criteria.'}, {'role': 'user', 'content': 'Great. Now, invoke each tool step-by-step exactly as outlined in your plan, providing the necessary arguments.\\nAfter reviewing the output of each tool, proceed to the next step.\\nBegin executing your plan now.'}, {'role': 'system', 'content': 'To begin executing the plan, I will start by invoking the **Extract Information Tool** to extract relevant information from the pathology report.\\n\\n```json\\n{\\n    \"type\": \"function\",\\n    \"name\": \"extract_information\",\\n    \"parameters\": {\\n        \"info_to_extract\": [\\n            \"tumor_size\",\\n            \"depth_of_invasion\",\\n            \"lymph_node_status\"\\n        ]\\n    }\\n}\\n```\\n\\nPlease wait for the output of this tool before proceeding to the next step.'}, {'role': 'user', 'content': 'Great. Now, call each tool step-by-step with the necessary arguments.'}], 'model': 'meta-llama/Llama-3.3-70B-Instruct', 'temperature': 0.4, 'tools': [{'type': 'function', 'function': {'name': 'retrieve_ajcc_criteria', 'description': 'Retrieves the AJCC staging criteria for a given cancer type and staging category.\\n    Args:\\n        cancer_type (str): The type of cancer (e.g., \"lung\", \"breast\").\\n        staging_category (Literal[\"T\", \"N\", \"M\"]): \"T\" for tumor, \"N\" for regional lymph nodes, or \"M\" for distant metastasis.', 'parameters': {'type': 'object', 'properties': {'cancer_type': {'type': 'string'}, 'staging_category': {'type': 'string'}}, 'required': ['cancer_type', 'staging_category']}}}, {'type': 'function', 'function': {'name': 'extract_information', 'description': 'Extracts relevent information for cancer staging from a pathology report.\\n    Args:\\n        items_to_extract (list[str]): A list of information fields to be extracted (e.g. [\"tumor_size\", \"depth_of_invasion\", ... etc]).', 'parameters': {'type': 'object', 'properties': {'info_to_extract': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['info_to_extract']}}}, {'type': 'function', 'function': {'name': 'compare_numerical_values', 'description': 'Compares a given numeric value against optional minimum and maximum thresholds.\\n    Args:\\n        value (float): The numeric value to compare.\\n        min_value (float, optional): The lower threshold. \\n                                     If None, no lower bound check is performed.\\n        max_value (float, optional): The upper threshold. \\n                                     If None, no upper bound check is performed.\\n        inclusive_min (bool): Whether the comparison with min_value \\n                              should be inclusive (value >= min_value) \\n                              or exclusive (value > min_value).\\n        inclusive_max (bool): Whether the comparison with max_value \\n                              should be inclusive (value <= max_value) \\n                              or exclusive (value < max_value).\\n\\n    Returns:\\n        bool: True if the value satisfies all specified boundary conditions; \\n              False otherwise.\\n\\n    Examples:\\n        compare_numerical_values(3.2, min_value=2, max_value=5) \\n            -> True (assuming inclusive checks)\\n        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\\n            -> False, since 2 is not strictly > 2', 'parameters': {'type': 'object', 'properties': {'value': {'type': 'number'}, 'min_value': {'type': 'number'}, 'max_value': {'type': 'number'}, 'inclusive_min': {'type': 'boolean'}, 'inclusive_max': {'type': 'boolean'}}, 'required': ['value']}}}, {'type': 'function', 'function': {'name': 'provide_final_prediction', 'description': 'Returns an answer string with reasoning and final prediction.\\n    Args:\\n        reasoning: A step-by-step explanation for how you arrived at the predicted T stage.\\n        prediction: The final predicted T stage (T1, T2, T3, or T4).', 'parameters': {'type': 'object', 'properties': {'reasoning': {'type': 'string'}, 'prediction': {'type': 'string'}}, 'required': ['reasoning', 'prediction']}}}]}}\n",
      "2025-03-11 10:47:55 - DEBUG - Sending HTTP Request: POST http://localhost:8000/v1/chat/completions\n",
      "2025-03-11 10:47:55 - DEBUG - close.started\n",
      "2025-03-11 10:47:55 - DEBUG - close.complete\n",
      "2025-03-11 10:47:55 - DEBUG - connect_tcp.started host='localhost' port=8000 local_address=None timeout=5.0 socket_options=None\n",
      "2025-03-11 10:47:55 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0f78c9a8b0>\n",
      "2025-03-11 10:47:55 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 10:47:55 - DEBUG - send_request_headers.complete\n",
      "2025-03-11 10:47:55 - DEBUG - send_request_body.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 10:47:55 - DEBUG - send_request_body.complete\n",
      "2025-03-11 10:47:55 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-03-11 10:48:04 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'date', b'Tue, 11 Mar 2025 10:47:54 GMT'), (b'server', b'uvicorn'), (b'content-length', b'660'), (b'content-type', b'application/json')])\n",
      "2025-03-11 10:48:04 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-11 10:48:04 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2025-03-11 10:48:04 - DEBUG - receive_response_body.complete\n",
      "2025-03-11 10:48:04 - DEBUG - response_closed.started\n",
      "2025-03-11 10:48:04 - DEBUG - response_closed.complete\n",
      "2025-03-11 10:48:04 - DEBUG - HTTP Response: POST http://localhost:8000/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 11 Mar 2025 10:47:54 GMT', 'server': 'uvicorn', 'content-length': '660', 'content-type': 'application/json'})\n",
      "2025-03-11 10:48:04 - DEBUG - request_id: None\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"system\", \"content\":response.choices[0].message.content})\n",
    "user_prompt2 = \\\n",
    "\"\"\"Great. Now, call each tool step-by-step with the necessary arguments.\"\"\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt2})\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    messages=messages,\n",
    "    temperature=0.4,\n",
    "    tools=tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='chatcmpl-tool-024aaf5603cb40ccaa216ac6ff4afdfe', function=Function(arguments='{\"info_to_extract\": [\"tumor_size\", \"depth_of_invasion\", \"lymph_node_status\"]}', name='extract_information'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please stick to your original plan. You haven't finished calling all the required tools yet.  \n",
      "Continue by invoking the next tool according to your planned sequence.\n"
     ]
    }
   ],
   "source": [
    "warning_prompt = \\\n",
    "    \"\"\"Please stick to your original plan. You haven't finished calling all the required tools yet.  \n",
    "Continue by calling the next tool according to your planned sequence.\"\"\"\n",
    "\n",
    "print(warning_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final node\n",
    "def generate_structured_output() -> dict:\n",
    "    \"\"\"\n",
    "    Generates a structured output containing the model's reasoning, determined stage, and confidence score.\n",
    "\n",
    "    Args:\n",
    "        last_model_answer (str): The final reasoning or explanation \n",
    "                                 from the LLM.\n",
    "        stage_label (str): The classification stage determined by \n",
    "                           the LLM (e.g., \"T2\").\n",
    "        confidence_score (float): A numeric value indicating confidence \n",
    "                                  (0.0 to 1.0).\n",
    "\n",
    "    Returns:\n",
    "        dict: A structured result in the format:\n",
    "            {\n",
    "                \"reasoning\": <str>,\n",
    "                \"stage\": <str>,\n",
    "                \"confidence_score\": <float>\n",
    "            }\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"reasoning\": \"\",\n",
    "        \"stage\": \"\",\n",
    "        \"confidence_score\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "semaphore = asyncio.Semaphore(5)\n",
    "async def process_single_query(row_idx: int, row: pd.Series):\n",
    "    async with semaphore:\n",
    "        logger.info(f\"Processing row index {row_idx}\")\n",
    "        report = row[\"text\"]\n",
    "        t_stage = row[\"t\"]\n",
    "        formatted_user_prompt = user_prompt.format(report=report)\n",
    "        result = await run_multi_agent_system(\n",
    "            system_instruction=system_instruction,\n",
    "            user_prompt=formatted_user_prompt,\n",
    "            available_tools=available_tools,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    logger.info(f\"Processing row index {idx}\")\n",
    "    report = row[\"text\"]\n",
    "    t_stage = row[\"t\"]\n",
    "\n",
    "    formatted_user_prompt = user_prompt.format(report=report)\n",
    "\n",
    "\n",
    "\n",
    "    # Run the multi-agent system for this single query\n",
    "    result_dict = await process_single_query(\n",
    "        question_text=question_text,\n",
    "        ground_truth=ground_truth,\n",
    "        choices=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "        # choices=[\"Yes\", \"No\"],\n",
    "        n_specialists=5\n",
    "    )\n",
    "    # result_dict[\"File ID\"] = row[\"File ID\"]\n",
    "    result_dict[\"qn_num\"] = row[\"qn_num\"]\n",
    "\n",
    "    # Store result for later evaluation\n",
    "    results.append(result_dict)\n",
    "\n",
    "    if idx % 10 == 0:\n",
    "        output_json_path = f\"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step3_{idx}.json\"\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"Saved aggregated results to {output_json_path}\")\n",
    "\n",
    "# OPTIONAL: Save results to JSON\n",
    "output_json_path = \"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step3_final.json\"\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "logger.info(f\"Saved aggregated results to {output_json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "messages = [{\"role\": \"system\", \"content\": system_instruction}, {\"role\": \"user\", \"content\": formatted_user_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model = \"meta-llama/Llama-3.3-70B-Instruct\", \n",
    "    messages = messages,\n",
    "    tools = tools,\n",
    "    tool_choice=\"auto\", \n",
    "    # tool_choice=\"none\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resp.choices[0].message.tool_calls:\n",
    "    print(\"Tool calls detected.\")\n",
    "    messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": resp.choices[0].message.tool_calls\n",
    "    })\n",
    "    for call in resp.choices[0].message.tool_calls:\n",
    "        \n",
    "        args = safe_json_load(call.function.arguments)\n",
    "        if call.function.name == \"provide_final_prediction\":\n",
    "            return args\n",
    "        result = available_tools[call.function.name](**args)\n",
    "        print(result)\n",
    "        messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": result,\n",
    "        \"tool_call_id\": call.id,\n",
    "        \"name\": call.function.name,\n",
    "        })\n",
    "\n",
    "else:\n",
    "    final_result = resp.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": final_result})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_load(s: str) -> Any:\n",
    "    \"\"\"\n",
    "    Attempts to parse a JSON string using the standard json.loads.\n",
    "    If that fails (e.g. due to an unterminated string), it will try using\n",
    "    a more forgiving parser (demjson3). If both attempts fail,\n",
    "    the original string is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(\"Standard json.loads failed: %s\", e)\n",
    "        try:\n",
    "            logger.info(\"Attempting to parse with demjson3 as fallback.\")\n",
    "            result = demjson3.decode(s)\n",
    "            logger.info(\"demjson3 successfully parsed the JSON.\")\n",
    "            return result\n",
    "        except Exception as e2:\n",
    "            logger.error(\"Fallback parsing with demjson3 also failed: %s. Returning original input.\", e2)\n",
    "            return s\n",
    "\n",
    "\n",
    "class LLMAgent:\n",
    "    def __init__(self, system_prompt: str, \n",
    "                 client=AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")):\n",
    "        self.client = client\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    async def llm_call(self, user_prompt: str,\n",
    "                       guided_: dict = None,\n",
    "                       tools: List[dict] = None) -> Any:\n",
    "        logger.debug(f\"LLMAgent.llm_call() - user_prompt[:60]: {user_prompt[:60]}...\")\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        params = {\n",
    "            \"model\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "            \"messages\": self.messages,\n",
    "            \"temperature\": 0.5,\n",
    "        }\n",
    "        if guided_:\n",
    "            logger.debug(f\"Guided JSON/choice detected: {guided_}\")\n",
    "            params[\"extra_body\"] = guided_\n",
    "        if tools:\n",
    "            params[\"tools\"] = tools\n",
    "\n",
    "        response = await self.client.chat.completions.create(**params)\n",
    "        return response.choices[0].message\n",
    "    \n",
    "    def append_message(self, content, role='assistant'):\n",
    "        logger.debug(f\"Appending message with role='{role}' to conversation.\")\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "        return\n",
    "\n",
    "\n",
    "class InitializerAgent(LLMAgent):\n",
    "    def __init__(self, n_specialists: int):\n",
    "        self.n_specialists = n_specialists\n",
    "        system_prompt = (\n",
    "            \"You are an initializer agent in a multi-agent AI system designed to handle medical questions.\\n\"\n",
    "            f\"Your job is to select {self.n_specialists} medical specialists whose expertise best matches the user's query.\\n\"\n",
    "            \"For each specialist, specify their role and a list of relevant expertise areas related to the query.\\n\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def identify_specialists(self, query: str):\n",
    "        logger.info(\"InitializerAgent: Identifying specialists.\")\n",
    "        class Specialist(BaseModel):\n",
    "            specialist: str = Field(..., description=\"Role of the specialist\")\n",
    "            expertise: List[str] = Field(..., description=\"Areas of expertise for the specialist.\")\n",
    "        panel_dict = {f\"Specialist_{i+1}\": (Specialist, ...) for i in range(self.n_specialists)}\n",
    "        SpecialistPanel = create_model(\"SpecialistPanel\", **panel_dict)\n",
    "\n",
    "        user_prompt = (\n",
    "            \"Here is the user's query:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            \"Based on the above query, identify the most suitable specialists.\"\n",
    "        )\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": SpecialistPanel.schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"InitializerAgent response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "class SpecialistAgent(LLMAgent):\n",
    "    def __init__(self, specialist: str, expertise: List[str]):\n",
    "        self.specialist = specialist\n",
    "        self.expertise = expertise\n",
    "        system_prompt = (\n",
    "            f\"You are a {specialist}.\\n\"\n",
    "            f\"Your expertise includes:\\n{expertise}\\n\"\n",
    "            f\"Analyze the user's query from the perspective of a {specialist}.\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def analyze_query(self, query: str, choices: List[str]):\n",
    "        logger.info(f\"[{self.specialist}] Analyzing query...\")\n",
    "        self.query = query\n",
    "        self.choices = tuple(choices)\n",
    "        choices_str = ', '.join(choices)\n",
    "\n",
    "        user_prompt = (\n",
    "            \"Here is the query of interest:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            f\"The possible answers are: {choices_str}.\\n\"\n",
    "            f\"From your perspective as a {self.specialist}, first provide step-by-step reasoning (rationale), \"\n",
    "            \"and then clearly state your final answer.\\n\\n\"\n",
    "        )\n",
    "\n",
    "        class Response(BaseModel):\n",
    "            reasoning: str = Field(..., description=\"Step-by-step reasoning leading to the final choice\")\n",
    "            choice: Literal[self.choices] = Field(..., description=\"Final choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": Response.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"[{self.specialist}] analyze_query response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "    \n",
    "    async def debate(self, agents: Dict[str, Any]):\n",
    "        logger.info(f\"[{self.specialist}] Debating with other specialists.\")\n",
    "        other_specialists = {}\n",
    "        for name, value in agents.items():\n",
    "            if name != self.specialist:\n",
    "                other_specialists[name] = value\n",
    "\n",
    "        formatted_other_specialists = json.dumps(other_specialists, indent=4)\n",
    "        user_prompt = (\n",
    "            \"Regarding the previous query, other specialists have also provided their reasoning and choices.\\n\"\n",
    "            \"Critically evaluate the reasoning and choice of those specialists.\\n\\n\"\n",
    "            f\"Specialists and their choices:\\n{formatted_other_specialists}\\n\\n\"\n",
    "            \"Considering the newly provided perspectives, refine your own reasoning and choice.\\n\"\n",
    "            \"You can change your choice or stick with the original one.\\n\\n\"\n",
    "        )\n",
    "\n",
    "        class Response(BaseModel):\n",
    "            reasoning: str = Field(..., description=\"Step-by-step reasoning leading to final choice\")\n",
    "            choice: Literal[self.choices] = Field(..., description=\"Final choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": Response.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"[{self.specialist}] debate response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "class AggregatorAgent(LLMAgent):\n",
    "    def __init__(self):\n",
    "        system_prompt = (\n",
    "            \"You are the aggregator agent in a multi-agent AI system for medical queries.\\n\"\n",
    "            \"You have access to each specialist's entire chat history.\\n\"\n",
    "            \"Your job is to read those full conversations, analyze their reasoning and any conflicts, \"\n",
    "            \"and then provide a single, definitive answer to the user.\\n\"\n",
    "            \"Provide a clear explanation for your final conclusion.\"\n",
    "        )\n",
    "        super().__init__(system_prompt)\n",
    "\n",
    "    async def aggregate(self, query: str, choices: List[str], specialists_chat_history: Dict[str, Any]):\n",
    "        logger.info(\"AggregatorAgent: Aggregating final answer from all specialists' chat history.\")\n",
    "        specialists_str = json.dumps(specialists_chat_history, indent=4)\n",
    "\n",
    "        user_prompt = (\n",
    "            f\"Here is the query of interest:\\n\\n\"\n",
    "            f\"<Query>\\n{query}\\n</Query>\\n\\n\"\n",
    "            \"Below is the *entire conversation history* for each specialist:\\n\\n\"\n",
    "            f\"{specialists_str}\\n\\n\"\n",
    "            \"Please review all these conversations in detail and produce one single, definitive final answer. \"\n",
    "            \"If there is no unanimous or majority choice, choose the answer best supported by the specialists' reasoning. \"\n",
    "            \"Clearly justify your reasoning, then provide your final recommended answer.\"\n",
    "        )\n",
    "\n",
    "        class AggregatedResponse(BaseModel):\n",
    "            aggregated_reasoning: str = Field(..., description=\"Detailed reasoning behind final choice\")\n",
    "            aggregated_choice: Literal[tuple(choices)] = Field(..., description=\"Single recommended choice\")\n",
    "\n",
    "        response = await self.llm_call(user_prompt, guided_={\"guided_json\": AggregatedResponse.model_json_schema()})\n",
    "        self.append_message(content=response.content)\n",
    "        logger.debug(f\"AggregatorAgent response: {response.content}\")\n",
    "        return safe_json_load(response.content)\n",
    "\n",
    "\n",
    "def check_consensus(status_dict: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Returns the consensus choice if >= 80% of specialists agree, else returns None.\n",
    "    \"\"\"\n",
    "    logger.info(\"Checking for consensus among specialists.\")\n",
    "    specialists_count = len(status_dict)\n",
    "    consensus_threshold = math.ceil(0.8 * specialists_count)\n",
    "\n",
    "    choice_counts = {}\n",
    "    for _, specialist_data in status_dict.items():\n",
    "        final_choice = specialist_data['response_after_debate']['choice']\n",
    "        choice_counts[final_choice] = choice_counts.get(final_choice, 0) + 1\n",
    "\n",
    "    for choice, count in choice_counts.items():\n",
    "        if count >= consensus_threshold:\n",
    "            logger.info(f\"Consensus found on choice '{choice}' with {count}/{specialists_count} specialists.\")\n",
    "            return choice\n",
    "    logger.info(\"No consensus found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 3) PROCESS A SINGLE ROW/QUERY\n",
    "# --------------------------------\n",
    "async def process_single_query(\n",
    "    question_text: str,\n",
    "    ground_truth: str,\n",
    "    choices: List[str],\n",
    "    n_specialists: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Given a single query (question + ground_truth + multiple choices), \n",
    "    run the multi-agent system (Initializer -> Specialists -> Debates -> Aggregator if needed).\n",
    "    Return the final dictionary containing all the specialists' output and aggregator results.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Initialize specialists\n",
    "    initializer = InitializerAgent(n_specialists=n_specialists)\n",
    "    json_resp = await initializer.identify_specialists(query=question_text)\n",
    "    if not isinstance(json_resp, dict):\n",
    "        logger.error(\"Invalid JSON output from initializer; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # Build specialists status dict\n",
    "    specialists_status = {}\n",
    "    for _, agent_info in json_resp.items():\n",
    "        specialist_name = agent_info[\"specialist\"]\n",
    "        expertise = agent_info[\"expertise\"]\n",
    "        specialists_status[specialist_name] = {\"expertise\": expertise}\n",
    "    \n",
    "    # 2. Run analyze_query for each specialist in parallel\n",
    "    async def analyze_specialist(specialist_name: str, status: Dict[str, Any], query: str, choices: List[str]):\n",
    "        specialist_agent = SpecialistAgent(specialist=specialist_name, expertise=status[\"expertise\"])\n",
    "        status[\"instance\"] = specialist_agent\n",
    "        message = await specialist_agent.analyze_query(query=query, choices=choices)\n",
    "        if not isinstance(message, dict):\n",
    "            logger.error(f\"[{specialist_name}] Invalid JSON output from specialist; skipping this specialist.\")\n",
    "            return None\n",
    "        status[\"original_response\"] = message\n",
    "        logger.info(f\"[{specialist_name}] Completed analyze_query.\")\n",
    "        return specialist_name\n",
    "\n",
    "    analyze_tasks = [\n",
    "        asyncio.create_task(analyze_specialist(name, status, question_text, choices))\n",
    "        for name, status in specialists_status.items()\n",
    "    ]\n",
    "    analyze_results = await asyncio.gather(*analyze_tasks)\n",
    "    if any(r is None for r in analyze_results):\n",
    "        logger.error(\"At least one specialist failed; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # Build a minimal dictionary for debate (remove 'instance')\n",
    "    input_specialists_dict = {\n",
    "        specialist_name: {\n",
    "            k: v for k, v in specialist_data.items() \n",
    "            if k != \"instance\"\n",
    "        }\n",
    "        for specialist_name, specialist_data in specialists_status.items()\n",
    "    }\n",
    "\n",
    "    # 3. Debate step, also in parallel\n",
    "    async def debate_specialist(specialist_name: str, status: Dict[str, Any], specialists_dict: Dict[str, Any]):\n",
    "        specialist_agent = status[\"instance\"]\n",
    "        message = await specialist_agent.debate(specialists_dict)\n",
    "        if not isinstance(message, dict):\n",
    "            logger.error(f\"[{specialist_name}] Invalid JSON output during debate; skipping this specialist.\")\n",
    "            return None\n",
    "        status[\"response_after_debate\"] = message\n",
    "        specialists_dict[specialist_name][\"response_after_debate\"] = message\n",
    "        logger.info(f\"[{specialist_name}] Completed debate.\")\n",
    "        return specialist_name\n",
    "\n",
    "    debate_tasks = [\n",
    "        asyncio.create_task(debate_specialist(name, status, input_specialists_dict))\n",
    "        for name, status in specialists_status.items()\n",
    "    ]\n",
    "    debate_results = await asyncio.gather(*debate_tasks)\n",
    "    if any(r is None for r in debate_results):\n",
    "        logger.error(\"At least one specialist failed during debate; skipping this query.\")\n",
    "        return {}  # Skip processing and continue to the next query\n",
    "\n",
    "    # 4. Check consensus\n",
    "    consensus_choice = check_consensus(input_specialists_dict)\n",
    "    aggregator_result = None\n",
    "\n",
    "    if consensus_choice is not None:\n",
    "        logger.info(f\"Consensus reached: {consensus_choice}\")\n",
    "        input_specialists_dict[\"Aggregator\"] = {\n",
    "            \"final_choice\": consensus_choice, \n",
    "            \"final_reasoning\": \"Consensus reached\"\n",
    "        }\n",
    "    else:\n",
    "        logger.info(\"No consensus reached; enabling aggregator path...\")\n",
    "        aggregator = AggregatorAgent()\n",
    "        aggregated_response = await aggregator.aggregate(\n",
    "            query=question_text,\n",
    "            choices=choices,\n",
    "            specialists_chat_history=input_specialists_dict\n",
    "        )\n",
    "        if not isinstance(aggregated_response, dict):\n",
    "            logger.error(\"Invalid JSON output from aggregator; skipping this query.\")\n",
    "            return {}  # Skip processing and continue to the next query\n",
    "        \n",
    "        final_choice = aggregated_response['aggregated_choice']\n",
    "        final_reasoning = aggregated_response['aggregated_reasoning']\n",
    "\n",
    "        logger.info(f\"Aggregator final choice: {final_choice}\")\n",
    "        logger.info(f\"Aggregator reasoning: {final_reasoning}\")\n",
    "\n",
    "        aggregator_result = {\n",
    "            \"final_choice\": final_choice,\n",
    "            \"final_reasoning\": final_reasoning\n",
    "        }\n",
    "        input_specialists_dict[\"Aggregator\"] = aggregator_result\n",
    "\n",
    "    # Add question and ground_truth for reference\n",
    "    input_specialists_dict[\"Question\"] = question_text\n",
    "    input_specialists_dict[\"Answer\"] = ground_truth\n",
    "\n",
    "    return input_specialists_dict\n",
    "\n",
    "\n",
    "async def process_multiple_queries(\n",
    "    qa_df: pd.DataFrame,\n",
    "    choices: List[str],\n",
    "    n_specialists: int,\n",
    "    max_concurrency: int = 5\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process multiple rows (queries) in `qa_df` asynchronously.\n",
    "    Each row is passed to `process_single_query`.\n",
    "    \n",
    "    :param qa_df: DataFrame with columns [\"question\", \"choice\", \"ground_truth\"] at least.\n",
    "    :param choices: A list of all possible answer choices, e.g. [\"A\", \"B\", \"C\", \"D\", \"E\"].\n",
    "    :param n_specialists: Number of specialists to initialize for each query.\n",
    "    :param max_concurrency: Limit on how many queries to process simultaneously.\n",
    "    :return: A list of result dictionaries, one per row in `qa_df`.\n",
    "    \"\"\"\n",
    "\n",
    "    # This semaphore keeps at most `max_concurrency` tasks running at once\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "    async def run_single_query(row_idx: int, row: pd.Series):\n",
    "        \"\"\"\n",
    "        This inner function is used to call `process_single_query` with concurrency control.\n",
    "        \"\"\"\n",
    "        async with semaphore:\n",
    "            logger.info(f\"Starting row {row_idx}\")\n",
    "            question_text = row[\"question\"] + \"\\n\" + str(row[\"choice\"])\n",
    "            ground_truth = str(row[\"ground_truth\"])\n",
    "            result = await process_single_query(\n",
    "                question_text=question_text,\n",
    "                ground_truth=ground_truth,\n",
    "                choices=choices,\n",
    "                n_specialists=n_specialists\n",
    "            )\n",
    "            logger.info(f\"Finished row {row_idx}\")\n",
    "            return result\n",
    "\n",
    "    tasks = [\n",
    "        asyncio.create_task(run_single_query(i, row))\n",
    "        for i, row in qa_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Wait for all tasks to complete\n",
    "    all_results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # `all_results` is a list of return values from each `run_single_query`\n",
    "    return all_results\n",
    "\n",
    "async def main():\n",
    "\n",
    "    logger.info(\"===== MAIN START =====\")\n",
    "\n",
    "    # Example CSV loading\n",
    "    df_path = \"/home/yl3427/cylab/llm_reasoning/reasoning/data/step2_ALL.csv\"\n",
    "    qa_df = pd.read_csv(df_path, encoding=\"latin-1\")  # columns: idx, question, choice, ground_truth, qn_num\n",
    "    # qa_df = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/SOAP_5_problems.csv')\n",
    "    logger.info(\"Loaded dataframe with %d rows.\", len(qa_df))\n",
    "\n",
    "\n",
    "    ################# 'process_single_query' Example usage #################\n",
    "    results = []\n",
    "    for idx, row in qa_df.iterrows():\n",
    "        # if idx <= 10:\n",
    "        #     continue\n",
    "        logger.info(f\"Processing row index {idx}\")\n",
    "        question_text = row[\"question\"] + \"\\n\" + str(row[\"choice\"])\n",
    "        ground_truth = str(row[\"ground_truth\"])\n",
    "\n",
    "        # patient_info = str(row[\"Subjective\"]) + \"\\n\" + str(row['Objective'])\n",
    "        # question_text = f\"\"\"\n",
    "        # Based on the following patient report, does the patient have sepsis?\n",
    "\n",
    "        # {patient_info}\n",
    "        # \"\"\"\n",
    "        # ground_truth = str(row[\"terms\"])\n",
    "        \n",
    "\n",
    "        # Run the multi-agent system for this single query\n",
    "        result_dict = await process_single_query(\n",
    "            question_text=question_text,\n",
    "            ground_truth=ground_truth,\n",
    "            choices=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "            # choices=[\"Yes\", \"No\"],\n",
    "            n_specialists=5\n",
    "        )\n",
    "        # result_dict[\"File ID\"] = row[\"File ID\"]\n",
    "        result_dict[\"qn_num\"] = row[\"qn_num\"]\n",
    "\n",
    "        # Store result for later evaluation\n",
    "        results.append(result_dict)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            output_json_path = f\"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step2_{idx}.json\"\n",
    "            with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"Saved aggregated results to {output_json_path}\")\n",
    "\n",
    "    # OPTIONAL: Save results to JSON\n",
    "    output_json_path = \"/home/yl3427/cylab/SOAP_MA/Output/MedicalQA/step2_final.json\"\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    logger.info(f\"Saved aggregated results to {output_json_path}\")\n",
    "\n",
    "    logger.info(\"===== MAIN END =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log\n",
    "for name, status in specialists_status.items():\n",
    "    print(f\"Specialist: {name}\")\n",
    "    message = status[\"instance\"].messages\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are a knowledgeable and meticulous medical expert specialized in diagnosing diseases based on partial information from SOAP notes. \n",
    "You will receive either:\n",
    "1. A single-disease assessment request (“specialist” scenario), or \n",
    "2. A multiple-disease assessment request (“generalist” scenario).\n",
    "\n",
    "In the “specialist” scenario, you focus on one disease and analyze evidence within the Subjective (S) and Objective (O) sections for or against that single disease. Your final answer must be in valid JSON with:\n",
    "    {\n",
    "        \"reasoning\": \"Concise explanation of your thought process\",\n",
    "        \"diagnosis\": true_or_false\n",
    "    }\n",
    "\n",
    "In the “generalist” scenario, you must assess each disease from a given list. For each disease, identify subjective and objective evidence that supports or refutes the disease. If evidence strongly supports it, conclude the diagnosis is true; if not, conclude false. If conflicting or incomplete, offer a reasoned explanation and a likely conclusion. Your final answer must be in valid JSON with each disease as a key:\n",
    "    {\n",
    "      \"DiseaseName1\": { \"reasoning\": \"Your reasoning...\", \"diagnosis\": true_or_false },\n",
    "      \"DiseaseName2\": { \"reasoning\": \"Your reasoning...\", \"diagnosis\": true_or_false },\n",
    "      ...\n",
    "    }\n",
    "\n",
    "When reasoning, consider clinical clues like symptoms, exam findings, risk factors, and labs. Clearly and succinctly justify why each disease is likely or unlikely. If any information is missing or ambiguous, note the uncertainty and choose the most probable conclusion.\n",
    "\n",
    "Follow these instructions precisely:\n",
    "• Always return output in the exact JSON format requested (no extra fields or text).\n",
    "• Provide concise, medically sound rationale for each decision.\n",
    "\"\"\"\n",
    "\n",
    "prompt_specialist = \"\"\"\n",
    "You are a medical expert specializing in {PROBLEM}.\n",
    "\n",
    "You are provided with only the Subjective (S) and Objective (O) sections of a patient's SOAP-formatted progress note for a potential case of {PROBLEM}.\n",
    "Identify relevant clues in the subjective and objective sections that align with or argue against {PROBLEM}. If evidence strongly suggests {PROBLEM}, conclude the diagnosis is true; if not, conclude it is false. If the evidence is uncertain or conflicting, explain your reasoning and lean toward the most likely conclusion.\n",
    "\n",
    "Patient Report:\n",
    "<Subjective>\n",
    "{SUBJ}\n",
    "</Subjective>\n",
    "\n",
    "<Objective>\n",
    "{OBJ}\n",
    "</Objective>\n",
    "\n",
    "Your answer must be output as valid JSON formatted exactly as follows:\n",
    "    {{\n",
    "        \"reasoning\": \"Your reasoning here...\",\n",
    "        \"diagnosis\": true_or_false\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "prompt_generalist = \"\"\"\n",
    "You are a medical expert in diagnostic reasoning.\n",
    "\n",
    "You are provided with only the Subjective (S) and Objective (O) sections of a patient's SOAP-formatted progress note that may be relevant to one or more of the following diseases:\n",
    "{PROBLEM_LIST}\n",
    "\n",
    "The patient may have one or more of these diseases, or none at all. Evaluate each disease independently.\n",
    "Identify relevant clues in the subjective and objective sections that align with or argue against each disease. If evidence strongly suggests the disease, conclude the diagnosis is true; if not, conclude it is false. If the evidence is uncertain or conflicting, explain your reasoning and lean toward the most likely conclusion.\n",
    "\n",
    "Patient Report:\n",
    "<Subjective>\n",
    "{SUBJ}\n",
    "</Subjective>\n",
    "\n",
    "<Objective>\n",
    "{OBJ}\n",
    "</Objective>\n",
    "\n",
    "Your answer must be output as valid JSON formatted exactly as follows:\n",
    "{{\n",
    "{json_keys}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "system_instruction_mediator = \"\"\"\n",
    "You are the mediator agent in a medical multi-agent diagnostic system. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    reasoning: str = Field(..., description=\"Step-by-step reasoning leading to the final diagnosis.\")\n",
    "    diagnosis: bool = Field(..., description=\"True if patient has the disease, False otherwise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import get_origin, get_args, Union, Any\n",
    "\n",
    "def generate_tools_spec(*functions):\n",
    "    \"\"\"\n",
    "    Generate a list of tool definitions (function schemas) for OpenAI's tool calling.\n",
    "    \n",
    "    Each function's name, docstring, and parameters (with types and required flags)\n",
    "    are extracted to form the JSON schema as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        *functions: One or more Python function objects to document.\n",
    "    Returns:\n",
    "        List[dict]: A list of tool definition dictionaries compatible with OpenAI API.\n",
    "    \"\"\"\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    for func in functions:\n",
    "        # Basic function info\n",
    "        func_name = func.__name__\n",
    "        func_description = func.__doc__.strip() if func.__doc__ else \"\"\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            param_name = param.name\n",
    "\n",
    "            # Determine JSON schema type from annotation (if available)\n",
    "            json_type = \"string\"  # default type\n",
    "            annotation = param.annotation\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                if origin is Union:\n",
    "                    args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(args) == 1:\n",
    "                        annotation = args[0]\n",
    "                        origin = get_origin(annotation)\n",
    "                # Map to JSON type if direct or via origin for generics\n",
    "                if annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                # Handle list item types for generics like list[int]\n",
    "                if json_type == \"array\":\n",
    "                    item_type = \"string\"  # default for items\n",
    "                    args = get_args(annotation)\n",
    "                    if args:\n",
    "                        # Use first type argument for list item if present\n",
    "                        item_type = type_map.get(args[0], \"string\")\n",
    "                    properties[param_name] = {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": item_type}\n",
    "                    }\n",
    "                elif json_type == \"object\":\n",
    "                    # For dicts or unknown complex types, use object without specifics\n",
    "                    properties[param_name] = {\"type\": \"object\"}\n",
    "                else:\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "            else:\n",
    "                # No annotation, assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        # Build the tool dictionary for this function\n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        tools.append(tool_dict)\n",
    "    return tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_synonyms(problem: str) -> Optional[List[str]]: \n",
    "    \"\"\"\n",
    "    Retrieve the list of synonyms for a given problem.\n",
    "    \"\"\"\n",
    "    problem = problem.lower()\n",
    "    mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "    chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "    pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "    pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "    sepsis = [\"sepsis\", \"septic shock\"]\n",
    "    urosepsis = [\"urosepsis\"]\n",
    "    meningitis = [\"meningitis\"]\n",
    "    aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "    atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "    pancreatitis = [\"pancreatitis\"]\n",
    "    gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "    hepatitis = [\"hepatitis\", \" hep\"]\n",
    "    cholangitis = [\"cholangitis\"]\n",
    "    asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "    prob_dict = {'myocardial infarction': mi, \n",
    "                 'congestive heart failure': chf, \n",
    "                 'pulmonary embolism': pulmonary_embolism, \n",
    "                 'pulmonary hypertension': pulmonary_hypertension, \n",
    "                 'sepsis': sepsis, \n",
    "                 'urosepsis': urosepsis, \n",
    "                 'meningitis': meningitis, \n",
    "                 'acute kidney injury': aki, \n",
    "                 'acute tubular necrosis': atn, \n",
    "                 'pancreatitis': pancreatitis, \n",
    "                 'gastrointestinal bleed': gi_bleed, \n",
    "                 'hepatitis': hepatitis, \n",
    "                 'cholangitis': cholangitis, \n",
    "                 'aspiration pneumonia': asp_pneumonia}\n",
    "    result = prob_dict.get(problem, None)\n",
    "    return result\n",
    "tools = generate_tools_spec(retrieve_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the synonym for acute kidney injury?\"}\n",
    "]\n",
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")\n",
    "response = client.chat.completions.create(\n",
    "    model=client.models.list().data[0].id,\n",
    "    messages=messages,\n",
    "    temperature= 0.1,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\" #none\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    print(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(name, args):\n",
    "    if name == \"retrieve_synonyms\":\n",
    "        return retrieve_synonyms(**args)\n",
    "    \n",
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    result = str(call_function(name, args))\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"name\": name,\n",
    "        \"output\": result\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "툴콜링 됐을 때와 아닐때 모델 아웃풋 차이\n",
    "```\n",
    "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='chatcmpl-tool-e9f31a3069694cc69887d4e03d16b412', function=Function(arguments='{\"problem\": \"acute kidney injury\"}', name='retrieve_synonyms'), type='function')], reasoning_content=None)\n",
    "\n",
    "\n",
    "ChatCompletionMessage(content='The synonym for acute kidney injury (AKI) is acute renal failure (ARF).', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[], reasoning_content=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=client.models.list().data[0].id,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, client: OpenAI):\n",
    "        self.client = client\n",
    "\n",
    "    def get_response(\n",
    "        self, \n",
    "        messages: List[Dict], \n",
    "        temperature: Optional[float] = 0.1,\n",
    "        guided_: Optional[dict] = None, # {\"guided_json\": json_schema}, {\"guided_choice\": [\"positive\", \"negative\"]}\n",
    "        tools: Optional[List[Dict]] = None\n",
    "    ):\n",
    "        try:\n",
    "            request_params = {\n",
    "                \"model\": self.client.models.list().data[0].id,\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": temperature,\n",
    "            }\n",
    "            if guided_:\n",
    "                request_params[\"extra_body\"] = guided_\n",
    "            if tools:\n",
    "                request_params[\"tools\"] = tools\n",
    "\n",
    "            response = self.client.chat.completions.create(**request_params)\n",
    "\n",
    "            return response.choices[0].message\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    # def test_single_prob(self, dataset: pd.DataFrame, problem: str):\n",
    "    #     pbar = tqdm(total=dataset.shape[0], desc=f\"Testing {problem}\")\n",
    "    #     for idx, row in dataset.iterrows():\n",
    "    #         subj_text = row[\"Subjective\"]\n",
    "    #         obj_text = row[\"Objective\"]\n",
    "\n",
    "    #         prompt_specialist_formatted = prompt_specialist.format(\n",
    "    #             PROBLEM=problem,\n",
    "    #             SUBJ=subj_text,\n",
    "    #             OBJ=obj_text\n",
    "    #         )\n",
    "    #         messages = [\n",
    "    #             {\"role\": \"system\", \"content\": system_instruction},\n",
    "    #             {\"role\": \"user\", \"content\": prompt_specialist_formatted}\n",
    "    #         ]\n",
    "    #         response = self.get_response(\n",
    "    #             messages,\n",
    "    #             schema= DiseaseDiagnosis.model_json_schema()\n",
    "    #         )\n",
    "    #         if response:\n",
    "    #             dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_pred_single\"] = response[\"diagnosis\"]\n",
    "    #             dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_reasoning_single\"] = response[\"reasoning\"]\n",
    "\n",
    "    #         pbar.update(1)\n",
    "    #     pbar.close()\n",
    "    #     return dataset\n",
    "    \n",
    "    # def test_multi_prob(self, dataset: pd.DataFrame, problem_lst: list):\n",
    "\n",
    "    #     problem_dict = {problem: (DiseaseDiagnosis, ...) for problem in problem_lst}\n",
    "\n",
    "    #     DynamicResponseMultiDiagnosis = create_model(\n",
    "    #                 'DynamicResponseMultiDiagnosis',\n",
    "    #                 **problem_dict\n",
    "    #             )\n",
    "\n",
    "    #     pbar = tqdm(total=dataset.shape[0], desc=\"Testing Multi-Diagnosis\")\n",
    "    #     for idx, row in dataset.iterrows():\n",
    "    #         subj_text = row[\"Subjective\"]\n",
    "    #         obj_text = row[\"Objective\"]\n",
    "\n",
    "    #         json_keys_list = [\n",
    "    #             f'  \"{disease}\": {{\"reasoning\": \"Your reasoning here...\", \"diagnosis\": true_or_false}}'\n",
    "    #             for disease in problem_lst\n",
    "    #         ]\n",
    "    #         json_keys = \",\\n\".join(json_keys_list)\n",
    "\n",
    "    #         prompt_generalist_formatted = prompt_generalist.format(\n",
    "    #             PROBLEM_LIST=\", \".join(problem_lst),\n",
    "    #             SUBJ=subj_text,\n",
    "    #             OBJ=obj_text,\n",
    "    #             json_keys=json_keys,\n",
    "    #         )\n",
    "\n",
    "    #         messages = [\n",
    "    #             {\"role\": \"system\", \"content\": system_instruction},\n",
    "    #             {\"role\": \"user\", \"content\": prompt_generalist_formatted}\n",
    "    #         ]\n",
    "\n",
    "    #         response = self.get_response(\n",
    "    #             messages,\n",
    "    #             schema=DynamicResponseMultiDiagnosis.model_json_schema()\n",
    "    #         )\n",
    "    #         if response:\n",
    "    #             for problem in problem_lst:\n",
    "    #                 dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_pred_multi\"] = response[problem][\"diagnosis\"]\n",
    "    #                 dataset.at[idx, f\"is_{problem.lower().replace(' ', '_')}_reasoning_multi\"] = response[problem][\"reasoning\"]\n",
    "    #         pbar.update(1)\n",
    "    #     pbar.close()\n",
    "    #     return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"dummy_key\", base_url=\"http://localhost:8000/v1\")\n",
    "df = pd.read_csv(\n",
    "    '/home/yl3427/cylab/SOAP_MA/data/mergedBioNLP2023.csv',\n",
    "    usecols=['File ID', 'Subjective', 'Objective', 'Summary', 'cleaned_expanded_Summary', 'terms']\n",
    ")\n",
    "df = df.fillna('').apply(lambda x: x.str.lower())\n",
    "df['combined_summary'] = df['Summary'] + df['cleaned_expanded_Summary'] + df['terms']\n",
    "\n",
    "mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "sepsis = [\"sepsis\", \"septic shock\"]\n",
    "urosepsis = [\"urosepsis\"]\n",
    "meningitis = [\"meningitis\"]\n",
    "aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "pancreatitis = [\"pancreatitis\"]\n",
    "gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "hepatitis = [\"hepatitis\", \" hep\"]\n",
    "cholangitis = [\"cholangitis\"]\n",
    "asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "prob_dict = {'myocardial infarction': mi, \n",
    "                'congestive heart failure': chf, \n",
    "                'pulmonary embolism': pulmonary_embolism, \n",
    "                'pulmonary hypertension': pulmonary_hypertension, \n",
    "                'sepsis': sepsis, \n",
    "                'urosepsis': urosepsis, \n",
    "                'meningitis': meningitis, \n",
    "                'acute kidney injury': aki, \n",
    "                'acute tubular necrosis': atn, \n",
    "                'pancreatitis': pancreatitis, \n",
    "                'gastrointestinal bleed': gi_bleed, \n",
    "                'hepatitis': hepatitis, \n",
    "                'cholangitis': cholangitis, \n",
    "                'aspiration pneumonia': asp_pneumonia}\n",
    "\n",
    "ids = set()\n",
    "for name, lst in prob_dict.items():\n",
    "    problem_terms = lst\n",
    "    problem_terms = [term.lower() for term in problem_terms]\n",
    "\n",
    "    # Use the first term as the primary term to check in the combined summary.\n",
    "    primary_term = problem_terms[0]\n",
    "\n",
    "    # Build a regex pattern that matches any of the problem terms.\n",
    "    # pattern = '|'.join(problem_terms)\n",
    "    pattern = '|'.join(re.escape(term) for term in problem_terms)\n",
    "\n",
    "    mask = (\n",
    "        df['combined_summary'].str.contains(pattern, na=False) &\n",
    "        ~df['Subjective'].str.contains(pattern, na=False) &\n",
    "        ~df['Objective'].str.contains(pattern, na=False)\n",
    "    )\n",
    "\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    ids.update(filtered_df['File ID'])\n",
    "\n",
    "agent = Agent(client=client)\n",
    "\n",
    "df = df[df['File ID'].isin(ids)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "result_df = agent.test_multi_prob(df, list(prob_dict.keys()))\n",
    "result_df.to_csv(\"multi_result_full.csv\", index=False)\n",
    "\n",
    "for name, lst in prob_dict.items():\n",
    "    result_df = agent.test_single_prob(result_df, name)\n",
    "    result_df.to_csv(f\"single_result_{name}.csv\", index=False)\n",
    "result_df.to_csv(\"single_result_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qa_df = pd.read_csv(\"/home/yl3427/cylab/llm_reasoning/reasoning/data/step1_ALL.csv\", encoding=\"latin-1\")\n",
    "print(len(qa_df))\n",
    "for idx, row in qa_df.iterrows():\n",
    "    if idx == 10:\n",
    "        # print(row['question'] + \"\\n\" + str(row['choice']))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
