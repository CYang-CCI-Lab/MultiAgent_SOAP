{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('/secure/shared_data/rag_tnm_results/summary/5_folds_summary/brca_df.csv')\n",
    "\n",
    "data_lst = []\n",
    "for i, row in df.iterrows():\n",
    "    pathology_report = row[\"text\"]\n",
    "    ground_truth = row[\"t\"]\n",
    "    filename = row[\"patient_filename\"]\n",
    "\n",
    "    question_text = f\"\"\"\n",
    "    Based on the following pathology report for a breast cancer patient, determine the pathologic T stage (T1, T2, T3, or T4) for breast cancer, according to the AJCC Cancer Staging Manual (7th edition). \n",
    "    Choose from T1, T2, T3, T4.\n",
    "\n",
    "    {pathology_report}\n",
    "    \"\"\"\n",
    "    data = {\"Question\": question_text, \"Answer\": ground_truth, \"Filename\": filename}\n",
    "    data_lst.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/yl3427/cylab/SOAP_MA/data/mergedBioNLP2023.csv',\n",
    "                        usecols=['File ID', 'Subjective', 'Objective', 'Assessment', 'Summary', 'cleaned_expanded_Summary', 'terms'])\n",
    "\n",
    "df = df.fillna('').apply(lambda x: x.str.lower())\n",
    "df['combined_summary'] = df['Summary'] + df['cleaned_expanded_Summary'] + df['terms']\n",
    "\n",
    "mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "sepsis = [\"sepsis\", \"septic shock\"]\n",
    "urosepsis = [\"urosepsis\"]\n",
    "meningitis = [\"meningitis\"]\n",
    "aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "pancreatitis = [\"pancreatitis\"]\n",
    "gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "hepatitis = [\"hepatitis\", \" hep\"]\n",
    "cholangitis = [\"cholangitis\"]\n",
    "asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "prob_dict = {'sepsis': sepsis, \n",
    "                'acute kidney injury': aki, \n",
    "                'pancreatitis': pancreatitis, \n",
    "                'gastrointestinal bleed': gi_bleed,\n",
    "                \"congestive heart failure\": chf}\n",
    "\n",
    "ids = set()\n",
    "for name, lst in prob_dict.items():\n",
    "    problem_terms = lst\n",
    "    problem_terms = [term.lower() for term in problem_terms]\n",
    "\n",
    "    # Use the first term as the primary term to check in the combined summary.\n",
    "    primary_term = problem_terms[0]\n",
    "\n",
    "    # Build a regex pattern that matches any of the problem terms.\n",
    "    # pattern = '|'.join(problem_terms)\n",
    "    pattern = '|'.join(re.escape(term) for term in problem_terms)\n",
    "\n",
    "    mask = (\n",
    "        df['combined_summary'].str.contains(pattern, na=False) &\n",
    "        ~df['Subjective'].str.contains(pattern, na=False) &\n",
    "        ~df['Objective'].str.contains(pattern, na=False)\n",
    "    )\n",
    "\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    ids.update(filtered_df['File ID'])\n",
    "\n",
    "df = df[df['File ID'].isin(ids)]\n",
    "df.to_csv('/home/yl3427/cylab/SOAP_MA/Input/SOAP_5_problems.csv', index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import re\n",
    "from typing import Optional, Union, List, get_origin, get_args, Any, Dict, Literal\n",
    "import inspect\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import math\n",
    "# import demjson3\n",
    "\n",
    "\n",
    "def generate_tools_spec(*functions):\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    \n",
    "    for func in functions:\n",
    "        func_name = func.__name__\n",
    "        func_description = (func.__doc__ or \"\").strip()\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        \n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            \n",
    "            param_name = param.name\n",
    "            annotation = param.annotation\n",
    "            json_type = \"string\"  # default type for fallback\n",
    "\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                \n",
    "                # Handle Literal types (e.g., Literal[\"T\", \"N\", \"M\"])\n",
    "                if origin is Literal:\n",
    "                    literal_args = get_args(annotation)\n",
    "                    \n",
    "                    # If all literal args are strings, produce a string enum\n",
    "                    if all(isinstance(arg, str) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    # If all are integers, produce an integer enum, etc.\n",
    "                    elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    else:\n",
    "                        # Fallback if the Literal contains mixed or unsupported types\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                elif origin is Union:\n",
    "                    union_args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(union_args) == 1:\n",
    "                        # e.g. Optional[str] -> just str\n",
    "                        real_type = union_args[0]\n",
    "                        origin2 = get_origin(real_type)\n",
    "                        \n",
    "                        if origin2 is Literal:\n",
    "                            # If inside an Optional[Literal[...]]\n",
    "                            literal_args = get_args(real_type)\n",
    "                            if all(isinstance(arg, str) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            else:\n",
    "                                properties[param_name] = {\"type\": \"string\"}\n",
    "                        else:\n",
    "                            # Map direct type to JSON schema\n",
    "                            json_type = type_map.get(real_type, \"string\")\n",
    "                            properties[param_name] = {\"type\": json_type}\n",
    "                    else:\n",
    "                        # More complex Unions not automatically handled; fallback to string\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # If it's a known type (str, int, etc.)\n",
    "                elif annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "                \n",
    "                # Handle typing.List[...] or typing.Dict[...] \n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                    if json_type == \"array\":\n",
    "                        # For list[...] or array\n",
    "                        item_type = \"string\"\n",
    "                        args = get_args(annotation)\n",
    "                        if args and args[0] in type_map:\n",
    "                            item_type = type_map[args[0]]\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": item_type}\n",
    "                        }\n",
    "                    elif json_type == \"object\":\n",
    "                        # For dict[...] or any unhandled complex mapping\n",
    "                        properties[param_name] = {\"type\": \"object\"}\n",
    "                \n",
    "                else:\n",
    "                    # Fallback if we can't detect the type\n",
    "                    properties[param_name] = {\"type\": \"string\"}\n",
    "            \n",
    "            else:\n",
    "                # No annotation; assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark as required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        \n",
    "        tools.append(tool_dict)\n",
    "    \n",
    "    return tools\n",
    "\n",
    "\n",
    "async def extract_information(info_to_extract: List[str], pathology_text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts relevant information from a given pathology text.\n",
    "\n",
    "    Args:\n",
    "        info_to_extract (List[str]): A list of information fields to be extracted,\n",
    "            e.g. [\"tumor_size\", \"depth_of_invasion\", ...].\n",
    "        pathology_text (str): The full text of the pathology report.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary mapping each requested field to the extracted information.\n",
    "    \"\"\"\n",
    "    client = AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    async def gather_responses():\n",
    "        tasks = []\n",
    "        for field in info_to_extract:\n",
    "            prompt = f\"\"\"You are given a pathology report:\n",
    "\n",
    "\\\"\\\"\\\"{pathology_text}\\\"\\\"\\\"\n",
    "\n",
    "Please extract the information for the field: {field}.\n",
    "Provide a concise answer containing only the relevant information for that field.\n",
    "\"\"\"\n",
    "            tasks.append(\n",
    "                client.chat.completions.create(\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    model=model_name,\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=500,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Run all extraction queries in parallel\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Build a dictionary of field -> extracted text\n",
    "        extracted_info = {}\n",
    "        for field, response in zip(info_to_extract, responses):\n",
    "            # Depending on your LLM library's return format, adjust how you access content.\n",
    "            raw_answer = response.choices[0].message.content.strip()\n",
    "            extracted_info[field] = raw_answer\n",
    "\n",
    "        return extracted_info\n",
    "\n",
    "    # Run the async logic and return the results\n",
    "    return await gather_responses()\n",
    "\n",
    "def compare_numerical_values(\n",
    "    value: float,\n",
    "    min_value: float = None,\n",
    "    max_value: float = None,\n",
    "    inclusive_min: bool = True,\n",
    "    inclusive_max: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Compares a given numeric value against optional minimum and maximum thresholds.\n",
    "    Args:\n",
    "        value (float): The numeric value to compare.\n",
    "        min_value (float, optional): The lower threshold. \n",
    "                                     If None, no lower bound check is performed.\n",
    "        max_value (float, optional): The upper threshold. \n",
    "                                     If None, no upper bound check is performed.\n",
    "        inclusive_min (bool): Whether the comparison with min_value \n",
    "                              should be inclusive (value >= min_value) \n",
    "                              or exclusive (value > min_value).\n",
    "        inclusive_max (bool): Whether the comparison with max_value \n",
    "                              should be inclusive (value <= max_value) \n",
    "                              or exclusive (value < max_value).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the value satisfies all specified boundary conditions; \n",
    "              False otherwise.\n",
    "\n",
    "    Examples:\n",
    "        compare_numerical_values(3.2, min_value=2, max_value=5) \n",
    "            -> True (assuming inclusive checks)\n",
    "        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\n",
    "            -> False, since 2 is not strictly > 2\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        if inclusive_min:\n",
    "            if value < min_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value <= min_value:\n",
    "                return False\n",
    "\n",
    "    if max_value is not None:\n",
    "        if inclusive_max:\n",
    "            if value > max_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value >= max_value:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def produce_final_staging_response(agent_response: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes the agent's final response and reformat it into a JSON schema with 'reasoning' and 'stage' as keys.\n",
    "\n",
    "    Args:\n",
    "        agent_response (str): The final response from the agent (after all internal processing).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing two keys: 'reasoning' and 'stage'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: we create a second LLM client specifically for formatting the final output\n",
    "    formatting_client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    formatting_model = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    prompt = f\"\"\"You are given the final reasoning and conclusions about a cancer T-staging task:\n",
    "\n",
    "\\\"\\\"\\\"{agent_response}\\\"\\\"\\\"\n",
    "\n",
    "Please provide valid JSON (and ONLY JSON, without extra text) with the following structure:\n",
    "{{\n",
    "\"reasoning\": \"A brief explanation of the reasoning that led to the stage conclusion.\",\n",
    "\"stage\": \"The final T stage (e.g. T1, T2, T3...)\"\n",
    "}}\n",
    "\n",
    "Make sure the output is strictly valid JSON.\n",
    "\"\"\"\n",
    "        \n",
    "    class ResponseStage(BaseModel):\n",
    "        reasoning: str = Field(\n",
    "            description=\"A step-by-step explanation for how you arrived at the predicted T stage.\"\n",
    "        )\n",
    "        stage: Literal[\"T1\", \"T2\", \"T3\", \"T4\"] = Field(\n",
    "            description=\"The final predicted T stage (T1, T2, T3, or T4).\"\n",
    "        )\n",
    "\n",
    "\n",
    "    response = formatting_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=formatting_model,\n",
    "        temperature=0.1,\n",
    "        extra_body={\"guided_json\": ResponseStage.model_json_schema()}\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "available_tools = {\n",
    "    \"extract_information\": extract_information,\n",
    "\n",
    "}\n",
    "tools = generate_tools_spec(*available_tools.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedicalQA 데이터, 5지선다만 골라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read each CSV file into a DataFrame\n",
    "df1 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step1_ALL.csv', encoding=\"utf-8\")\n",
    "df2 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step2_ALL.csv', encoding=\"utf-8\")\n",
    "df3 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step3_ALL.csv', encoding=\"utf-8\")\n",
    "\n",
    "# Reassign the qn_num values with a prefix for each file\n",
    "df1['qn_num'] = '1_' + df1['qn_num'].astype(str)\n",
    "df2['qn_num'] = '2_' + df2['qn_num'].astype(str)\n",
    "df3['qn_num'] = '3_' + df3['qn_num'].astype(str)\n",
    "\n",
    "# Concatenate the DataFrames into one\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Optionally, view the merged DataFrame\n",
    "print(len(merged_df))\n",
    "\n",
    "# Filter rows based on the rule\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in merged_df.iterrows():\n",
    "    matches = re.findall(r'\\b[A-Z](?=[.:])', row['choice'])\n",
    "    if set(matches) == {'A', 'B', 'C', 'D', 'E'}:\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Convert the list of rows to a new DataFrame\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Optionally, view the new DataFrame\n",
    "print(len(filtered_df))\n",
    "filtered_df.to_csv('/home/yl3427/cylab/SOAP_MA/Input/filtered_merged_QA.csv', index=False, encoding=\"utf-8\", lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df.qn_num.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>question</th>\n",
       "      <th>choice</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>qn_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Serum LDL-cholesterol concentrations are measu...</td>\n",
       "      <td>A: 105-155, B: 120-140, C: 125-135, D: 128-132...</td>\n",
       "      <td>B</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A 48-year-old man dies suddenly of a cardiac a...</td>\n",
       "      <td>A. Acute inflammation, B. Fibrinous exudate, C...</td>\n",
       "      <td>E</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>In a sample of 100 individuals, the mean leuko...</td>\n",
       "      <td>A: 5500-9500/mm3, B: &lt;6500/mm3 or &gt;8500/mm3, C...</td>\n",
       "      <td>D</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A 55-year-old woman comes to the clinic becaus...</td>\n",
       "      <td>A: Candida albicans, B: Chlamydia trachomatis,...</td>\n",
       "      <td>A</td>\n",
       "      <td>1_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A 39-year-old man comes to the physician becau...</td>\n",
       "      <td>A: Asthma, B: Bronchiectasis, C: Chronic pulmo...</td>\n",
       "      <td>E</td>\n",
       "      <td>1_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>132</td>\n",
       "      <td>A 72-year-old man is admitted to the intensive...</td>\n",
       "      <td>A: Continuous application of bilateral lower e...</td>\n",
       "      <td>D</td>\n",
       "      <td>3_132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>133</td>\n",
       "      <td>A 45-year-old man comes to the emergency depar...</td>\n",
       "      <td>A: Calcitonin, B: Dehydroepiandrosterone, C: H...</td>\n",
       "      <td>C</td>\n",
       "      <td>3_133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>134</td>\n",
       "      <td>A 45-year-old man comes to the office because ...</td>\n",
       "      <td>A: Acetaminophen, B: Allopurinol, C: Ceftriaxo...</td>\n",
       "      <td>D</td>\n",
       "      <td>3_134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>135</td>\n",
       "      <td>A 2-year-old boy is brought to the emergency d...</td>\n",
       "      <td>A: Intravenous aminophylline therapy, B: Intra...</td>\n",
       "      <td>D</td>\n",
       "      <td>3_135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>137</td>\n",
       "      <td>A 31-year-old man with a 5-year history of HIV...</td>\n",
       "      <td>A: Acyclovir, B: Imiquimod, C: Levofloxacin, D...</td>\n",
       "      <td>B</td>\n",
       "      <td>3_137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                           question  \\\n",
       "0      1  Serum LDL-cholesterol concentrations are measu...   \n",
       "1      2  A 48-year-old man dies suddenly of a cardiac a...   \n",
       "2      3  In a sample of 100 individuals, the mean leuko...   \n",
       "3      4  A 55-year-old woman comes to the clinic becaus...   \n",
       "4      5  A 39-year-old man comes to the physician becau...   \n",
       "..   ...                                                ...   \n",
       "370  132  A 72-year-old man is admitted to the intensive...   \n",
       "371  133  A 45-year-old man comes to the emergency depar...   \n",
       "372  134  A 45-year-old man comes to the office because ...   \n",
       "373  135  A 2-year-old boy is brought to the emergency d...   \n",
       "375  137  A 31-year-old man with a 5-year history of HIV...   \n",
       "\n",
       "                                                choice ground_truth qn_num  \n",
       "0    A: 105-155, B: 120-140, C: 125-135, D: 128-132...            B    1_1  \n",
       "1    A. Acute inflammation, B. Fibrinous exudate, C...            E    1_2  \n",
       "2    A: 5500-9500/mm3, B: <6500/mm3 or >8500/mm3, C...            D    1_3  \n",
       "3    A: Candida albicans, B: Chlamydia trachomatis,...            A    1_4  \n",
       "4    A: Asthma, B: Bronchiectasis, C: Chronic pulmo...            E    1_5  \n",
       "..                                                 ...          ...    ...  \n",
       "370  A: Continuous application of bilateral lower e...            D  3_132  \n",
       "371  A: Calcitonin, B: Dehydroepiandrosterone, C: H...            C  3_133  \n",
       "372  A: Acetaminophen, B: Allopurinol, C: Ceftriaxo...            D  3_134  \n",
       "373  A: Intravenous aminophylline therapy, B: Intra...            D  3_135  \n",
       "375  A: Acyclovir, B: Imiquimod, C: Levofloxacin, D...            B  3_137  \n",
       "\n",
       "[284 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
