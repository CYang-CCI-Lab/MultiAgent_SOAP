{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_filename</th>\n",
       "      <th>t</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>TCGA-3C-AALI.84E6A935-1A49-4BC1-9669-3DEA161CF6FC</td>\n",
       "      <td>1</td>\n",
       "      <td>Path No.: Date Obtained: (Age: ). Date Receive...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>TCGA-3C-AALJ.265E5A9A-64FD-4B86-89BC-5E89F253C118</td>\n",
       "      <td>1</td>\n",
       "      <td>Path No.: Date Obtained: (Age: ). Date Receive...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>TCGA-3C-AALK.F43B01E6-E1DB-44B1-8003-93870606346A</td>\n",
       "      <td>0</td>\n",
       "      <td>Path No.: Date Obtained: (Age: ). Date Receive...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>TCGA-4H-AAAK.8894688F-7167-48A1-BB1B-FC219B7675C2</td>\n",
       "      <td>1</td>\n",
       "      <td>Procedure: Left radical mastectomy. Preoperati...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245</td>\n",
       "      <td>TCGA-5L-AAT0.F9B6971F-23C0-465F-BFEC-778BF228A1AE</td>\n",
       "      <td>1</td>\n",
       "      <td>Gender: Female. Color: White. Origin: Nature o...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1512</td>\n",
       "      <td>TCGA-WT-AB41.FDB00212-9782-4ACE-AD59-019384297A2F</td>\n",
       "      <td>1</td>\n",
       "      <td>SURG PATH #: SPECIMEN CLASS: ALT ID #: SEX: F....</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1513</td>\n",
       "      <td>TCGA-WT-AB44.B7EB0E0B-46C5-43C0-A78D-FB094290765A</td>\n",
       "      <td>0</td>\n",
       "      <td>SURG PATH #: SPECIMEN CLASS: ALT ID #: SEX: F....</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>1514</td>\n",
       "      <td>TCGA-XX-A89A.5D85E578-64B4-4238-922E-802B8ED87800</td>\n",
       "      <td>2</td>\n",
       "      <td>Research Gross Description. Research Dx. Left ...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1515</td>\n",
       "      <td>TCGA-Z7-A8R5.7726F7AA-88A8-4DD6-B322-6FC68893E0D2</td>\n",
       "      <td>2</td>\n",
       "      <td>ADDENDUM. Addendum #1. Entered. BREAST CANCER ...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1516</td>\n",
       "      <td>TCGA-Z7-A8R6.9A5C8EDF-9243-4F55-9036-A400CF3F4CC1</td>\n",
       "      <td>0</td>\n",
       "      <td>ADDENDUM. Addendum #1. Entered: : BREAST CANCE...</td>\n",
       "      <td>BRCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                   patient_filename  t  \\\n",
       "0             46  TCGA-3C-AALI.84E6A935-1A49-4BC1-9669-3DEA161CF6FC  1   \n",
       "1             47  TCGA-3C-AALJ.265E5A9A-64FD-4B86-89BC-5E89F253C118  1   \n",
       "2             48  TCGA-3C-AALK.F43B01E6-E1DB-44B1-8003-93870606346A  0   \n",
       "3            127  TCGA-4H-AAAK.8894688F-7167-48A1-BB1B-FC219B7675C2  1   \n",
       "4            245  TCGA-5L-AAT0.F9B6971F-23C0-465F-BFEC-778BF228A1AE  1   \n",
       "...          ...                                                ... ..   \n",
       "1026        1512  TCGA-WT-AB41.FDB00212-9782-4ACE-AD59-019384297A2F  1   \n",
       "1027        1513  TCGA-WT-AB44.B7EB0E0B-46C5-43C0-A78D-FB094290765A  0   \n",
       "1028        1514  TCGA-XX-A89A.5D85E578-64B4-4238-922E-802B8ED87800  2   \n",
       "1029        1515  TCGA-Z7-A8R5.7726F7AA-88A8-4DD6-B322-6FC68893E0D2  2   \n",
       "1030        1516  TCGA-Z7-A8R6.9A5C8EDF-9243-4F55-9036-A400CF3F4CC1  0   \n",
       "\n",
       "                                                   text  type  n  \n",
       "0     Path No.: Date Obtained: (Age: ). Date Receive...  BRCA  1  \n",
       "1     Path No.: Date Obtained: (Age: ). Date Receive...  BRCA  1  \n",
       "2     Path No.: Date Obtained: (Age: ). Date Receive...  BRCA -1  \n",
       "3     Procedure: Left radical mastectomy. Preoperati...  BRCA  2  \n",
       "4     Gender: Female. Color: White. Origin: Nature o...  BRCA  0  \n",
       "...                                                 ...   ... ..  \n",
       "1026  SURG PATH #: SPECIMEN CLASS: ALT ID #: SEX: F....  BRCA -1  \n",
       "1027  SURG PATH #: SPECIMEN CLASS: ALT ID #: SEX: F....  BRCA -1  \n",
       "1028  Research Gross Description. Research Dx. Left ...  BRCA  0  \n",
       "1029  ADDENDUM. Addendum #1. Entered. BREAST CANCER ...  BRCA  1  \n",
       "1030  ADDENDUM. Addendum #1. Entered: : BREAST CANCE...  BRCA  0  \n",
       "\n",
       "[1031 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('/secure/shared_data/rag_tnm_results/summary/5_folds_summary/brca_df.csv')\n",
    "\n",
    "data_lst = []\n",
    "for i, row in df.iterrows():\n",
    "    pathology_report = row[\"text\"]\n",
    "    ground_truth = row[\"t\"]\n",
    "    filename = row[\"patient_filename\"]\n",
    "\n",
    "    question_text = f\"\"\"\n",
    "    Based on the following pathology report for a breast cancer patient, determine the pathologic T stage (T1, T2, T3, or T4) for breast cancer, according to the AJCC Cancer Staging Manual (7th edition). \n",
    "    Choose from T1, T2, T3, T4.\n",
    "\n",
    "    {pathology_report}\n",
    "    \"\"\"\n",
    "    data = {\"Question\": question_text, \"Answer\": ground_truth, \"Filename\": filename}\n",
    "    data_lst.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/yl3427/cylab/SOAP_MA/data/mergedBioNLP2023.csv',\n",
    "                        usecols=['File ID', 'Subjective', 'Objective', 'Assessment', 'Summary', 'cleaned_expanded_Summary', 'terms'])\n",
    "\n",
    "df = df.fillna('').apply(lambda x: x.str.lower())\n",
    "df['combined_summary'] = df['Summary'] + df['cleaned_expanded_Summary'] + df['terms']\n",
    "\n",
    "mi = [\"myocardial infarction\", \"elevation mi\", \"non-stemi\", \" NSTEMI\", \" stemi\"]\n",
    "chf = [\"congestive heart failure\", \" chf\", \"HFrEF\", \"HFpEF\"]\n",
    "pulmonary_embolism = [\"pulmonary embolism\"]\n",
    "pulmonary_hypertension = [\"pulmonary hypertension\", \"pulmonary htn\"]\n",
    "sepsis = [\"sepsis\", \"septic shock\"]\n",
    "urosepsis = [\"urosepsis\"]\n",
    "meningitis = [\"meningitis\"]\n",
    "aki = [\"acute kidney injury\", \" aki\", \"acute renal failure\", \" arf\"] # -> Acute tubular necrosis (ATN)인가 아닌가\n",
    "atn = [\"acute tubular necrosis\", \" atn\"]\n",
    "pancreatitis = [\"pancreatitis\"]\n",
    "gi_bleed = [\"gastrointestinal bleed\", \"gi bleed\"]\n",
    "hepatitis = [\"hepatitis\", \" hep\"]\n",
    "cholangitis = [\"cholangitis\"]\n",
    "asp_pneumonia = [\"aspiration pneumonia\"]\n",
    "\n",
    "prob_dict = {'sepsis': sepsis, \n",
    "                'acute kidney injury': aki, \n",
    "                'pancreatitis': pancreatitis, \n",
    "                'gastrointestinal bleed': gi_bleed,\n",
    "                \"congestive heart failure\": chf}\n",
    "\n",
    "ids = set()\n",
    "for name, lst in prob_dict.items():\n",
    "    problem_terms = lst\n",
    "    problem_terms = [term.lower() for term in problem_terms]\n",
    "\n",
    "    # Use the first term as the primary term to check in the combined summary.\n",
    "    primary_term = problem_terms[0]\n",
    "\n",
    "    # Build a regex pattern that matches any of the problem terms.\n",
    "    # pattern = '|'.join(problem_terms)\n",
    "    pattern = '|'.join(re.escape(term) for term in problem_terms)\n",
    "\n",
    "    mask = (\n",
    "        df['combined_summary'].str.contains(pattern, na=False) &\n",
    "        ~df['Subjective'].str.contains(pattern, na=False) &\n",
    "        ~df['Objective'].str.contains(pattern, na=False)\n",
    "    )\n",
    "\n",
    "    filtered_df = df[mask]\n",
    "\n",
    "    ids.update(filtered_df['File ID'])\n",
    "\n",
    "df = df[df['File ID'].isin(ids)]\n",
    "df.to_csv('/home/yl3427/cylab/SOAP_MA/Input/SOAP_5_problems.csv', index=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import re\n",
    "from typing import Optional, Union, List, get_origin, get_args, Any, Dict, Literal\n",
    "import inspect\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import math\n",
    "# import demjson3\n",
    "\n",
    "\n",
    "def generate_tools_spec(*functions):\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    \n",
    "    for func in functions:\n",
    "        func_name = func.__name__\n",
    "        func_description = (func.__doc__ or \"\").strip()\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        \n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            \n",
    "            param_name = param.name\n",
    "            annotation = param.annotation\n",
    "            json_type = \"string\"  # default type for fallback\n",
    "\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                \n",
    "                # Handle Literal types (e.g., Literal[\"T\", \"N\", \"M\"])\n",
    "                if origin is Literal:\n",
    "                    literal_args = get_args(annotation)\n",
    "                    \n",
    "                    # If all literal args are strings, produce a string enum\n",
    "                    if all(isinstance(arg, str) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    # If all are integers, produce an integer enum, etc.\n",
    "                    elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    else:\n",
    "                        # Fallback if the Literal contains mixed or unsupported types\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                elif origin is Union:\n",
    "                    union_args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(union_args) == 1:\n",
    "                        # e.g. Optional[str] -> just str\n",
    "                        real_type = union_args[0]\n",
    "                        origin2 = get_origin(real_type)\n",
    "                        \n",
    "                        if origin2 is Literal:\n",
    "                            # If inside an Optional[Literal[...]]\n",
    "                            literal_args = get_args(real_type)\n",
    "                            if all(isinstance(arg, str) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            else:\n",
    "                                properties[param_name] = {\"type\": \"string\"}\n",
    "                        else:\n",
    "                            # Map direct type to JSON schema\n",
    "                            json_type = type_map.get(real_type, \"string\")\n",
    "                            properties[param_name] = {\"type\": json_type}\n",
    "                    else:\n",
    "                        # More complex Unions not automatically handled; fallback to string\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # If it's a known type (str, int, etc.)\n",
    "                elif annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "                \n",
    "                # Handle typing.List[...] or typing.Dict[...] \n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                    if json_type == \"array\":\n",
    "                        # For list[...] or array\n",
    "                        item_type = \"string\"\n",
    "                        args = get_args(annotation)\n",
    "                        if args and args[0] in type_map:\n",
    "                            item_type = type_map[args[0]]\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": item_type}\n",
    "                        }\n",
    "                    elif json_type == \"object\":\n",
    "                        # For dict[...] or any unhandled complex mapping\n",
    "                        properties[param_name] = {\"type\": \"object\"}\n",
    "                \n",
    "                else:\n",
    "                    # Fallback if we can't detect the type\n",
    "                    properties[param_name] = {\"type\": \"string\"}\n",
    "            \n",
    "            else:\n",
    "                # No annotation; assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark as required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        \n",
    "        tools.append(tool_dict)\n",
    "    \n",
    "    return tools\n",
    "\n",
    "\n",
    "async def extract_information(info_to_extract: List[str], pathology_text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts relevant information from a given pathology text.\n",
    "\n",
    "    Args:\n",
    "        info_to_extract (List[str]): A list of information fields to be extracted,\n",
    "            e.g. [\"tumor_size\", \"depth_of_invasion\", ...].\n",
    "        pathology_text (str): The full text of the pathology report.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary mapping each requested field to the extracted information.\n",
    "    \"\"\"\n",
    "    client = AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    async def gather_responses():\n",
    "        tasks = []\n",
    "        for field in info_to_extract:\n",
    "            prompt = f\"\"\"You are given a pathology report:\n",
    "\n",
    "\\\"\\\"\\\"{pathology_text}\\\"\\\"\\\"\n",
    "\n",
    "Please extract the information for the field: {field}.\n",
    "Provide a concise answer containing only the relevant information for that field.\n",
    "\"\"\"\n",
    "            tasks.append(\n",
    "                client.chat.completions.create(\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    model=model_name,\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=500,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Run all extraction queries in parallel\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Build a dictionary of field -> extracted text\n",
    "        extracted_info = {}\n",
    "        for field, response in zip(info_to_extract, responses):\n",
    "            # Depending on your LLM library's return format, adjust how you access content.\n",
    "            raw_answer = response.choices[0].message.content.strip()\n",
    "            extracted_info[field] = raw_answer\n",
    "\n",
    "        return extracted_info\n",
    "\n",
    "    # Run the async logic and return the results\n",
    "    return await gather_responses()\n",
    "\n",
    "def compare_numerical_values(\n",
    "    value: float,\n",
    "    min_value: float = None,\n",
    "    max_value: float = None,\n",
    "    inclusive_min: bool = True,\n",
    "    inclusive_max: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Compares a given numeric value against optional minimum and maximum thresholds.\n",
    "    Args:\n",
    "        value (float): The numeric value to compare.\n",
    "        min_value (float, optional): The lower threshold. \n",
    "                                     If None, no lower bound check is performed.\n",
    "        max_value (float, optional): The upper threshold. \n",
    "                                     If None, no upper bound check is performed.\n",
    "        inclusive_min (bool): Whether the comparison with min_value \n",
    "                              should be inclusive (value >= min_value) \n",
    "                              or exclusive (value > min_value).\n",
    "        inclusive_max (bool): Whether the comparison with max_value \n",
    "                              should be inclusive (value <= max_value) \n",
    "                              or exclusive (value < max_value).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the value satisfies all specified boundary conditions; \n",
    "              False otherwise.\n",
    "\n",
    "    Examples:\n",
    "        compare_numerical_values(3.2, min_value=2, max_value=5) \n",
    "            -> True (assuming inclusive checks)\n",
    "        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\n",
    "            -> False, since 2 is not strictly > 2\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        if inclusive_min:\n",
    "            if value < min_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value <= min_value:\n",
    "                return False\n",
    "\n",
    "    if max_value is not None:\n",
    "        if inclusive_max:\n",
    "            if value > max_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value >= max_value:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def produce_final_staging_response(agent_response: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes the agent's final response and reformat it into a JSON schema with 'reasoning' and 'stage' as keys.\n",
    "\n",
    "    Args:\n",
    "        agent_response (str): The final response from the agent (after all internal processing).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing two keys: 'reasoning' and 'stage'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: we create a second LLM client specifically for formatting the final output\n",
    "    formatting_client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    formatting_model = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    prompt = f\"\"\"You are given the final reasoning and conclusions about a cancer T-staging task:\n",
    "\n",
    "\\\"\\\"\\\"{agent_response}\\\"\\\"\\\"\n",
    "\n",
    "Please provide valid JSON (and ONLY JSON, without extra text) with the following structure:\n",
    "{{\n",
    "\"reasoning\": \"A brief explanation of the reasoning that led to the stage conclusion.\",\n",
    "\"stage\": \"The final T stage (e.g. T1, T2, T3...)\"\n",
    "}}\n",
    "\n",
    "Make sure the output is strictly valid JSON.\n",
    "\"\"\"\n",
    "        \n",
    "    class ResponseStage(BaseModel):\n",
    "        reasoning: str = Field(\n",
    "            description=\"A step-by-step explanation for how you arrived at the predicted T stage.\"\n",
    "        )\n",
    "        stage: Literal[\"T1\", \"T2\", \"T3\", \"T4\"] = Field(\n",
    "            description=\"The final predicted T stage (T1, T2, T3, or T4).\"\n",
    "        )\n",
    "\n",
    "\n",
    "    response = formatting_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=formatting_model,\n",
    "        temperature=0.1,\n",
    "        extra_body={\"guided_json\": ResponseStage.model_json_schema()}\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "available_tools = {\n",
    "    \"extract_information\": extract_information,\n",
    "\n",
    "}\n",
    "tools = generate_tools_spec(*available_tools.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'extract_information',\n",
       "   'description': 'Extracts relevant information from a given pathology text.\\n\\n    Args:\\n        info_to_extract (List[str]): A list of information fields to be extracted,\\n            e.g. [\"tumor_size\", \"depth_of_invasion\", ...].\\n        pathology_text (str): The full text of the pathology report.\\n    \\n    Returns:\\n        Dict[str, str]: A dictionary mapping each requested field to the extracted information.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'info_to_extract': {'type': 'array',\n",
       "      'items': {'type': 'string'}},\n",
       "     'pathology_text': {'type': 'string'}},\n",
       "    'required': ['info_to_extract', 'pathology_text']}}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedicalQA 데이터, 5지선다만 골라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read each CSV file into a DataFrame\n",
    "df1 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step1_ALL.csv')\n",
    "df2 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step2_ALL.csv')\n",
    "df3 = pd.read_csv('/home/yl3427/cylab/SOAP_MA/Input/step3_ALL.csv')\n",
    "\n",
    "# Reassign the qn_num values with a prefix for each file\n",
    "df1['qn_num'] = '1_' + df1['qn_num'].astype(str)\n",
    "df2['qn_num'] = '2_' + df2['qn_num'].astype(str)\n",
    "df3['qn_num'] = '3_' + df3['qn_num'].astype(str)\n",
    "\n",
    "# Concatenate the DataFrames into one\n",
    "merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Optionally, view the merged DataFrame\n",
    "print(len(merged_df))\n",
    "\n",
    "# Filter rows based on the rule\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in merged_df.iterrows():\n",
    "    matches = re.findall(r'\\b[A-Z](?=[.:])', row['choice'])\n",
    "    if set(matches) == {'A', 'B', 'C', 'D', 'E'}:\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Convert the list of rows to a new DataFrame\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Optionally, view the new DataFrame\n",
    "print(len(filtered_df))\n",
    "filtered_df.to_csv('/home/yl3427/cylab/SOAP_MA/Input/filtered_merged_QA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df.qn_num.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
