{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import re\n",
    "from typing import Optional, Union, List, get_origin, get_args, Any, Dict, Literal\n",
    "import inspect\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import math\n",
    "# import demjson3\n",
    "\n",
    "\n",
    "def generate_tools_spec(*functions):\n",
    "    # Mapping of Python types to JSON Schema types\n",
    "    type_map = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\",\n",
    "        list: \"array\",\n",
    "        dict: \"object\",\n",
    "        type(None): \"null\"\n",
    "    }\n",
    "    tools = []\n",
    "    \n",
    "    for func in functions:\n",
    "        func_name = func.__name__\n",
    "        func_description = (func.__doc__ or \"\").strip()\n",
    "        sig = inspect.signature(func)\n",
    "        \n",
    "        properties = {}\n",
    "        required = []\n",
    "        \n",
    "        for param in sig.parameters.values():\n",
    "            # Skip *args and **kwargs as they cannot be described in JSON schema easily\n",
    "            if param.kind in (inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD):\n",
    "                continue\n",
    "            \n",
    "            param_name = param.name\n",
    "            annotation = param.annotation\n",
    "            json_type = \"string\"  # default type for fallback\n",
    "\n",
    "            if annotation is not inspect._empty:\n",
    "                origin = get_origin(annotation)\n",
    "                \n",
    "                # Handle Literal types (e.g., Literal[\"T\", \"N\", \"M\"])\n",
    "                if origin is Literal:\n",
    "                    literal_args = get_args(annotation)\n",
    "                    \n",
    "                    # If all literal args are strings, produce a string enum\n",
    "                    if all(isinstance(arg, str) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    # If all are integers, produce an integer enum, etc.\n",
    "                    elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"enum\": list(literal_args)\n",
    "                        }\n",
    "                    else:\n",
    "                        # Fallback if the Literal contains mixed or unsupported types\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # Handle Optional[X] or Union[X, None]\n",
    "                elif origin is Union:\n",
    "                    union_args = [t for t in get_args(annotation) if t is not type(None)]\n",
    "                    if len(union_args) == 1:\n",
    "                        # e.g. Optional[str] -> just str\n",
    "                        real_type = union_args[0]\n",
    "                        origin2 = get_origin(real_type)\n",
    "                        \n",
    "                        if origin2 is Literal:\n",
    "                            # If inside an Optional[Literal[...]]\n",
    "                            literal_args = get_args(real_type)\n",
    "                            if all(isinstance(arg, str) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            elif all(isinstance(arg, int) for arg in literal_args):\n",
    "                                properties[param_name] = {\n",
    "                                    \"type\": \"integer\",\n",
    "                                    \"enum\": list(literal_args)\n",
    "                                }\n",
    "                            else:\n",
    "                                properties[param_name] = {\"type\": \"string\"}\n",
    "                        else:\n",
    "                            # Map direct type to JSON schema\n",
    "                            json_type = type_map.get(real_type, \"string\")\n",
    "                            properties[param_name] = {\"type\": json_type}\n",
    "                    else:\n",
    "                        # More complex Unions not automatically handled; fallback to string\n",
    "                        properties[param_name] = {\"type\": \"string\"}\n",
    "                \n",
    "                # If it's a known type (str, int, etc.)\n",
    "                elif annotation in type_map:\n",
    "                    json_type = type_map[annotation]\n",
    "                    properties[param_name] = {\"type\": json_type}\n",
    "                \n",
    "                # Handle typing.List[...] or typing.Dict[...] \n",
    "                elif origin in type_map:\n",
    "                    json_type = type_map[origin]\n",
    "                    if json_type == \"array\":\n",
    "                        # For list[...] or array\n",
    "                        item_type = \"string\"\n",
    "                        args = get_args(annotation)\n",
    "                        if args and args[0] in type_map:\n",
    "                            item_type = type_map[args[0]]\n",
    "                        properties[param_name] = {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": item_type}\n",
    "                        }\n",
    "                    elif json_type == \"object\":\n",
    "                        # For dict[...] or any unhandled complex mapping\n",
    "                        properties[param_name] = {\"type\": \"object\"}\n",
    "                \n",
    "                else:\n",
    "                    # Fallback if we can't detect the type\n",
    "                    properties[param_name] = {\"type\": \"string\"}\n",
    "            \n",
    "            else:\n",
    "                # No annotation; assume string\n",
    "                properties[param_name] = {\"type\": \"string\"}\n",
    "\n",
    "            # Mark as required if no default value\n",
    "            if param.default is inspect._empty:\n",
    "                required.append(param_name)\n",
    "        \n",
    "        tool_dict = {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": func_name,\n",
    "                \"description\": func_description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": properties\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if required:\n",
    "            tool_dict[\"function\"][\"parameters\"][\"required\"] = required\n",
    "        \n",
    "        tools.append(tool_dict)\n",
    "    \n",
    "    return tools\n",
    "\n",
    "\n",
    "async def extract_information(info_to_extract: List[str], pathology_text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts relevant information from a given pathology text.\n",
    "\n",
    "    Args:\n",
    "        info_to_extract (List[str]): A list of information fields to be extracted,\n",
    "            e.g. [\"tumor_size\", \"depth_of_invasion\", ...].\n",
    "        pathology_text (str): The full text of the pathology report.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary mapping each requested field to the extracted information.\n",
    "    \"\"\"\n",
    "    client = AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    model_name = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    async def gather_responses():\n",
    "        tasks = []\n",
    "        for field in info_to_extract:\n",
    "            prompt = f\"\"\"You are given a pathology report:\n",
    "\n",
    "\\\"\\\"\\\"{pathology_text}\\\"\\\"\\\"\n",
    "\n",
    "Please extract the information for the field: {field}.\n",
    "Provide a concise answer containing only the relevant information for that field.\n",
    "\"\"\"\n",
    "            tasks.append(\n",
    "                client.chat.completions.create(\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    model=model_name,\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=500,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Run all extraction queries in parallel\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "\n",
    "        # Build a dictionary of field -> extracted text\n",
    "        extracted_info = {}\n",
    "        for field, response in zip(info_to_extract, responses):\n",
    "            # Depending on your LLM library's return format, adjust how you access content.\n",
    "            raw_answer = response.choices[0].message.content.strip()\n",
    "            extracted_info[field] = raw_answer\n",
    "\n",
    "        return extracted_info\n",
    "\n",
    "    # Run the async logic and return the results\n",
    "    return await gather_responses()\n",
    "\n",
    "def compare_numerical_values(\n",
    "    value: float,\n",
    "    min_value: float = None,\n",
    "    max_value: float = None,\n",
    "    inclusive_min: bool = True,\n",
    "    inclusive_max: bool = True\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Compares a given numeric value against optional minimum and maximum thresholds.\n",
    "    Args:\n",
    "        value (float): The numeric value to compare.\n",
    "        min_value (float, optional): The lower threshold. \n",
    "                                     If None, no lower bound check is performed.\n",
    "        max_value (float, optional): The upper threshold. \n",
    "                                     If None, no upper bound check is performed.\n",
    "        inclusive_min (bool): Whether the comparison with min_value \n",
    "                              should be inclusive (value >= min_value) \n",
    "                              or exclusive (value > min_value).\n",
    "        inclusive_max (bool): Whether the comparison with max_value \n",
    "                              should be inclusive (value <= max_value) \n",
    "                              or exclusive (value < max_value).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the value satisfies all specified boundary conditions; \n",
    "              False otherwise.\n",
    "\n",
    "    Examples:\n",
    "        compare_numerical_values(3.2, min_value=2, max_value=5) \n",
    "            -> True (assuming inclusive checks)\n",
    "        compare_numerical_values(2, min_value=2, max_value=5, inclusive_min=False)\n",
    "            -> False, since 2 is not strictly > 2\n",
    "    \"\"\"\n",
    "    if min_value is not None:\n",
    "        if inclusive_min:\n",
    "            if value < min_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value <= min_value:\n",
    "                return False\n",
    "\n",
    "    if max_value is not None:\n",
    "        if inclusive_max:\n",
    "            if value > max_value:\n",
    "                return False\n",
    "        else:\n",
    "            if value >= max_value:\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def produce_final_staging_response(agent_response: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes the agent's final response and reformat it into a JSON schema with 'reasoning' and 'stage' as keys.\n",
    "\n",
    "    Args:\n",
    "        agent_response (str): The final response from the agent (after all internal processing).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing two keys: 'reasoning' and 'stage'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: we create a second LLM client specifically for formatting the final output\n",
    "    formatting_client = OpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\")\n",
    "    formatting_model = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "    prompt = f\"\"\"You are given the final reasoning and conclusions about a cancer T-staging task:\n",
    "\n",
    "\\\"\\\"\\\"{agent_response}\\\"\\\"\\\"\n",
    "\n",
    "Please provide valid JSON (and ONLY JSON, without extra text) with the following structure:\n",
    "{{\n",
    "\"reasoning\": \"A brief explanation of the reasoning that led to the stage conclusion.\",\n",
    "\"stage\": \"The final T stage (e.g. T1, T2, T3...)\"\n",
    "}}\n",
    "\n",
    "Make sure the output is strictly valid JSON.\n",
    "\"\"\"\n",
    "        \n",
    "    class ResponseStage(BaseModel):\n",
    "        reasoning: str = Field(\n",
    "            description=\"A step-by-step explanation for how you arrived at the predicted T stage.\"\n",
    "        )\n",
    "        stage: Literal[\"T1\", \"T2\", \"T3\", \"T4\"] = Field(\n",
    "            description=\"The final predicted T stage (T1, T2, T3, or T4).\"\n",
    "        )\n",
    "\n",
    "\n",
    "    response = formatting_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=formatting_model,\n",
    "        temperature=0.1,\n",
    "        extra_body={\"guided_json\": ResponseStage.model_json_schema()}\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "available_tools = {\n",
    "    \"extract_information\": extract_information,\n",
    "\n",
    "}\n",
    "tools = generate_tools_spec(*available_tools.values())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
